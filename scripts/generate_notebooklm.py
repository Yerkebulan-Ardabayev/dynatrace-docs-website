#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –¥–ª—è Google NotebookLM.

–°—Ç—Ä–∞—Ç–µ–≥–∏—è: –¢–û–õ–¨–ö–û —Ä—É—Å—Å–∫–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã –∏–∑ docs/ru/
- –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ —Ñ–∞–π–ª—ã –ù–ï –≤–∫–ª—é—á–∞—é—Ç—Å—è
- –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ä–∞–∑–¥–µ–ª—É (2–π —É—Ä–æ–≤–µ–Ω—å –ø–∞–ø–∫–∏)
- –ü–æ –º–µ—Ä–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤ ‚Äî –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏ –ø–µ—Ä–µ–∑–∞–ª–∏—Ç—å

NotebookLM –ª–∏–º–∏—Ç—ã:
- –ú–∞–∫—Å 300 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–∞ –Ω–æ—É—Ç–±—É–∫
- –ú–∞–∫—Å 500,000 —Å–ª–æ–≤ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫
"""

import sys
import io
from pathlib import Path
from datetime import datetime

if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    except Exception:
        pass

MAX_WORDS_PER_FILE = 400_000
PROJECT_ROOT = Path(__file__).parent.parent
RU_DIR  = PROJECT_ROOT / 'docs' / 'ru'
OUT_DIR = PROJECT_ROOT / 'docs' / 'notebooklm'


def read_file(path: Path) -> str:
    try:
        return path.read_text(encoding='utf-8', errors='ignore').strip()
    except Exception:
        return ''


def word_count(text: str) -> int:
    return len(text.split())


def get_group_key(rel_path: Path) -> str:
    parts = rel_path.parts
    if len(parts) >= 2:
        # –£–±–∏—Ä–∞–µ–º .md –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–∞–ø–∫–∏-–≥—Ä—É–ø–ø—ã (–∞—Ä—Ç–µ—Ñ–∞–∫—Ç –ø—É—Ç–µ–π —Ç–∏–ø–∞ explorer.md/subfile)
        section = parts[0]
        subsection = parts[1].replace('.md', '')
        return f"{section}/{subsection}"
    return parts[0].replace('.md', '') if parts else 'root'


def collect_ru_groups() -> dict:
    """–°–æ–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ RU —Ñ–∞–π–ª—ã, –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–¥–µ–ª—É."""
    groups = {}
    for ru_file in sorted(RU_DIR.rglob('*.md')):
        rel = ru_file.relative_to(RU_DIR)
        key = get_group_key(rel)
        if key not in groups:
            groups[key] = []
        groups[key].append((rel, ru_file))
    return groups


def combine_group(entries: list, group_name: str) -> str:
    lines = [
        f"# –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Dynatrace: {group_name}",
        f"–Ø–∑—ã–∫: –†—É—Å—Å–∫–∏–π (RU)",
        f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {datetime.now().strftime('%Y-%m-%d')}",
        f"–§–∞–π–ª–æ–≤ –≤ —Ä–∞–∑–¥–µ–ª–µ: {len(entries)}",
        "---",
        "",
    ]
    for rel, fpath in entries:
        content = read_file(fpath)
        if not content:
            continue
        lines.append(f"## {rel.as_posix()}")
        lines.append("")
        lines.append(content)
        lines.append("")
        lines.append("---")
        lines.append("")
    return '\n'.join(lines)


def write_group(key: str, entries: list) -> int:
    safe_name = key.replace('/', '__').replace('\\', '__')
    combined = combine_group(entries, key)
    words = word_count(combined)
    written = 0

    if words <= MAX_WORDS_PER_FILE:
        out_file = OUT_DIR / f"{safe_name}.md"
        out_file.write_text(combined, encoding='utf-8')
        print(f"  ‚úÖ {safe_name}.md  ({len(entries)} —Ñ–∞–π–ª–æ–≤, {words:,} —Å–ª–æ–≤)")
        written = 1
    else:
        part_num = 1
        cur_entries, cur_words = [], 0
        for rel, fpath in entries:
            content = read_file(fpath)
            fw = word_count(content)
            if cur_words + fw > MAX_WORDS_PER_FILE and cur_entries:
                part_text = combine_group(cur_entries, f"{key} (—á–∞—Å—Ç—å {part_num})")
                out_file = OUT_DIR / f"{safe_name}__part{part_num}.md"
                out_file.write_text(part_text, encoding='utf-8')
                print(f"  ‚úÖ {out_file.name}  ({len(cur_entries)} —Ñ–∞–π–ª–æ–≤, {cur_words:,} —Å–ª–æ–≤)")
                written += 1
                part_num += 1
                cur_entries, cur_words = [], 0
            cur_entries.append((rel, fpath))
            cur_words += fw
        if cur_entries:
            part_text = combine_group(cur_entries, f"{key} (—á–∞—Å—Ç—å {part_num})")
            out_file = OUT_DIR / f"{safe_name}__part{part_num}.md"
            out_file.write_text(part_text, encoding='utf-8')
            print(f"  ‚úÖ {out_file.name}  ({len(cur_entries)} —Ñ–∞–π–ª–æ–≤, {cur_words:,} —Å–ª–æ–≤)")
            written += 1

    return written


def generate():
    print("=" * 60)
    print("  üìö –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –¥–ª—è NotebookLM")
    print("  –Ø–∑—ã–∫: –¢–û–õ–¨–ö–û –†–£–°–°–ö–ò–ô (docs/ru/)")
    print("=" * 60)

    if not RU_DIR.exists():
        print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {RU_DIR}")
        sys.exit(1)

    # –û—á–∏—â–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –ø–∞–ø–∫—É
    OUT_DIR.mkdir(parents=True, exist_ok=True)
    deleted = sum(1 for f in OUT_DIR.glob('*.md') if not f.unlink())
    if deleted:
        print(f"\n  üóëÔ∏è  –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤: {deleted}")

    groups = collect_ru_groups()
    total_docs = sum(len(v) for v in groups.values())

    print(f"\n  üá∑üá∫ –ü–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {total_docs}")
    print(f"  üìÇ –†–∞–∑–¥–µ–ª–æ–≤: {len(groups)}")
    print(f"\n  –ì–µ–Ω–µ—Ä–∏—Ä—É—é...")

    total_files = 0
    for key in sorted(groups.keys()):
        total_files += write_group(key, groups[key])

    all_out = list(OUT_DIR.glob('*.md'))
    total_size_mb = sum(f.stat().st_size for f in all_out) / 1024 / 1024

    print()
    print("=" * 60)
    print(f"  ‚úÖ –ì–æ—Ç–æ–≤–æ!")
    print(f"  üìÅ –§–∞–π–ª–æ–≤ –¥–ª—è NotebookLM: {total_files}")
    print(f"  üíæ –†–∞–∑–º–µ—Ä: {total_size_mb:.1f} MB")
    print(f"  üö´ –ê–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤: 0")
    print(f"  üö´ –î—É–±–ª–µ–π: 0")
    print(f"  üìä –õ–∏–º–∏—Ç NotebookLM: 300 (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {total_files})")
    if total_files > 300:
        print(f"  ‚ö†Ô∏è  –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç! NotebookLM –ø—Ä–∏–º–µ—Ç —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 300.")
    print("=" * 60)
    print(f"\n  üí° –ü–æ –º–µ—Ä–µ –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –∑–∞–ø—É—Å–∫–∞–π—Ç–µ —Å–Ω–æ–≤–∞:")
    print(f"     python scripts/generate_notebooklm.py")


if __name__ == '__main__':
    generate()
