#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–£–ü–ï–†-–ë–´–°–¢–†–´–ô –ø–µ—Ä–µ–≤–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ Dynatrace —Å –ø–æ–º–æ—â—å—é Groq API
Llama 3.1 70B - –ë–ï–°–ü–õ–ê–¢–ù–û –∏ –≤ 10 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ!
"""

import os
import sys
import json
import time
import hashlib
import requests
from pathlib import Path

# Groq API - –∫–ª—é—á –±–µ—Ä—ë—Ç—Å—è –¢–û–õ–¨–ö–û –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
API_KEY = os.environ.get('GROQ_API_KEY', '')
GROQ_API_URL = 'https://api.groq.com/openai/v1/chat/completions'

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
DOCS_DIR = Path('../docs')
EN_DIR = DOCS_DIR / 'en'
RU_DIR = DOCS_DIR / 'ru'

# –ö–µ—à –ø–µ—Ä–µ–≤–æ–¥–æ–≤
CACHE_FILE = Path('.translation_cache_groq.json')
cache = {}

if CACHE_FILE.exists():
    with open(CACHE_FILE, 'r', encoding='utf-8') as f:
        cache = json.load(f)

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ (~4000 —Ç–æ–∫–µ–Ω–æ–≤ ‚âà 12000 —Å–∏–º–≤–æ–ª–æ–≤, –æ—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞)
MAX_CHUNK_CHARS = 10000

import re

def split_into_chunks(text: str, max_chars: int = MAX_CHUNK_CHARS) -> list:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ –ø–æ Markdown-–∑–∞–≥–æ–ª–æ–≤–∫–∞–º, –Ω–µ –ø—Ä–µ–≤—ã—à–∞—è max_chars"""
    if len(text) <= max_chars:
        return [text]

    chunks = []
    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º ## (–≤—Ç–æ—Ä–æ–≥–æ —É—Ä–æ–≤–Ω—è –∏ –Ω–∏–∂–µ)
    sections = re.split(r'(^#{1,3} .+$)', text, flags=re.MULTILINE)

    current_chunk = ""
    for section in sections:
        if len(current_chunk) + len(section) > max_chars and current_chunk:
            chunks.append(current_chunk)
            current_chunk = section
        else:
            current_chunk += section

    if current_chunk:
        chunks.append(current_chunk)

    # –ï—Å–ª–∏ –∫–∞–∫–æ–π-—Ç–æ —á–∞–Ω–∫ –≤—Å—ë –µ—â—ë —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ‚Äî —Ä–µ–∂–µ–º –ø–æ –∞–±–∑–∞—Ü–∞–º
    final_chunks = []
    for chunk in chunks:
        if len(chunk) <= max_chars:
            final_chunks.append(chunk)
        else:
            paragraphs = chunk.split('\n\n')
            sub_chunk = ""
            for para in paragraphs:
                if len(sub_chunk) + len(para) + 2 > max_chars and sub_chunk:
                    final_chunks.append(sub_chunk)
                    sub_chunk = para
                else:
                    sub_chunk += ('\n\n' if sub_chunk else '') + para
            if sub_chunk:
                final_chunks.append(sub_chunk)

    return final_chunks


def translate_text(text: str, source_file: str) -> str:
    """–°—É–ø–µ—Ä-–±—ã—Å—Ç—Ä—ã–π –ø–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ Groq + Llama 3.1 70B"""

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–µ—à–∞ (hashlib –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏)
    cache_key = f"{source_file}:{hashlib.sha256(text.encode('utf-8')).hexdigest()[:16]}"
    if cache_key in cache:
        print(f"  ‚Üª –ò–∑ –∫–µ—à–∞")
        return cache[cache_key]

    try:
        print(f"  üöÄ –ü–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ Groq (Llama 3.1 70B - —Å—É–ø–µ—Ä –±—ã—Å—Ç—Ä–æ!)...")

        # –ü—Ä–æ–º–ø—Ç –¥–ª—è Llama —Å –ø–æ–ª–Ω—ã–º –≥–ª–æ—Å—Å–∞—Ä–∏–µ–º Dynatrace
        prompt = f"""–ü–µ—Ä–µ–≤–µ–¥–∏ —Å–ª–µ–¥—É—é—â—É—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é Dynatrace —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π.

–í–ê–ñ–ù–û:
- –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å—ë —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Markdown (–∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏, –∫–æ–¥, —Å—Å—ã–ª–∫–∏, YAML frontmatter)
- –ù–ï –ø–µ—Ä–µ–≤–æ–¥–∏ —Å–ª–µ–¥—É—é—â–∏–µ —Ç–µ—Ä–º–∏–Ω—ã (–æ—Å—Ç–∞–≤—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –∫–∞–∫ –µ—Å—Ç—å):
  Dynatrace, OneAgent, ActiveGate, Smartscape, PurePath, Davis AI, Grail, DQL,
  Cluster Management Console (CMC), Mission Control, Management Zone, Host Unit,
  Host Group, Service Flow, Session Replay, Real User Monitoring (RUM),
  Synthetic Monitoring, AppEngine, Hub, Extensions, Environment,
  Kubernetes, Docker, Helm, OpenShift, Ansible, AWS, Azure, GCP,
  API, SDK, REST API, gRPC, JSON, YAML, XML
- –ü–µ—Ä–µ–≤–µ–¥–∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ
- –ù–ï –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥
- –ù–µ –¥–æ–±–∞–≤–ª—è–π –≤–≤–æ–¥–Ω—ã–µ —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "–í–æ—Ç –ø–µ—Ä–µ–≤–æ–¥:" - —Å—Ä–∞–∑—É –Ω–∞—á–∏–Ω–∞–π —Å –ø–µ—Ä–µ–≤–æ–¥–∞

–¢–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞:

{text}"""

        # –í—ã–∑–æ–≤ Groq API —Å retry –∏ exponential backoff
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    GROQ_API_URL,
                    headers={
                        'Content-Type': 'application/json',
                        'Authorization': f'Bearer {API_KEY}'
                    },
                    json={
                        'model': 'llama-3.3-70b-versatile',
                        'messages': [{
                            'role': 'user',
                            'content': prompt
                        }],
                        'temperature': 0.3,
                        'max_tokens': 8000,
                        'top_p': 1,
                        'stream': False
                    },
                    timeout=60
                )

                if response.status_code == 429:
                    # Rate limited ‚Äî backoff
                    wait_time = 2 ** (attempt + 1)
                    print(f"  ‚è≥ Rate limit, –∂–¥—É {wait_time}—Å (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})...")
                    time.sleep(wait_time)
                    continue

                if response.status_code != 200:
                    print(f"  ‚ùå –û—à–∏–±–∫–∞ API: {response.status_code} - {response.text[:200]}")
                    if attempt < max_retries - 1:
                        time.sleep(2 ** attempt)
                        continue
                    return text

                result = response.json()

                if 'choices' not in result or not result['choices']:
                    print(f"  ‚ùå –ù–µ—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç API")
                    return text

                translation = result['choices'][0]['message']['content'].strip()

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫–µ—à
                cache[cache_key] = translation

                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (Groq: 30 req/min)
                time.sleep(2.0)

                return translation

            except requests.Timeout:
                wait_time = 2 ** (attempt + 1)
                print(f"  ‚è≥ –¢–∞–π–º–∞—É—Ç, –∂–¥—É {wait_time}—Å (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})...")
                time.sleep(wait_time)
                continue
            except requests.ConnectionError:
                wait_time = 2 ** (attempt + 1)
                print(f"  ‚è≥ –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è, –∂–¥—É {wait_time}—Å (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})...")
                time.sleep(wait_time)
                continue

        print(f"  ‚ùå –í—Å–µ {max_retries} –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã")
        return text

    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {str(e)}")
        return text  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ

def translate_file(en_file: Path):
    """–ü–µ—Ä–µ–≤–æ–¥ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""

    # –ü—É—Ç—å –∫ —Ä—É—Å—Å–∫–æ–º—É —Ñ–∞–π–ª—É
    relative_path = en_file.relative_to(EN_DIR)
    ru_file = RU_DIR / relative_path

    print(f"\nüìÑ {relative_path}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, –Ω—É–∂–µ–Ω –ª–∏ –ø–µ—Ä–µ–≤–æ–¥
    if ru_file.exists():
        en_mtime = en_file.stat().st_mtime
        ru_mtime = ru_file.stat().st_mtime

        if ru_mtime > en_mtime:
            print(f"  ‚úì –£–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω (–ø—Ä–æ–ø—É—Å–∫)")
            return

    # –ß—Ç–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
    try:
        with open(en_file, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è: {e}")
        return

    # –ü–µ—Ä–µ–≤–æ–¥ —Å chunking –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
    if len(content) > MAX_CHUNK_CHARS:
        print(f"  üìè –ë–æ–ª—å—à–æ–π —Ñ–∞–π–ª ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤) - —Ä–∞–∑–±–∏–≤–∞—é –Ω–∞ —á–∞—Å—Ç–∏...")
        chunks = split_into_chunks(content)
        translated_parts = []
        for ci, chunk in enumerate(chunks, 1):
            print(f"  üì¶ –ß–∞—Å—Ç—å {ci}/{len(chunks)}...")
            translated_parts.append(translate_text(chunk, f"{relative_path}#chunk{ci}"))
        translated = '\n\n'.join(translated_parts)
    else:
        translated = translate_text(content, str(relative_path))

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    try:
        ru_file.parent.mkdir(parents=True, exist_ok=True)

        with open(ru_file, 'w', encoding='utf-8') as f:
            f.write(translated)

        print(f"  ‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ!")

    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏: {e}")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""

    print("="*70)
    print("üöÄ –°–£–ü–ï–†-–ë–´–°–¢–†–´–ô –ü–ï–†–ï–í–û–î DYNATRACE –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–ò")
    print("ü§ñ –ú–æ–¥–µ–ª—å: Groq Llama 3.1 70B")
    print("‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: –í 10 –†–ê–ó –ë–´–°–¢–†–ï–ï –æ–±—ã—á–Ω–æ–≥–æ!")
    print("="*70)
    print()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–∞
    if not API_KEY:
        print("‚ùå GROQ_API_KEY –Ω–µ –∑–∞–¥–∞–Ω!")
        print("üìù –ü–æ–ª—É—á–∏—Ç–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π –∫–ª—é—á –Ω–∞: https://console.groq.com")
        print("üí° –ó–∞—Ç–µ–º —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: set GROQ_API_KEY=gsk_your_key_here")
        return

    # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
    if not EN_DIR.exists():
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {EN_DIR}")
        return

    en_files = list(EN_DIR.rglob('*.md'))

    if not en_files:
        print(f"‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ {EN_DIR}")
        return

    print(f"üìö –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(en_files)}")
    print()

    # –ü–µ—Ä–µ–≤–æ–¥ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
    translated = 0
    skipped = 0
    errors = 0

    start_time = time.time()

    for i, en_file in enumerate(en_files, 1):
        print(f"[{i}/{len(en_files)}]", end=" ")

        try:
            translate_file(en_file)
            translated += 1
        except KeyboardInterrupt:
            print("\n\n‚ö†Ô∏è  –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            break
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")
            errors += 1

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–µ—à–∞ –∫–∞–∂–¥—ã–µ 10 —Ñ–∞–π–ª–æ–≤
        if i % 10 == 0:
            with open(CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump(cache, f, ensure_ascii=False, indent=2)

    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–µ—à–∞
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)

    elapsed_time = time.time() - start_time
    minutes = int(elapsed_time // 60)
    seconds = int(elapsed_time % 60)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print()
    print("="*70)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*70)
    print(f"‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translated}")
    print(f"‚Üª –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped}")
    print(f"‚ùå –û—à–∏–±–æ–∫: {errors}")
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {minutes}–º {seconds}—Å")
    if translated > 0:
        avg_time = elapsed_time / translated
        print(f"‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: {avg_time:.1f}—Å –Ω–∞ —Ñ–∞–π–ª")
    print()
    print("üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å: –ë–ï–°–ü–õ–ê–¢–ù–û! üéâ")
    print("üöÄ Groq - —Å–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π AI!")
    print()

if __name__ == '__main__':
    main()
