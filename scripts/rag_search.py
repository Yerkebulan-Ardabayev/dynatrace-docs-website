#!/usr/bin/env python3
"""
Dynatrace Documentation RAG Search
Local search + Groq Llama for intelligent answers.

Usage:
    python scripts/rag_search.py                    # interactive mode
    python scripts/rag_search.py "your question"    # single question
    python scripts/rag_search.py --lang ru "Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ" # answer in Russian
"""

import os
import sys
import io
import json
import time
import hashlib
import argparse
from pathlib import Path

import requests
try:
    from dotenv import load_dotenv
    load_dotenv(Path(__file__).parent.parent / ".env")
except ImportError:
    pass
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Fix Windows encoding (only in interactive terminal, not piped)
if sys.platform == 'win32' and sys.stdout.isatty():
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SCRIPT_DIR = Path(__file__).parent
DOCS_DIR = SCRIPT_DIR.parent / "docs"
EN_DIR = DOCS_DIR / "en"
RU_DIR = DOCS_DIR / "ru"
INDEX_CACHE = SCRIPT_DIR / ".rag_index_cache.json"

GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
GROQ_API_KEY = os.environ.get("GROQ_API_KEY", "")
GROQ_MODEL = "llama-3.3-70b-versatile"

TOP_K = 5  # number of relevant docs to include in context


# â”€â”€â”€ Document Loading â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_documents():
    """Load all markdown documents from en/ and ru/ directories."""
    docs = []

    for lang_dir, lang in [(EN_DIR, "en"), (RU_DIR, "ru")]:
        if not lang_dir.exists():
            continue
        for md_file in sorted(lang_dir.rglob("*.md")):
            try:
                content = md_file.read_text(encoding="utf-8", errors="ignore").strip()
                if len(content) < 50:  # skip empty/tiny files
                    continue
                rel_path = md_file.relative_to(DOCS_DIR)

                # Extract title from content
                title = ""
                for line in content.split("\n")[:10]:
                    line = line.strip()
                    if line.startswith("# "):
                        title = line[2:].strip()
                        break
                    if line.startswith("title:"):
                        title = line.split(":", 1)[1].strip()
                        break

                docs.append({
                    "path": str(rel_path),
                    "lang": lang,
                    "title": title or md_file.stem,
                    "content": content,
                })
            except Exception:
                continue

    return docs


# â”€â”€â”€ Search Index â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SearchIndex:
    def __init__(self, docs):
        self.docs = docs
        self.vectorizer = TfidfVectorizer(
            max_features=50000,
            ngram_range=(1, 2),
            stop_words="english",
            sublinear_tf=True,
        )

        # Build index
        texts = [f"{d['title']} {d['content']}" for d in docs]
        self.tfidf_matrix = self.vectorizer.fit_transform(texts)

    def search(self, query, top_k=TOP_K, lang=None):
        """Search for relevant documents."""
        query_vec = self.vectorizer.transform([query])
        scores = cosine_similarity(query_vec, self.tfidf_matrix).flatten()

        # Get top results
        top_indices = np.argsort(scores)[::-1]

        results = []
        for idx in top_indices:
            if len(results) >= top_k:
                break
            doc = self.docs[idx]
            score = scores[idx]
            if score < 0.01:  # skip irrelevant
                continue
            if lang and doc["lang"] != lang:
                continue
            results.append({
                "doc": doc,
                "score": float(score),
            })

        return results


# â”€â”€â”€ Groq LLM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ask_groq(question, context_docs, lang="ru", _retry=0):
    """Generate answer using Groq Llama with document context."""
    if not GROQ_API_KEY:
        return "GROQ_API_KEY Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½! Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸: set GROQ_API_KEY=gsk_..."

    # Build context from top documents
    context_parts = []
    for i, result in enumerate(context_docs, 1):
        doc = result["doc"]
        # Truncate content to fit in context window
        content = doc["content"][:3000]
        context_parts.append(
            f"[Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ {i}] ({doc['path']})\n"
            f"Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº: {doc['title']}\n"
            f"Ğ ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ: {result['score']:.2f}\n"
            f"Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ:\n{content}\n"
        )

    context = "\n---\n".join(context_parts)

    lang_instruction = {
        "ru": "ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.",
        "en": "Answer in English.",
        "kk": "ÒšĞ°Ğ·Ğ°Ò› Ñ‚Ñ–Ğ»Ñ–Ğ½Ğ´Ğµ Ğ¶Ğ°ÑƒĞ°Ğ¿ Ğ±ĞµÑ€.",
    }.get(lang, "ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.")

    prompt = f"""Ğ¢Ñ‹ â€” ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¿Ğ¾ Dynatrace. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°.
{lang_instruction}

ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ°:
- ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¸ Ğ¿Ğ¾ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ñƒ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸
- Ğ£ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ğ¹ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº [Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ N] Ğ¿Ñ€Ğ¸ Ñ†Ğ¸Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸
- Ğ•ÑĞ»Ğ¸ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ Ğ½ĞµÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° â€” Ñ‡ĞµÑÑ‚Ğ½Ğ¾ ÑĞºĞ°Ğ¶Ğ¸ Ğ¾Ğ± ÑÑ‚Ğ¾Ğ¼
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ñ‹ Dynatrace Ğ±ĞµĞ· Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ° (OneAgent, ActiveGate, PurePath Ğ¸ Ñ‚.Ğ´.)

ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ· Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸:
{context}

Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: {question}

ĞÑ‚Ğ²ĞµÑ‚:"""

    try:
        response = requests.post(
            GROQ_API_URL,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {GROQ_API_KEY}",
            },
            json={
                "model": GROQ_MODEL,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.2,
                "max_tokens": 4000,
            },
            timeout=30,
        )

        if response.status_code == 429:
            if _retry >= 2:
                return "âš ï¸ Groq rate limit Ğ¸ÑÑ‡ĞµÑ€Ğ¿Ğ°Ğ½. ĞŸĞ¾Ğ´Ğ¾Ğ¶Ğ´Ğ¸ Ğ¿Ğ°Ñ€Ñƒ Ğ¼Ğ¸Ğ½ÑƒÑ‚ Ğ¸ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ ÑĞ½Ğ¾Ğ²Ğ°."
            wait = int(response.headers.get("retry-after", 5))
            print(f"  â³ Rate limit, Ğ¶Ğ´Ñƒ {wait}Ñ...")
            time.sleep(min(wait, 10))
            return ask_groq(question, context_docs, lang, _retry + 1)

        if response.status_code != 200:
            return f"ĞÑˆĞ¸Ğ±ĞºĞ° API: {response.status_code} â€” {response.text[:200]}"

        result = response.json()
        return result["choices"][0]["message"]["content"].strip()

    except Exception as e:
        return f"ĞÑˆĞ¸Ğ±ĞºĞ°: {e}"


# â”€â”€â”€ CLI Interface â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def print_header():
    print()
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘   Dynatrace Documentation RAG Search                   â•‘")
    print("â•‘   Powered by Groq Llama 3.3 70B + TF-IDF              â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()


def interactive_mode(index, lang):
    """Interactive question-answer loop."""
    print_header()
    print(f"  Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ğ¸Ğ½Ğ´ĞµĞºÑĞµ: {len(index.docs)}")
    print(f"  Ğ¯Ğ·Ñ‹Ğº Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²: {lang}")
    print(f"  Ğ’Ğ²ĞµĞ´Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¸Ğ»Ğ¸ 'exit' Ğ´Ğ»Ñ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°")
    print()

    while True:
        try:
            question = input("â“ > ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\n\nĞ’Ñ‹Ñ…Ğ¾Ğ´.")
            break

        if not question:
            continue
        if question.lower() in ("exit", "quit", "q", "Ğ²Ñ‹Ñ…Ğ¾Ğ´"):
            print("Ğ’Ñ‹Ñ…Ğ¾Ğ´.")
            break

        # Search
        print("  ğŸ” ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸...")
        results = index.search(question, top_k=TOP_K)

        if not results:
            print("  âŒ ĞĞ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾.\n")
            continue

        # Show found documents
        print(f"  ğŸ“„ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(results)} Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²:")
        for i, r in enumerate(results, 1):
            doc = r["doc"]
            score = r["score"]
            flag = "ğŸ‡¬ğŸ‡§" if doc["lang"] == "en" else "ğŸ‡·ğŸ‡º"
            print(f"     {i}. {flag} {doc['title'][:60]}  ({score:.2f})")

        # Generate answer
        print("  ğŸ¤– Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ñ‡ĞµÑ€ĞµĞ· Groq...")
        answer = ask_groq(question, results, lang)

        print()
        print("  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print()
        # Print answer with indent
        for line in answer.split("\n"):
            print(f"  {line}")
        print()
        print("  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print()


def single_query(index, question, lang):
    """Answer a single question."""
    results = index.search(question, top_k=TOP_K)

    if not results:
        print("ĞĞ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾.")
        return

    print(f"\nğŸ“„ Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸ ({len(results)}):")
    for i, r in enumerate(results, 1):
        doc = r["doc"]
        flag = "EN" if doc["lang"] == "en" else "RU"
        print(f"  {i}. [{flag}] {doc['title'][:70]}  (score: {r['score']:.2f})")

    print("\nğŸ¤– ĞÑ‚Ğ²ĞµÑ‚:\n")
    answer = ask_groq(question, results, lang)
    print(answer)
    print()


# â”€â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    parser = argparse.ArgumentParser(description="Dynatrace Documentation RAG Search")
    parser.add_argument("question", nargs="?", help="Question to ask (or omit for interactive mode)")
    parser.add_argument("--lang", default="ru", choices=["ru", "en", "kk"], help="Answer language")
    args = parser.parse_args()

    # Check API key
    if not GROQ_API_KEY:
        print("âš ï¸  GROQ_API_KEY Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½!")
        print("   Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸: set GROQ_API_KEY=gsk_your_key")
        print("   ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ¾: https://console.groq.com")
        print()
        print("   ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°Ñ Ğ±ĞµĞ· LLM (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾Ğ¸ÑĞº)...\n")

    # Load documents
    print("ğŸ“š Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸...")
    docs = load_documents()
    print(f"   Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾: {len(docs)} Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²")

    en_count = sum(1 for d in docs if d["lang"] == "en")
    ru_count = sum(1 for d in docs if d["lang"] == "ru")
    print(f"   EN: {en_count} | RU: {ru_count}")

    # Build search index
    print("ğŸ”§ ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ğ´ĞµĞºÑĞ°...")
    index = SearchIndex(docs)
    print("   Ğ˜Ğ½Ğ´ĞµĞºÑ Ğ³Ğ¾Ñ‚Ğ¾Ğ²!")

    if args.question:
        single_query(index, args.question, args.lang)
    else:
        interactive_mode(index, args.lang)


if __name__ == "__main__":
    main()
