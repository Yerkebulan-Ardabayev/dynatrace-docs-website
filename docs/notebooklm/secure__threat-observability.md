# Dynatrace Documentation: secure/threat-observability

Generated: 2026-02-17

Files combined: 23

---


## Source: concepts.md


---
title: Threat Observability concepts
source: https://www.dynatrace.com/docs/secure/threat-observability/concepts
scraped: 2026-02-16T09:33:44.633373
---

# Threat Observability concepts

# Threat Observability concepts

* Latest Dynatrace
* Explanation
* Updated on Jan 28, 2026

This section aims to give you a better understanding of data in the security context so you can easily accomplish various [use cases](#usecase) with security-related data available on [Grail](/docs/platform/grail "Insights on what and how you can query Dynatrace data."). To learn how DQL can help in your daily tasks, see [DQL examples for security data](#examples).

## Types of data in Grail

Data can be ingested in Grail from your monitored environment or from third-party sources.

Data from your monitored environment

Data from third-party sources

Data that Dynatrace collects from your monitored environment and that can be currently queried in Grail consists of:

* [Security events](#security-events)
* [Logs](/docs/analyze-explore-automate/logs "Log Management and Analytics provides a unified approach to controlling and studying your log data in Dynatrace.")
* [Metrics](/docs/analyze-explore-automate/metrics/built-in-metrics-on-grail "Get to know the equivalents of the classic built-in metrics supported on Grail.")
* [Entities](/docs/platform/grail/querying-monitored-entities "Find out how to query monitored entities in Grail.")
* [Dynatrace Intelligence problems and events](/docs/dynatrace-intelligence/root-cause-analysis/event-analysis-and-correlation "Gain an understanding of the Events section on each host, process, and service overview page.")
* [System events](/docs/platform/upgrade#system-data "Use the power of Grail, AppEngine, and AutomationEngine to take advantage of improvements in storing and analyzing observability and security data.")
* [Business events](/docs/observe/business-observability/bo-basic-concepts#business-event "Basic concepts of Dynatrace Business Observability.")

For details, see

* [Data in Grail](/docs/platform/upgrade#data-in-grail "Use the power of Grail, AppEngine, and AutomationEngine to take advantage of improvements in storing and analyzing observability and security data.")
* [Grail data model](/docs/platform/grail/organize-data "Insights on the Grail data model consisting of buckets, tables, and views.")

Dynatrace consumes data from third-party sources, providing consolidated, unified analysis and automation.

For a list of supported integrations, see [Security events ingest](/docs/secure/threat-observability/security-events-ingest "Ingest external security data into Grail.").

## Security-related data

Security-related data can be either generated by Dynatrace native capabilities and collected by [OneAgent](/docs/platform/oneagent "Learn the monitoring capabilities of OneAgent.") or [ActiveGate](/docs/ingest-from/dynatrace-activegate "Understand the basic concepts related to ActiveGate."), or ingested from third-party tools via [log ingestion](/docs/analyze-explore-automate/logs "Log Management and Analytics provides a unified approach to controlling and studying your log data in Dynatrace.") or [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.").

Security-related data on Grail can provide you answers with different granularity and from various perspectives. You can query, aggregate, visualize, and report data on multiple levels.

The Grail data lakehouse doesn't distinguish security-related data from observability information. You can use all your data in Dynatrace for your security use cases. For example, if you ingested your application authentication logs for business purposes, you can use the same logs to detect potential [brute force attacksï»¿](https://attack.mitre.org/techniques/T1110/) on your customer accounts.
Below are some examples of how you can use data for security purposes:

* [Context-aware security incident response with Dynatrace Automations and Tetragonï»¿](https://dt-url.net/he03pmt)
* [Overseeing SaaS security with AWS AppFabric and Dynatraceï»¿](https://dt-url.net/mj23pnk)
* [Detect VMware Aria Operations for Logs exploitation with Dynatrace and DQLï»¿](https://dt-url.net/t203p6a)
* [TTP-based threat hunting with Dynatrace Security Analytics and Falco Alerts solves alert noiseï»¿](https://dt-url.net/j903pdg)
* [Log forensics: Finding malicious activity in multicloud environments with Dynatrace Grailï»¿](https://dt-url.net/dz03pqc)

## Security events

This section has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Security events are a type of [security-related data](#security-data) consisting of various generated events such as

* [Vulnerability events](#vuln-events)
* [Compliance events](#compliance)
* [Detection finding events](#detection)

### Storage

* Security events generated by Dynatrace from your monitored environment are stored in the `default_securityevents_builtin` bucket for **three years**.
* Security events ingested from third-party sources are stored in the `default_securityevents` bucket for **one year**.
* The original (raw) data ingested is stored in `dt.raw_data`. You can query it with a [parse command](/docs/platform/grail/dynatrace-query-language/commands/extraction-and-parsing-commands "DQL extraction commands"), for example:

  ```
  fetch security.events



  | parse dt.raw_data, """JSON:dt.raw_data"""



  | filter isNotNull(dt.raw_data[vulnerability.title])



  | fields dt.raw_data[vulnerability.title]
  ```

### Permissions

* `storage:security.events:read` (to query ingested security events)
* `storage:logs:read` (to query ingested logs)

## Vulnerability events

Vulnerability events can be classified by event levels (`event.level`), event groups (`event.group_label`), and event types (`event.type`). See below for details.

**Event levels**

| Event levels | Description |
| --- | --- |
| `VULNERABILITY` | The vulnerability on the global level, including general information, global statuses, and changes. The unique identifier is `vulnerability.id` or `vulnerability.display_id`. |
| `ENTITY` | The vulnerable entity with vulnerability-related information scoped to the entity. The unique identifier is a tuple of (`affected_entity.id`, `vulnerability.id`). |

**Event groups**

| Event groups | Description |
| --- | --- |
| `CHANGE_EVENT` | Change that occurs on a vulnerability or its affected entity. |
| `STATE_REPORT` | The full historical state of a vulnerability or its affected entity and is reported periodically over time: `OPEN` (muted and not muted) vulnerabilities are reported every 15 minutes; `RESOLVED` vulnerabilities are reported only once (when open vulnerabilities get resolved). To analyze resolved vulnerabilities, filter for the desired time range. |

**Event types**

| Event types | Description |
| --- | --- |
| `VULNERABILITY_STATE_REPORT_EVENT` | Historical vulnerability states reported periodically. |
| `VULNERABILITY_COVERAGE_REPORT_EVENT` | Historical coverage events reported periodically. |
| `VULNERABILITY_STATUS_CHANGE_EVENT` | Vulnerability status changes reported on change. These include resolution and mute statuses. |
| `VULNERABILITY_ASSESSMENT_CHANGE_EVENT` | Vulnerability assessment changes reported on change. These include the Dynatrace Security Score and Dynatrace Assessment. |
| `VULNERABILITY_FINDING`[1](#fn-1-1-def) | A single vulnerability identified in a specific process at a given time. |
| `VULNERABILITY_SCAN`[1](#fn-1-1-def) | The analysis of detected packages within a specific process at a given time. |

1

This event type can be ingested both from [third-party security tools](/docs/secure/threat-observability/security-events-ingest "Ingest external security data into Grail.") and from [third-party libraries used by Dynatrace-monitored processes](/docs/secure/vulnerabilities/concepts#tpv-events "Concepts that are specific to the Dynatrace Vulnerabilities app.").

For a list of vulnerability event fields mapped to Grail, see [Dynatrace Semantic Dictionary](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.").

### Vulnerability findings

Use ![Vulnerabilities](https://dt-cdn.net/images/vulnerabilities-highresolution-1025-9279da9743.png "Vulnerabilities") **Vulnerabilities** to [analyze, prioritize, and efficiently manage findings](/docs/secure/vulnerabilities/explore-findings "View, filter, and analyze vulnerability findings from Dynatrace and external security tools.") in your monitored environments.

A vulnerability finding is a security event that highlights a detected weakness in a system, software component, or environment. It represents a single instance of a flaw or misconfiguration that could be exploited.

Each finding is stored as an individual event at the time it is detected. These records may come from external sources such as thirdâparty scanners or libraries used by Dynatraceâmonitored processes. Dynatrace ingests and stores these events as raw data but does not perform additional analysis (for example, no Dynatrace Security Score is calculated).

Findings include details such as:

* Severity and risk level
* Affected component and remediation status
* Metadata (timestamps, unique IDs, and source information)
* Technical attributes (CVSS scores, exploit availability, and CVE references)

## Compliance events

A compliance event is a type of security event specific to the [Security Posture Management capability](/docs/secure/application-security/security-posture-management-hub "Assess, manage, and take action on misconfigurations and violations against security hardening guidelines and regulatory compliance standards."). It represents the assessment of a resource in the context of the rule specified in the compliance standard.

| Event types | Description |
| --- | --- |
| `COMPLIANCE_SCAN_COMPLETED` | A compliance scan completed event is generated when a scan of a configuration dataset against compliance rules is completed. |
| `COMPLIANCE_FINDING` | A compliance finding event is generated when an object is evaluated against a compliance rule during a scan. The event contains the results of this evaluation and the compliance status of the given object. |

For a list of compliance event fields mapped to Grail, see [Dynatrace Semantic Dictionary](/docs/semantic-dictionary/model/security-events#compliance-finding-events "Get to know the Semantic Dictionary models related to security events.").

## Detection finding events

A detection finding event is generated when suspicious activity is observed around an object. The event contains all information available and deemed useful at the moment of detection.

Use [![Threats & Exploits](https://dt-cdn.net/images/attacks-512-b922840b12.png "Threats & Exploits") **Threats & Exploits**](/docs/secure/threats-and-exploits "Understand, triage, and investigate detection findings and alerts.") to evaluate, triage, and investigate detection findings.

| Event types | Description |
| --- | --- |
| `DETECTION_FINDING` | An alert or detection generated by security tools using correlation algorithms, detection rules, or other analytical methods. |

To retrieve detection finding events, use a query such as the following:

```
fetch security.events



| filter event.kind == "SECURITY_EVENT" AND event.type == "DETECTION_FINDING"



| filter product.name == "Runtime Application Protection"



| makeTimeseries count()
```

For a list of detection finding event fields mapped to Grail, see [Dynatrace Semantic Dictionary](/docs/semantic-dictionary/model/security-events#detection-finding-events "Get to know the Semantic Dictionary models related to security events.").

## OpenPipeline integration

With [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline."), you can ingest external security events from multiple third-party products into [Grail](/docs/platform/grail "Insights on what and how you can query Dynatrace data.") and operationalize your data on the Dynatrace platform.

**Out-of-the-box integrations**

Dynatrace provides seamless OpenPipeline integration options for specific technologies. Ingested data is automatically stored in [Grail](/docs/platform/grail "Insights on what and how you can query Dynatrace data.") and mapped to the [Dynatrace Semantic Dictionary unified formatï»¿](https://dt-url.net/3q03pb0).
We provide ready-made dashboards and workflows to help you visualize data and automatize notifications. For a practical example, see [Visualize and analyze security findings use case](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.").

**Support for custom ingestion**

You can use our built-in security events API endpoint or create a custom API endpoint to ingest any kind of security events from any third-party system into Grail. You can [configure a pipelineï»¿](https://dt-url.net/k203p5t) to manually map your data to the [Semantic Dictionary conventionsï»¿](https://dt-url.net/3q03pb0).
Once your events comply with the Semantic Dictionary, you can leverage the dashboards and workflows provided by other integrations to view, analyze, and automate those findings alongside existing security data.

## Severity and score normalization

When findings are ingested from different vulnerability sources, Dynatrace distinguishes between the values reported by the provider and the normalized values used across the platform. Normalization ensures that all findings can be consistently compared and prioritized, regardless of their origin.

* **Ingested severity**: Severity level reported by the original vendor or scanner. The severity level is stored in the `finding.severity` field.
* **Normalized severity**: Severity mapped to a unified Dynatrace risk scale (`dt.security.risk.level`) to ensure consistency across products.
* **Ingested risk score**: Risk score defined by the provider (for example, Dynatrace Security Score). When provided by the source tool, the ingested risk score is stored in the `finding.score` field.
* **Normalized risk score**: Risk score converted to a unified Dynatrace scale (`dt.security.risk.score`) so you can consistently crossâprioritize vulnerabilities.

Each finding also specifies the product (`product.name` and `product.vendor`) that detected it (for example, Runtime Vulnerability Analytics), so you can identify the source of the data.
For more information and the complete security model specification, see [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.").


---


## Source: dql-examples.md


---
title: DQL examples for security data
source: https://www.dynatrace.com/docs/secure/threat-observability/dql-examples
scraped: 2026-02-17T21:16:03.764371
---

# DQL examples for security data

# DQL examples for security data

* Latest Dynatrace
* How-to guide
* Updated on Oct 22, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

The examples below illustrate how to slice and dice [security data](/docs/secure/threat-observability/concepts#security-data "Basic concepts related to Threat Observability") and build powerful and flexible security reports with [Dynatrace Query Language (DQL)](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.").

## Query Dynatrace events

### Total number of open vulnerabilities

Get the total number of open, non-muted vulnerabilities in your environment.

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities



| filter vulnerability.resolution.status=="OPEN"



AND vulnerability.parent.mute.status!="MUTED"



AND vulnerability.mute.status!="MUTED"



// count unique vulnerabilities



| summarize {`Open vulnerabilities`=countDistinctExact(vulnerability.display_id)}
```

**Query result**:

![Open non-muted vulnerabilities](https://dt-cdn.net/images/2023-12-15-11-32-55-1543-ca0c6f47d5.png)

### Total number of critical open vulnerabilities

Get the total number of critical open, non-muted vulnerabilities in your environment.

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for critical open non-muted vulnerabilities



| filter vulnerability.resolution.status=="OPEN"



AND vulnerability.parent.mute.status!="MUTED"



AND vulnerability.mute.status!="MUTED"



AND vulnerability.risk.level=="CRITICAL"



// count unique vulnerabilities



| summarize {`Critical open vulnerabilities`=countDistinctExact(vulnerability.display_id)}
```

**Query result**:

![Total number of critical open vulnerabilities](https://dt-cdn.net/images/2023-12-20-13-57-44-1512-b21087af2c.png)

### Total number of open vulnerabilities in a management zone

Get the total number of open, non-muted vulnerabilities in a specific management zone (in this example, `AppSec: UNGUARD`).

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities in a specific management zone



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



AND in("AppSec: Unguard", affected_entity.management_zones.names)



// count unique vulnerabilities



| summarize {`Open vulnerabilities (unguard)`=countDistinctExact(vulnerability.display_id)}
```

**Query result**:

![Open, non-muted vulnerabilities in a management zone](https://dt-cdn.net/images/2023-12-20-13-34-01-1580-01e1dbca61.png)

### Total number of open vulnerabilities with internet exposure

Get the total number of open, non-muted vulnerabilities with public internet exposure in your environment.

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities with public internet exposure



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



AND vulnerability.davis_assessment.exposure_status=="PUBLIC_NETWORK"



// count unique vulnerabilities



| summarize {`With internet exposure`=countDistinctExact(vulnerability.display_id)}
```

**Query result**:

![Total number of open vulnerabilities with public internet exposure](https://dt-cdn.net/images/2023-12-20-14-09-32-1540-05942b1581.png)

### Total number of affected entities

Get the total number of affected entities in your environment.

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



// count unique entities



| summarize {`Affected entities`=countDistinctExact(affected_entity.id)}
```

**Query result**:

![Total number of affected entities](https://dt-cdn.net/images/2023-12-20-14-20-33-1511-7f499653c3.png)

### Total number of affected process groups

Get the total number of affected process groups in your environment.

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities detected in running processes



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



AND affected_entity.type=="PROCESS_GROUP"



// count unique entities



| summarize {`Affected process groups`=countDistinctExact(affected_entity.id)}
```

**Query result**:

![Total number of affected process groups](https://dt-cdn.net/images/2023-12-20-14-27-23-1471-c0f5334716.png)

### Total number of affected entities over time

Get the total number of affected, non-muted entities over time (in three-hour buckets).

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for open non-muted vulnerabilities



AND vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



// count unique entities for each timestamp bucket of 3h



| sort timestamp desc



| summarize {entities=countDistinctExact(affected_entity.id)}, by: {timestamp=bin(timestamp, 3h)}
```

**Query result**:

![Total number of affected entities over time](https://dt-cdn.net/images/2023-12-20-14-36-38-1380-7e18f35512.png)

### Total number of hosts related to vulnerabilities

Get the total number of hosts that are indirectly affected by open vulnerabilities in your environment.

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities



|filter  vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



// count hosts



| summarize {`Related hosts`=arraySize(collectDistinct(related_entities.hosts.ids, expand:true))}
```

**Query result**:

![Total number of hosts related to vulnerabilities](https://dt-cdn.net/images/2023-12-20-16-17-58-1591-f1ab611412.png)

### Open vulnerabilities by risk level

Get a count of open vulnerabilities split by risk levels.

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



// summarize score per vulnerability



| summarize {vulnerability.risk.score=takeMax(vulnerability.risk.score)}, by: {vulnerability.display_id}



// map the risk level



| fieldsAdd vulnerability.risk.level=if(vulnerability.risk.score>=9,"CRITICAL",



else:if(vulnerability.risk.score>=7,"HIGH",



else:if(vulnerability.risk.score>=4,"MEDIUM",



else:if(vulnerability.risk.score>=0.1,"LOW",



else:"NONE"))))



// count vulnerabilities per risk level



| summarize { Vulnerabilities=count(), maxScore=takeMax(vulnerability.risk.score) }, by:{vulnerability.risk.level}



| sort maxScore, direction:"descending"
```

**Query result**:

![Open vulnerabilities by risk level](https://dt-cdn.net/images/2023-12-20-16-05-32-1263-b388e93ee3.png)

### Open vulnerabilities by type

Get a count of open vulnerabilities split by type.

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



// count vulnerabilities per type



| summarize { Vulnerabilities=countDistinctExact(vulnerability.display_id) }, by:{vulnerability.type}



| sort Vulnerabilities, direction:"descending"



| limit 10
```

**Query result**:

![Open vulnerabilities by type](https://dt-cdn.net/images/2023-12-20-16-03-28-1755-79c825ba70.png)

### Open vulnerabilities over time

Get the open vulnerability count over time, in three-hour buckets.

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for open non-muted vulnerabilities



AND vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



| sort timestamp desc



| summarize {Open=countDistinctExact(vulnerability.display_id)}, by: {timestamp=bin(timestamp,3h)}
```

**Query result**:

![open vulnerabilities in 3-hr buckets](https://dt-cdn.net/images/2024-06-19-10-00-41-1375-bba6223c8c.png)

### Vulnerabilities on a library

Get the open vulnerabilities on a specific library (in this example, `log4j`).

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



// filter by the vulnerable library/component name



AND contains(affected_entity.vulnerable_component.name,"log4j",caseSensitive:false)



// now summarize on the vulnerability level



| summarize{



vulnerability.risk.score=round(takeMax(vulnerability.risk.score),decimals:1),



vulnerability.title=takeFirst(vulnerability.title),



vulnerability.references.cve=takeFirst(vulnerability.references.cve),



last_detected=coalesce(takeMax(vulnerability.resolution.change_date),takeMax(vulnerability.parent.first_seen)),



affected_entities=countDistinctExact(affected_entity.id),



vulnerable_function_in_use=if(in("IN_USE",collectArray(vulnerability.davis_assessment.vulnerable_function_status)),true, else:false),



public_internet_exposure=if(in("PUBLIC_NETWORK",collectArray(vulnerability.davis_assessment.exposure_status)),true,else:false),



public_exploit_available=if(in("AVAILABLE",collectArray(vulnerability.davis_assessment.exploit_status)),true,else:false),



data_assets_within_reach=if(in("REACHABLE",collectArray(vulnerability.davis_assessment.data_assets_status)),true,else:false)



}, by: {vulnerability.display_id}



// map the risk level



| fieldsAdd vulnerability.risk.level=if(vulnerability.risk.score>=9,"CRITICAL",



else:if(vulnerability.risk.score>=7,"HIGH",



else:if(vulnerability.risk.score>=4,"MEDIUM",



else:if(vulnerability.risk.score>=0.1,"LOW",



else:"NONE"))))



| sort   {vulnerability.risk.score, direction:"descending"}, {affected_entities, direction:"descending"}
```

**Query result**:

![List vulnerabilities on a library](https://dt-cdn.net/images/2023-12-20-15-56-43-1762-c9da6644e4.png)

### Vulnerabilities on a host

Get the open vulnerabilities directly or indirectly affecting a specific host (in this example, `i-05f1305a50721e04d`).

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



// filter by the host name of the related/affected host



AND in("easytravel-demo2",related_entities.hosts.names) OR affected_entity.name=="easytravel-demo2"



// now summarize on the vulnerability level



| summarize{



vulnerability.risk.score=round(takeMax(vulnerability.risk.score),decimals:1),



vulnerability.title=takeFirst(vulnerability.title),



vulnerability.references.cve=takeFirst(vulnerability.references.cve),



last_detected=coalesce(takeMax(vulnerability.resolution.change_date),takeMax(vulnerability.parent.first_seen)),



affected_entities=countDistinctExact(affected_entity.id),



vulnerable_function_in_use=if(in("IN_USE",collectArray(vulnerability.davis_assessment.vulnerable_function_status)),true, else:false),



public_internet_exposure=if(in("PUBLIC_NETWORK",collectArray(vulnerability.davis_assessment.exposure_status)),true,else:false),



public_exploit_available=if(in("AVAILABLE",collectArray(vulnerability.davis_assessment.exploit_status)),true,else:false),



data_assets_within_reach=if(in("REACHABLE",collectArray(vulnerability.davis_assessment.data_assets_status)),true,else:false)



}, by: {vulnerability.display_id}



// map the risk level



| fieldsAdd vulnerability.risk.level=if(vulnerability.risk.score>=9,"CRITICAL",



else:if(vulnerability.risk.score>=7,"HIGH",



else:if(vulnerability.risk.score>=4,"MEDIUM",



else:if(vulnerability.risk.score>=0.1,"LOW",



else:"NONE"))))



| sort {vulnerability.risk.score, direction:"descending"}, {affected_entities, direction:"descending"}
```

**Query result**:

![Vulnerabilities on a host ](https://dt-cdn.net/images/2023-12-20-15-47-11-1621-799a5d1c04.png)

### Vulnerabilities on an application

Get the open vulnerabilities affecting a specific application (in this example, `www.easytravel.com`).

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



// filter by name of the related applications



AND in("www.easytravel.com",related_entities.applications.names)



// now summarize on the vulnerability level



| summarize{



vulnerability.risk.score=round(takeMax(vulnerability.risk.score),decimals:1),



vulnerability.title=takeFirst(vulnerability.title),



vulnerability.references.cve=takeFirst(vulnerability.references.cve),



last_detected=coalesce(takeMax(vulnerability.resolution.change_date),takeMax(vulnerability.parent.first_seen)),



affected_entities=countDistinctExact(affected_entity.id),



vulnerable_function_in_use=if(in("IN_USE",collectArray(vulnerability.davis_assessment.vulnerable_function_status)),true, else:false),



public_internet_exposure=if(in("PUBLIC_NETWORK",collectArray(vulnerability.davis_assessment.exposure_status)),true,else:false),



public_exploit_available=if(in("AVAILABLE",collectArray(vulnerability.davis_assessment.exploit_status)),true,else:false),



data_assets_within_reach=if(in("REACHABLE",collectArray(vulnerability.davis_assessment.data_assets_status)),true,else:false)



}, by: {vulnerability.display_id}



// map the risk level



| fieldsAdd vulnerability.risk.level=if(vulnerability.risk.score>=9,"CRITICAL",



else:if(vulnerability.risk.score>=7,"HIGH",



else:if(vulnerability.risk.score>=4,"MEDIUM",



else:if(vulnerability.risk.score>=0.1,"LOW",



else:"NONE"))))



| sort   {vulnerability.risk.score, direction:"descending"}, {affected_entities, direction:"descending"}
```

**Query result**:

![Vulnerabilities on an application](https://dt-cdn.net/images/2024-01-10-06-58-57-1719-5d67b39da3.png)

### Top 10 affected entities by vulnerability count

Get the top 10 affected entities by the number of open vulnerabilities.

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



| summarize {



`Affected entity name` = takeFirst(affected_entity.name),



Type = takeFirst(affected_entity.type),



Vulnerabilities = countDistinctExact(vulnerability.display_id)



}, by: {dt.source_entity=affected_entity.id}



| sort {Vulnerabilities, direction:"descending"}



| limit 10
```

**Query result**:

![Top 10 affected entities by vulnerability count](https://dt-cdn.net/images/2024-06-05-14-44-42-1131-5868876889.png)

### Top 10 process groups with owners

Get the top five process groups by the count of open vulnerabilities, with their respective owners.

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



AND affected_entity.type=="PROCESS_GROUP"



// summarize per process group



| summarize {



`Affected entity name` = takeFirst(affected_entity.name),



Type = takeFirst(affected_entity.type),



Vulnerabilities = countDistinctExact(vulnerability.display_id)



}, by: {dt.source_entity=affected_entity.id}



| sort {Vulnerabilities, direction:"descending"}



| limit 10



// add ownership information



| lookup [



fetch dt.entity.process_group



| parse toString(tags), "LD ('owner:'|'owner\\\\:') (SPACE)? LD:Team ('\"')"



| fields id, Team=coalesce(Team, "-")



], sourceField:dt.source_entity, lookupField:id, fields:{Team}



| sort Vulnerabilities, direction:"descending"
```

**Query result**:

![Top 10 process groups with owner teams](https://dt-cdn.net/images/2023-12-20-15-35-41-1624-fb83180f1e.png)

### Hosts related to vulnerabilities on a library with owners

Get the hosts that are indirectly related to open vulnerabilities on a specific library (in this example, `tomcat`), with their respective owners.

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



AND related_entities.hosts.count > 0



// filter by the vulnerable component name



AND contains(affected_entity.vulnerable_component.name,"tomcat")



| expand entity_id=related_entities.hosts.ids



| summarize Vulnerabilities=countDistinctExact(vulnerability.display_id), by: {entity_id}



//add ownership information



| lookup [



fetch dt.entity.host



| parse toString(tags), "LD ('owner:'|'owner\\\\:') (SPACE)? LD:Team ('\"')"



| fields id, Host=entity.name, Team=coalesce(Team, "-")



], sourceField:entity_id, lookupField:id, fields: {Host,Team}



| sort Vulnerabilities, direction:"descending"
```

**Query result**:

![Hosts related to vulnerabilities on a library with owners](https://dt-cdn.net/images/2023-12-20-15-31-09-1624-16288a4369.png)

### Vulnerable software components of a host with owners

Get the vulnerable components of a specific host (in this example, `HOST-4CF0F659B8823D74`) with owners.

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



// filter by ID of the related or affected host



AND in("HOST-DBF63A01C27E4B50",related_entities.hosts.ids) or affected_entity.id=="HOST-DBF63A01C27E4B50"



| summarize{



entities=countDistinctExact(affected_entity.id),



vulnerable_functions=arraySize(collectDistinct(affected_entity.vulnerable_functions, expand:true)),



vulnerable_component.name=takeAny(affected_entity.vulnerable_component.name)



}, by: {dt.entity.software_component=affected_entity.vulnerable_component.id}



| filterOut isNull(dt.entity.software_component)



// add component information



| lookup [



fetch dt.entity.software_component



| fieldsAdd softwareComponentFileName



], sourceField:dt.entity.software_component, lookupField:id, fields:{softwareComponentFileName}



| fields dt.entity.software_component, vulnerable_component.name, softwareComponentFileName, entities, vulnerable_functions



| sort {entities, direction:"descending"}, {vulnerable_functions, direction:"descending"}
```

**Query result**:

![Vulnerable software components of a host with owners](https://dt-cdn.net/images/2023-12-20-15-23-11-1617-9be4d95d88.png)

### Vulnerable functions of a software component

Get the vulnerable functions of a specific software component (in this example, `SOFTWARE_COMPONENT-1D466FB7ADEBF92E`).

**Query example**:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents_builtin"



AND event.provider=="Dynatrace"



AND event.type=="VULNERABILITY_STATE_REPORT_EVENT"



AND event.level=="ENTITY"



// filter for the latest snapshot per entity



| dedup {vulnerability.display_id, affected_entity.id}, sort:{timestamp desc}



// filter for open non-muted vulnerabilities



| filter vulnerability.resolution.status == "OPEN"



AND vulnerability.parent.mute.status != "MUTED"



AND vulnerability.mute.status != "MUTED"



// filter for the software component ID



AND affected_entity.vulnerable_component.id=="SOFTWARE_COMPONENT-1D466FB7ADEBF92E"



| expand vulnerable_function=affected_entity.vulnerable_functions



| filter isNotNull(vulnerable_function)



| summarize{Usages=countIf(in(vulnerable_function,affected_entity.vulnerable_functions))}, by: {vulnerable_function}



| sort {Usages, direction:"descending"}
```

**Query result**:

![Vulnerable functions of a software component](https://dt-cdn.net/images/2023-12-20-15-13-13-1623-f4c7e8d398.png)

## Query ingested events

### Total number of critical vulnerability findings

Get the total number of critical vulnerability findings ingested into Dynatrace.

**Query example**:

```
fetch security.events



| filter dt.system.bucket == "default_securityevents"



AND event.type == "VULNERABILITY_FINDING"



AND isNotNull(component.name)



// latest findings per affected object, vulnerability and component



| dedup {object.id, vulnerability.id, component.name, component.version}, sort: {timestamp desc}



// aggregation and custom filtering



| filter dt.security.risk.level=="CRITICAL"



| summarize {Vulnerabilities=countDistinctExact(vulnerability.id)}
```

**Query result**:

![critical vulnerability findings](https://dt-cdn.net/images/image-20241029-120929-1685-ab662f5f28.png)

### Total number of vulnerable container images

Get the total number of container images containing vulnerability findings ingested into Dynatrace.

**Query example**:

```
fetch security.events



| filter dt.system.bucket == "default_securityevents"



AND event.type == "VULNERABILITY_FINDING"



AND isNotNull(component.name)



// latest findings per affected object, vulnerability and component



| dedup {object.id, vulnerability.id, component.name, component.version,



container_image.registry, container_image.repository, container_image.tags}, sort: {timestamp desc}



// aggregation and custom filtering



| summarize {containerImages=countDistinctExact(container_image.digest)}
```

**Query result**:

![vulnerable container images](https://dt-cdn.net/images/image-20241029-121235-1638-d550a4b6bc.png)

### Total number of vulnerable components

Get the total number of vulnerable components in the container images containing vulnerability findings ingested into Dynatrace.

**Query example**:

```
fetch security.events



| filter dt.system.bucket == "default_securityevents"



AND event.type == "VULNERABILITY_FINDING"



AND isNotNull(component.name)



// latest findings per affected object, vulnerability and component



| dedup {object.id, vulnerability.id, component.name, component.version}, sort: {timestamp desc}



// aggregation and custom filtering



| summarize {components=countDistinctExact(component.name)}
```

**Query result**:

![vulnerable components](https://dt-cdn.net/images/image-20241029-121220-1684-5eeb70313e.png)

### Most recent vulnerability findings

Get the most recent vulnerability findings ingested into Dynatrace.

**Query example**:

```
fetch security.events



// data access



| filter dt.system.bucket == "default_securityevents"



AND event.type == "VULNERABILITY_FINDING"



AND isNotNull(component.name)



// latest findings per affected object, vulnerability and component



| dedup {object.id, vulnerability.id, component.name, component.version}, sort: {timestamp desc}



| sort timestamp desc
```

**Query result**:

![most recent vulnerability findings](https://dt-cdn.net/images/censored3-20241029-145107-1685-c8bb339c99.png)

### Number of scanned container images

Get the total number of ingested container images that have been scanned.

**Query example**:

```
fetch security.events



| filter dt.system.bucket == "default_securityevents"



| filter object.type == "CONTAINER_IMAGE" // includes both SCAN_EVENTS and VULNERABILITY_FINDINGS without scan events



| dedup {container_image.digest}, sort: {timestamp desc}



| summarize {containerImages=count()}
```

**Query result**:

![Number of scanned container images](https://dt-cdn.net/images/image-20241029-121426-1980-ef745c8257.png)

### Number of container image scan events

Get the total number of scan events from ingested container images.

**Query example**:

```
fetch security.events



| filter dt.system.bucket == "default_securityevents"



| filter event.type == "VULNERABILITY_SCAN"



AND object.type == "CONTAINER_IMAGE"



| summarize {scanEvents=count()}
```

**Query result**:

![Number of container image scan events](https://dt-cdn.net/images/image-20241029-121224-1605-37798c4a10.png)

## Query compliance events

### Latest results for all covered systems

Get the latest compliance results of supported standards for all systems [covered by Security Posture Management](/docs/secure/xspm/assess-coverage#coverage "Review the Security Posture Management coverage of your systems at a glance.").

**Query example**:

```
fetch security.events



| filter dt.system.bucket == "default_securityevents_builtin"



AND event.type == "COMPLIANCE_SCAN_COMPLETED"



// filter for the latest assessment



| dedup {object.name}, sort:{timestamp desc}



// parse the compliance percentage from json



| parse `scan.result.summary_json`, """JSON{JSON_ARRAY{JSON{ STRING:standardCode, INT:compliancePercentage }}:standardResultSummaries}(flat=true)"""



| expand standardResultSummaries



| fieldsFlatten standardResultSummaries



| fields timestamp, object.name, standard = standardResultSummaries.standardCode, compliance = standardResultSummaries.compliancePercentage
```

**Query result**:

![Latest results for all covered systems](https://dt-cdn.net/images/2024-11-19-12-00-23-976-c026b0abd7.png)

### Historical compliance results for a standard for all covered systems

Get the historical compliance results for a standard (in this case, DORA) for all systems [covered by Security Posture Management](/docs/secure/xspm/assess-coverage#coverage "Review the Security Posture Management coverage of your systems at a glance.").

**Query example**:

```
fetch security.events



| filter dt.system.bucket == "default_securityevents_builtin"



AND event.type == "COMPLIANCE_SCAN_COMPLETED"



// parse the compliance percentage from json



| parse `scan.result.summary_json`, """JSON{JSON_ARRAY{JSON{ STRING:standardCode, INT:compliancePercentage }}:standardResultSummaries}(flat=true)"""



| expand standardResultSummaries



| fieldsFlatten standardResultSummaries



// filter for the specific standard



| filter standardResultSummaries.standardCode == "DORA"



| fields timestamp, object.name, standardResultSummaries.compliancePercentage
```

**Query result**:

![Historical compliance results of DORA standard for all covered systems](https://dt-cdn.net/images/2024-11-19-12-04-14-1722-f64d652cf3.png)

### Latest analysis results for a system in a selected timeframe

Get the latest analysis results for a given system in a selected timeframe.

This results in a view similar to that displayed in ![xSPM](https://dt-cdn.net/images/security-posture-management-highresolution-1024-83a748ecdd.png "xSPM") **Security Posture Management** on the **Assessment results** page.

**Query example**:

```
fetch security.events



| filter dt.system.bucket == "default_securityevents_builtin"



AND event.type == "COMPLIANCE_FINDING"



// filter for the latest rule assessment results in the timeframe



| join [



fetch security.events



| filter dt.system.bucket == "default_securityevents_builtin"



AND event.type == "COMPLIANCE_SCAN_COMPLETED"



// filter for desired system



AND object.name == "demo-kspm"



| dedup object.name, sort: { timestamp desc }



| fields scan.id



], on: {scan.id}



// summarize findings on rule level



| summarize {



compliance.rule.severity.level = takeFirst(compliance.rule.severity.level),



compliance.standard.short_name = takeFirst(compliance.standard.short_name),



compliance.rule.title = takeFirst(compliance.rule.title),



compliance.standard.url = takeFirst(compliance.standard.url),



finding.time.created = takeFirst(finding.time.created),



compliance.result.count.passed = countIf(compliance.result.status.level == "PASSED"),



compliance.result.count.failed = countIf(compliance.result.status.level == "FAILED"),



compliance.result.count.manual = countIf(compliance.result.status.level == "MANUAL"),



compliance.result.count.not_relevant = countIf(compliance.result.status.level == "NOT_RELEVANT"),



compliance.rule.metadata_json = takeFirst(compliance.rule.metadata_json)



},



by: { compliance.rule.id }



// add rule level status



| fieldsAdd compliance.result.status.level =



if(compliance.result.count.failed > 0, "FAILED",



else: if(compliance.result.count.manual > 0, "MANUAL",



else: if(compliance.result.count.passed > 0, "PASSED",



else: "NOT_RELEVANT"



)))



| filterout compliance.result.status.level == "NOT_RELEVANT"
```

**Query result**:

![Latest analysis results for a given system in selected timeframe](https://dt-cdn.net/images/2025-09-15-15-02-36-1813-5461c4173d.png)

### Historical assessment results for selected rule and system

Get the counts for every assessment that happened in a selected period for a selected rule and system (in this case, `dt-cluster-01`).

**Query example**:

```
fetch security.events



| filter dt.system.bucket == "default_securityevents_builtin"



AND event.type == "COMPLIANCE_FINDING"



AND k8s.cluster.name == "dt-cluster-01"



// filter for the specific rule



AND compliance.rule.id == "DORA-67950"



// summarize findings on rule level



| summarize {



timestamp = takeFirst(timestamp),



Passed=countIf(compliance.result.status.level == "PASSED"),



Failed=countIf(compliance.result.status.level == "FAILED"),



Manual=countIf(compliance.result.status.level == "MANUAL")



}, by: {scan.id}



| makeTimeseries avg(Passed), avg(Failed), avg(Manual)
```

**Query result**:

![Historical assessment results for selected rule and system](https://dt-cdn.net/images/2024-11-22-10-22-05-1705-07ef87b89d.png)

### Latest misconfigurations of the object according to a specific standard

Get the counts of the latest misconfigurations of the object (in this case, `ip-10-45-243-57`) for a specific standard (in this case, CIS).

**Query example**:

```
fetch security.events



| filter dt.system.bucket == "default_securityevents_builtin"



AND event.type == "COMPLIANCE_FINDING"



// filter for desired object



AND object.name == "ip-10-45-243-57"



// filter for compliance findings reporting misconfigurations



AND compliance.result.status.level == "FAILED"



// filter for the specific standard



AND compliance.standard.short_name == "CIS"



// filter for the latest rule assessment results in the timeframe



| join [



fetch security.events



| filter dt.system.bucket == "default_securityevents_builtin"



AND event.type == "COMPLIANCE_SCAN_COMPLETED"



// filter for desired system



AND object.name == "demo-kspm"



| dedup object.name, sort: { timestamp desc }



| fields scan.id



], on: {scan.id}
```

**Query result**:

![Latest misconfigurations for a specific standard](https://dt-cdn.net/images/dql-324-v2-1979-c103989603.png)


---


## Source: migration.md


---
title: Grail security table migration guide
source: https://www.dynatrace.com/docs/secure/threat-observability/migration
scraped: 2026-02-17T21:30:20.717653
---

# Grail security table migration guide

# Grail security table migration guide

* Latest Dynatrace
* How-to guide
* Updated on Sep 23, 2025

Dynatrace introduces a new `security.events` table in [Grail](/docs/platform/grail "Insights on what and how you can query Dynatrace data."), improving how security event data is consumed, stored, and queried. This guide explains the benefits, access control adjustments, ingestion and query changes, and required user actions.

The migration to the new `security.events` table is expected to be completed by the end of December 2025. To prevent any disruptions in your workflows, please ensure your migration is finalized before this deadline.

Refer to this guide for detailed instructions on completing the transition.

## Why migrate?

The new `security.events` table enhances security data management with:

* **Simpler security event queries** â You can directly retrieve security events with the `fetch security.events` command (see [DQL examples for security data](/docs/secure/threat-observability/dql-examples "DQL examples for security data powered by Grail.")).
* **No-code query support** â Dashboards and notebooks enable security event analysis via user-friendly filters, requiring no previous DQL knowledge (see [Explore security events](/docs/analyze-explore-automate/dashboards-and-notebooks/explore-data#explore-security-events "Explore your data with our point-and-click interface.")).
* **Stronger access control** â Separate permissions ensure table-level and record-level security without impacting other event tables (see [Permissions in Grail](/docs/platform/grail/organize-data/assign-permissions-in-grail "Find out how to assign permissions to buckets and tables in Grail.")).
* **Improved query performance** â Queries only scan security events, reducing complexity and improving efficiency.
* **Enhanced data ingestion** â Supports native nested JSON and introduces dedicated fields for raw event data access.

## Whatâs changing and what you need to do

With the introduction of the `security.events` table, some updates take place automatically, while others require manual action. See below for an overview.

### Automatic updates

* **Default data access policies** â Updated to include security events.
* **Dynatrace-generated security events** â Written to old and new tables until the migration is complete.
* **Dynatrace-provided processors and pipelines** â Will be migrated and will work seamlessly with the new ingest scope.
* **![Dashboards](https://dt-cdn.net/images/dashboards-512-b1f1e9690b.png "Dashboards") **Dashboards**, ![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**, ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows**, and ready-made documentation samples** â Adjusted to query the new security events table.

### Manual updates required

* **Custom access policies** â Update manually to grant permissions for the new `security.events` table (see [Access control updates](#access)).
* **Third-party product ingest URLs** â Change the ingest endpoint from `/events.security` to `/security.events` (see [Data ingestion updates](#data)).
* **Custom processing pipelines** â Manually migrate sources via ![Settings](https://dt-cdn.net/images/settings-icon-256-38e1321b51.webp "Settings") **Settings** > **Process and contextualize** > **OpenPipeline** > **Security events** (see [Data ingestion updates](#data)).
* **Custom queries** â Modify DQL queries to reference `security.events` instead of `events` (see [DQL query updates](#query)).
* **Migrating the connections for the integration apps/extensions** - If you've already installed and configured [security integrations](/docs/secure/threat-observability/security-events-ingest#ingest "Ingest external security data into Grail."), you need to do one of the following:

  + Reconfigure the third-party URL to point to `/security.events`. This allows existing connections to continue working and display data from the new table.
  + Recreate the connections and follow the on-screen setup instructions, which already include the updated endpoint.

## Access control updates

* (Automatic) Default access policies are automatically updated:

  + `All Grail data read access` â Read all Grail data, including security events.
  + `Read Security Events` â Read security events only.
  + `OpenPipeline Ingest` â Continue ingesting security events using existing permissions.
* (Manual) Custom policies require manual changes:

  + New:

    ```
    // previous security events within the events data table



    ALLOW storage:buckets:read WHERE storage:bucket-name IN ("default_security_events", "default_security_custom_events");



    ALLOW storage:events:read;



    // new table permissions



    ALLOW storage:buckets:read WHERE storage:table-name = 'security.events';



    ALLOW storage:security.events:read;
    ```
  + Previously:

    ```
    ALLOW storage:buckets:read WHERE storage:bucket-name IN ("default_security_events", "default_security_custom_events");



    ALLOW storage:events:read;
    ```
* (Manual) For more granular access control, use the new buckets:

  + Read Dynatrace-generated events:

    - New: `default_securityevents_builtin`
    - Previously: `default_security_events`
  + Read externally ingested events:

    - New: `default_securityevents`
    - Previously: `default_security_custom_events`

## Data ingestion updates

Dynatrace-generated events are stored in both the legacy and new tables until migration is complete. However, [Kubernetes Security Posture Management](/docs/ingest-from/setup-on-k8s/deployment/security-posture-management "Configure and enable Security Posture Management in Kubernetes.")-related events are no longer duplicated and are now available exclusively in the new `security.events` table. All other Dynatrace-generated events continue to be written to both tables during the migration period.

* (Automatic) Dynatrace-provided processors and pipelines work seamlessly with the new ingestion scope.
* (Manual) Update third-party product ingest URLs:

  + Default pipeline:

    - New: `/platform/ingest/v1/security.events`
    - Previously: `/platform/ingest/v1/events.security`
  + Custom pipeline:

    - New: `/platform/ingest/v1/security.events/<custom_ingest_source>`
    - Previously: `/platform/ingest/v1/events.security/<custom_ingest_source>`

    Example new default and custom pipelines

    New default and custom pipelines via **Settings** > **Process and contextualize** > **OpenPipeline** > **Security events (New)**:

    ![settings-openpipeline-security-events](https://dt-cdn.net/images/custom-settings-openpipeline-security-events-3382-de1282230f.png)
* (Manual) Migrate custom ingest sources via ![Settings](https://dt-cdn.net/images/settings-icon-256-38e1321b51.webp "Settings") **Settings** > **Process and contextualize** > **OpenPipeline** > **Security events**.
* (Manual) Copy over and adjust, if required, the existing custom processors in your custom pipelines into the new `security.events` OpenPipeline ingest scope.

## DQL query updates

* (Automatic) ![Dashboards](https://dt-cdn.net/images/dashboards-512-b1f1e9690b.png "Dashboards") **Dashboards**, ![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**, ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows**, and ready-made documentation samples delivered with Dynatrace apps and extensions now reference `security.events`.
* (Automatic) The pre-built queries in Dynatrace apps are updated automatically where applicable.
* (Manual) Update your custom queries in ![Dashboards](https://dt-cdn.net/images/dashboards-512-b1f1e9690b.png "Dashboards") **Dashboards**, ![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**, and ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows** to fetch from `security.events` instead of `events`.

  + To query only recent data, switch completely to querying `security.events`.
  + To query both historical and new security events, modify queries to fetch from both tables.
  + To query only historical data, you can continue using the old queries.

  To bulk-update multiple queries in ![Dashboards](https://dt-cdn.net/images/dashboards-512-b1f1e9690b.png "Dashboards") **Dashboards**, ![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**, or ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows**, download the document JSON file and use a text editor for find and replace actions.

### Example query updates

#### Query all security events

* New:

```
fetch security.events
```

* Previously:

```
fetch events | filter event.kind == "SECURITY_EVENT"
```

#### Query Dynatrace-generated events

* New:

```
fetch security.events | filter dt.system.bucket=="default_securityevents_builtin"
```

* Previously:

```
fetch events | filter dt.system.bucket=="default_security_events"
```

#### Query ingested events

* New:

```
fetch security.events | filter dt.system.bucket=="default_securityevents"
```

* Previously:

```
fetch events | filter dt.system.bucket=="default_security_custom_events"
```

#### Query ingested events in both old and new security event tables

```
// Fetch all migrated security events



fetch security.events



| filter dt.system.bucket!="default_securityevents_builtin"



| append [



// Fetch all security events that were not migrated



fetch events



| filter event.kind == "SECURITY_EVENT"



// Exclude the by Dynatrace generated security events as they are written in both tables



| filter dt.system.bucket!="default_security_events"



]
```


---


## Source: abuseipdb-enrich.md


---
title: Enrich threat observables with AbuseIPDB
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/abuseipdb-enrich
scraped: 2026-02-17T21:17:31.266097
---

# Enrich threat observables with AbuseIPDB

# Enrich threat observables with AbuseIPDB

* Latest Dynatrace
* How-to guide
* Updated on Jan 07, 2026

Enrich threat observables with AbuseIPDB and analyze them in Dynatrace.

## Get started

### Overview

The Dynatrace integration with [AbuseIPDBï»¿](https://www.abuseipdb.com/) enhances alerts and detection investigations by providing valuable context for threat intelligence. This helps organizations combat online abuse, including cyber-attacks, spamming, and other malicious activities.

By enriching observability with reputation data from AbuseIPDB, you can conduct more efficient security investigations, automate alert triaging, and reduce noise through threat-aware prioritization. This streamlines incident response and enhances overall security posture.

### Use cases

Once you set up the AbuseIPDB integration, you can leverage threat intelligence to enrich observables like IP addresses.

Key use cases include:

* [Accelerate threat validation and streamline case triage in ![Investigations](https://dt-cdn.net/images/security-investigator-256-93f6c187d9.png "Investigations") **Investigations** with external reputation data](/docs/secure/investigations/enhance-results#enrich "Organize and interpret query outputs across investigations --- from performance analysis to threat detection.").
* [Enhance detection findings in ![Threats & Exploits](https://dt-cdn.net/images/attacks-512-b922840b12.png "Threats & Exploits") **Threats & Exploits** with external reputation data](/docs/secure/threats-and-exploits/manage-results#enrich "Filter, format, and sort detection findings.").
* IP enrichment with the Workflows app

  1. In [![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows**](/docs/analyze-explore-automate/workflows "Automate IT processes with Dynatrace Workflowsâreact to events, schedule tasks, and connect services.") ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows"), create a new workflow or edit an existing one.
  2. In the **Choose action** pane, search for **AbuseIPDB** and select the **AbuseIPDB check IP** action.
  3. Enter the parameters required for the action to run.
  4. Run the workflow to validate the action and review the results.
  5. Continue with your automation definition.

  ![workflow sample](https://dt-cdn.net/images/image-51-2526-e747d4a5ee.png)
* [Automated threat-alert triaging](/docs/secure/use-cases/automated-threat-alert-triaging "Use case scenario for automating threat-alert triaging with Dynatrace.")
* Threat-informed security investigations Coming soon

### Requirements

See below for the [AbuseIPDB](#abuseipdb) and [Dynatrace](#dt) requirements.

#### AbuseIPDB requirements

Register with AbuseIPDB and create an API v2 key.

#### Dynatrace requirements

The following IAM permissions are required:

* `app-engine:apps:run`
* `app-settings:objects:read`
* `document:documents:read`
* `settings:objects:read`
* `storage:system:read`
* `security-intelligence:enrichments:run`

To run the enrichment workflow action, all the permissions above need to be enabled in ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows** as well.

1. Go to the settings menu  in the upper-right corner of ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows** and select **Authorization settings**.
2. In **Secondary permissions**, search for and select the above-listed permissions.
3. Select **Save**.

## Activation and setup

1. In Dynatrace, open  [**Hub**](/docs/manage/hub "See the information about Dynatrace Hub.").
2. Look for **AbuseIPDB** and select **Install**.
3. Select **Set up** , then select  **Configure new connection**.
4. Follow the on-screen instructions to set up the connection using the API key obtained in **Prerequisites**.

   Allowed outbound connections are extended automatically with `api.abuseipdb.com`.

   How to set up outbound connections

   1. In **Settings**, go to **Preferences** > **Limit Outbound Connections**.
   2. Select **Add item** and add the domain.
   3. Select **Save changes**.
5. Test the connection to ensure the correct configuration and save it.

## Details

### How it works

![abuseipdb mechanism](https://dt-cdn.net/images/image-20250325-091933-2537-ee7bd898c5.png)

1. Install and configure the app

Dynatrace integration with AbuseIPDB is an app that you can install from  [**Hub**](/docs/manage/hub "See the information about Dynatrace Hub.").

The app delivers a workflow action for observable enrichment in ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows**.

To prevent accidental edits or deletions across environments, connection setup now includes owner-based access control. This ensures reliable automation, avoids unexpected configuration loss, and aligns with minimal access requirements.

For details on sharing and permissions, see [Access control for Connectors](/docs/analyze-explore-automate/workflows/actions/access-control "Display, view, create, and share connections for Dynatrace Connectors.").

2. Enrich observables

Various consumer apps can perform an on-demand enrichment of observables, for example, via a [workflow action](#workflow).

Dynatrace reaches out to AbuseIPDB to perform the observable enrichment.

Geolocation fields in enrichment results are sourced from the provider and can differ from the geolocation used in Dynatrace.  
For more information, see [FAQ: Geolocation differences](#ti-geo).

3. Use the threat intelligence data

The threat intelligence context is displayed within the consumer apps or in ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows**, helping you drive smarter decisions.

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## FAQ

### Which observable types are currently supported?

Supported observables: IP addresses (more coming soon).

### How will my AbuseIPDB API quotas will be affected from this integration?

For every new observable enrichment we perform a single API call.

### Why does geolocation differ between enrichment results and Dynatrace?

Geolocation fields in enrichment results (such as `geo.country.iso_code`, `geo.country.name`, and city/coordinates if available) are provided directly by the external provider (in this case, AbuseIPDB).

These values reflect the AbuseIPDB geolocation data and may differ from the geolocation used in Dynatrace features (such as Real User Monitoring or platformâlevel geolocation).

Differences can occur because of different databases, update cycles, or mapping rules.

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Enrich observables with threat intelligence from AbuseIPDB.](https://www.dynatrace.com/hub/detail/abuseipdb)


---


## Source: ingest-akamai.md


---
title: Ingest Akamai security logs and events
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-akamai
scraped: 2026-02-17T21:17:40.580012
---

# Ingest Akamai security logs and events

# Ingest Akamai security logs and events

* Latest Dynatrace
* Extension
* Updated on Aug 25, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest Akamai security logs and events into Dynatrace as security events.

## Get started

### Overview

Dynatrace integration with [Akamaiï»¿](https://dt-url.net/3403xsr) allows you to unify and contextualize security findings across tools and products, enabling central prioritization, visualization, and automation.

Akamai products generate security events and detect suspicious network activity. Dynatrace observes the runtime entities protected by those products. Ingesting security events from Akamai products helps users analyze those logs and findings in the context of their runtime production environments.

### Use cases

With the ingested data, you can accomplish various use cases, such as

* [Visualize and analyze security findings](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.")
* [Automate and orchestrate security findings](/docs/secure/use-cases/automate-and-orchestrate-security-findings "Regularly check for critical security findings and get automatic Jira tickets or Slack alerts.")
* Evaluate, triage, and investigate detection findings with [![Threats & Exploits](https://dt-cdn.net/images/attacks-512-b922840b12.png "Threats & Exploits") **Threats & Exploits**](/docs/secure/threats-and-exploits "Understand, triage, and investigate detection findings and alerts.")
* Analyze network logs and detections Coming soon

### Requirements

See below for the [Akamai](#akamai) and [Dynatrace](#dt) requirements.

#### Akamai requirements

[Create authentication credentials with the proper permissionsï»¿](https://dt-url.net/0gg3xvi)

#### Dynatrace requirements

* ActiveGate version 1.300+
* Permissions:

  + To run ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**: Go to  **Hub**, select ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**, and display **Technical information**.
  + To query ingested logs: `storage:logs:read`.
  + Optional To query the extracted security events: `storage:security.events:read`.
* Tokens:

  + Generate an access token with the `openpipeline.events_security` scope and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").

## Activation and setup

1. In Dynatrace, search for **Akamai** and select **Install**.
2. Follow the on-screen instructions to configure the extension.
3. Verify configuration by running the following queries in [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace."):

   * For security logs:

     ```
     fetch logs



     | filter log.source=="Akamai SIEM"
     ```
   * For finding events (if you configured the extension to extract detection events):

     ```
     fetch security.events



     | filter dt.system.bucket == "default_securityevents"



     | filter event.provider=="Akamai"
     ```
4. Once the extension is installed and working, you can access and manage it in Dynatrace via ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**. For details, see [About Extensions](/docs/ingest-from/extensions/concepts "Learn more about the concept of Dynatrace Extensions.").

## Details

### How it works

![how it works](https://dt-cdn.net/images/image-20250212-154515-3094-1f68916ee3.png)

Dynatrace integration with Akamai is an [extension](/docs/ingest-from/extensions "Learn how to create and manage Dynatrace Extensions.") running on Dynatrace ActiveGate. Once you enable and configure the Dynatrace Akamai extension

1. It periodically reaches out to [Akamai SIEM APIï»¿](https://dt-url.net/wbe3xyb) and fetches the security events.
2. The raw data is ingested into Dynatrace as logs. If security event extraction is configured, detection events are ingested in addition to the logs mapped to the [Dynatrace Semantic Dictionaryï»¿](https://dt-url.net/z1c3xsm).
3. Data is stored as follows:

   * Logs are stored in the `default_logs` bucket
   * Security events are stored in the `default_securityevents` bucket

   For details, see [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.").

#### Additional integrations

In addition to the extension, you have the following integration options:

* [Monitor application performance with mPulse integration of Dynatrace metricsï»¿](https://dt-url.net/p1i3xuc)
* [Stream Akamai transactional events and metrics via DataStream 2 into Dynatraceï»¿](https://dt-url.net/zek3xcv)

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## Feature sets

When activating your extension using [monitoring configuration](#monitoring-configuration), you can limit monitoring to one of the feature sets. To work properly, the extension has to collect at least one metric after the activation.

In highly segmented networks, feature sets can reflect the segments of your environment. Then, when you create a monitoring configuration, you can select a feature set and a corresponding ActiveGate group that can connect to this particular segment.

All metrics that aren't categorized into any feature set are considered to be the default and are always reported.

A metric inherits the feature set of a subgroup, which in turn inherits the feature set of a group. Also, the feature set defined on the metric level overrides the feature set defined on the subgroup level, which in turn overrides the feature set defined on the group level.

self-monitoring

| Metric name | Metric key | Description |
| --- | --- | --- |
| Ingested logs | sfm.akamai-siem.ingested.logs | The number of log records ingested by the extension. |
| Ingested logs bytes | sfm.akamai-siem.ingested.logs\_bytes | The volume of bytes ingested by the extension as logs. |
| Ingested security events | sfm.akamai-siem.ingested.security\_events | The number of security events ingested by the extension. |
| Ingested security events bytes | sfm.akamai-siem.ingested.security\_events\_bytes | The volume of bytes ingested by the extension as security events. |

## FAQ

### Which data model is used for the security logs and events coming from Akamai SIEM integration?

* [Logs](/docs/semantic-dictionary/model/log "Get to know the Semantic Dictionary models related to Log Analytics.") - all the Akamai SIEM data is ingested as logs. The log follows the basic schema for logs with a few relevant extensions of namespaces, such as [`geo`](/docs/semantic-dictionary/fields#geolocation "Get to know the list of global fields that have a well defined semantic meaning in Dynatrace and can be used across different monitoring types."), [`http`](/docs/semantic-dictionary/fields#http "Get to know the list of global fields that have a well defined semantic meaning in Dynatrace and can be used across different monitoring types."), and [`url`](/docs/semantic-dictionary/fields#url "Get to know the list of global fields that have a well defined semantic meaning in Dynatrace and can be used across different monitoring types.").
* [Detection finding events](/docs/semantic-dictionary/model/security-events#detection-finding-events "Get to know the Semantic Dictionary models related to security events.")

### Which extension fields are added on top of the core fields of the events ingested from Akamai?

* The [`geo`](/docs/semantic-dictionary/fields#geolocation "Get to know the list of global fields that have a well defined semantic meaning in Dynatrace and can be used across different monitoring types.") namespace maps the corresponding geolocation information of the actor detected in the log.
* The [`http`](/docs/semantic-dictionary/fields#http "Get to know the list of global fields that have a well defined semantic meaning in Dynatrace and can be used across different monitoring types.") namespace maps the corresponding HTTP request fields from the monitored transaction.
* The [`url`](/docs/semantic-dictionary/fields#url "Get to know the list of global fields that have a well defined semantic meaning in Dynatrace and can be used across different monitoring types.") namespace maps the corresponding web application/URL accessed as the target of the monitored transaction.
* The `akamai` namespace extracts several Akamai-specific fields for user convenience on top of the original JSON content, which is stored in the `log.content` field.

Some extracted fields from which you can benefit include:

* `akamai.config.id`
* `akamai.attackdata.*`

### Which metrics are extracted automatically with the Akamai extension?

| Metric key | Description |
| --- | --- |
| `log.akamai-siem.volumetric-activity` | The count of events matching volume-based activity, such as request rates exceeded or DoS attacks. |
| `log.akamai-siem.deny_count` | The count of events where the rule action is to block the request (deny). |
| `log.akamai-siem.alert_count` | The count of events where the rule action is to allow the request and log a warning (alert). |
| `log.akamai-siem.monitor_count` | The count of events with monitor rule action type. |
| `log.akamai-siem.total-events` | The total number of events processed from Akamai SIEM, regardless of attack type or severity. |
| `log.akamai-siem.slow-posts` | The count of events matching a slow POST attack, which tries to tie up the site using extremely slow requests and responses. |
| `log.akamai-siem.targeted-web-attacks` | The count of events matching specialized web app attacks such as SQL, PHP, command injections, and cross-site scripting. |
| `log.akamai-siem.generic-web-attacks` | The count of events matching generic web app attacks. These include keywords such as `Trojan`, `Web attack tool`, `Web protocol attack`, and `Web platform attack`. |

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Ingest logs and security events from Akamai products.](https://www.dynatrace.com/hub/detail/akamai)

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-amazon-guardduty.md


---
title: Ingest Amazon GuardDuty security findings
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-amazon-guardduty
scraped: 2026-02-17T21:17:26.093040
---

# Ingest Amazon GuardDuty security findings

# Ingest Amazon GuardDuty security findings

* Latest Dynatrace
* How-to guide
* Updated on Aug 25, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest Amazon GuardDuty security findings and analyze them in Dynatrace.

## Get started

### Overview

Dynatrace integration with [Amazon GuardDutyï»¿](https://dt-url.net/2h03zvk) allows you to unify and contextualize security findings across tools and products, enabling central prioritization, visualization, and automation.

GuardDuty detects suspicious activities in your AWS accounts, workloads, and data. The Dynatrace platform observes the runtime entities related to those AWS resources. Ingesting the detection findings from GuardDuty helps you analyze them in the context of their production apps.

### Use cases

With the ingested data, you can accomplish various use cases, such as

* [Visualize and analyze security findings](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.")
* [Automate and orchestrate security findings](/docs/secure/use-cases/automate-and-orchestrate-security-findings "Regularly check for critical security findings and get automatic Jira tickets or Slack alerts.")

### Requirements

See below for the [Amazon GuardDuty](#aws) and [Dynatrace](#dt) requirements.

#### Amazon GuardDuty requirements

* Install and configure the [latest AWS CLIï»¿](https://dt-url.net/uf03pcx).
* Select the AWS region where you want to create the event forwarder.

  Show me how

  1. In a terminal, run:

     ```
     aws configure
     ```
  2. Set your default region (for example, `us-east-1`).

#### Dynatrace requirements

* Permissions:

  + To query ingested data: `storage:security.events:read`.
* Tokens:

  + Generate an access token with the `openpipeline.events_security` scope and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").

## Activation and setup

1. In Dynatrace, open  [**Hub**](/docs/manage/hub "See the information about Dynatrace Hub.").
2. Look for **Amazon GuardDuty** and select **Install**.
3. Select **Set up**, then select  **Configure new connection**.
4. Follow the on-screen instructions to set up the ingestion.

## Details

### How it works

![guardduty](https://dt-cdn.net/images/image-20250327-102449-2454-96b81169b5.png)

1. Events are ingested into Dynatrace

1. Amazon GuardDuty events are sent to [Amazon EventBridgeï»¿](https://dt-url.net/qi03wtk), which triggers an AWS Lambda function.
2. The Lambda function pre-processes the events and sends them to Dynatrace via a dedicated [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.") security ingest endpoint.

2. Security findings are processed and stored in Grail

1. The OpenPipeline ingest endpoint processes and maps the data according to the [Semantic Dictionary conventionsï»¿](https://dt-url.net/3q03pb0).
2. Data is stored in a bucket called `default_securityevents` (for details, see: [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.")).

### Monitor data

Once you ingest your Amazon GuardDuty data into Grail, you can monitor your data in the app (in Dynatrace, go to **Settings** > **Amazon GuardDuty**).

![guardduty](https://dt-cdn.net/images/2025-05-27-09-26-29-1431-96bb80a495.png)

You can view

* A chart of ingested data from all existing connections over time

  + Available actions: [Query ingested data](#query)
* A table with information about your connections

  + Available actions: [Delete connection](#remove)

### Visualize and analyze findings

You can create your own [dashboards](/docs/analyze-explore-automate/dashboards-and-notebooks/dashboards-new "Create interactive, customizable views to visualize, analyze, and share your observability data in real time.") or use our templates to visualize and analyze container vulnerability findings.

1. In Dynatrace, go to **Settings** > **Amazon GuardDuty**.
2. In the **Try our templates** section, select the desired dashboard template.

### Automate and orchestrate findings

You can create your own [workflows](/docs/analyze-explore-automate/workflows "Automate IT processes with Dynatrace Workflowsâreact to events, schedule tasks, and connect services.") or use our templates to automate and orchestrate container vulnerability findings.

1. In Dynatrace, go to **Settings** > **Amazon GuardDuty**.
2. In the **Try our templates** section, select the desired workflow template.

### Query ingested data

You can query ingested data in [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace.") or [![Investigations](https://dt-cdn.net/images/security-investigator-256-93f6c187d9.png "Investigations") **Investigations**](/docs/secure/investigations "Combine Grail functionalities for evidence-driven investigations, including incident resolution, root cause analysis, and threat hunting."), using the data format in [Semantic Dictionaryï»¿](https://dt-url.net/3q03pb0).

1. In Dynatrace, go to **Settings** > **Amazon GuardDuty**.
2. Select **Open with** .
3. Select **Investigations** or **Notebooks**.

### Evaluate, triage, and investigate detection findings

You can evaluate, triage, and investigate detection findings with [![Threats & Exploits](https://dt-cdn.net/images/attacks-512-b922840b12.png "Threats & Exploits") **Threats & Exploits**](/docs/secure/threats-and-exploits "Understand, triage, and investigate detection findings and alerts.").

1. In Dynatrace, open ![Threats & Exploits](https://dt-cdn.net/images/attacks-512-b922840b12.png "Threats & Exploits") **Threats & Exploits**.
2. Filter for **Provider** > **Amazon GuardDuty**.

### Delete connections

To stop sending events to Dynatrace

1. In Dynatrace, go to **Settings** > **Amazon GuardDuty**.
2. For the connection you want to delete, select  **Delete**.
3. Follow the on-screen instructions to delete the resources. If you used values different from those specified in the setup dialog, adjust them accordingly.

This removes the Dynatrace resources created for this integration.

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## FAQ

### Which data model is used for the security logs and events coming from Amazon GuardDuty?

[Detection finding events](/docs/secure/threat-observability/concepts#detection "Basic concepts related to Threat Observability") store the individual detection findings per affected object represented by an AWS resource.

### Which extension fields are added on the events ingested from Amazon GuardDuty?

The `aws` namespace is added to store AWS-related information with the following fields:

* `aws.account.id`
* `aws.region`
* `aws.availability_zone`
* `aws.resource.type`
* `aws.resource.name`

### What Amazon GuardDuty resource types are supported by Dynatrace for runtime contextualization?

`CONTAINER`: All the detection findings with a container as the target resource are classified as `CONTAINER` in `object.type`, and the container namespace is added with the corresponding fields:

* `container.id`
* `container.name`
* `container.image.name`
* `container.image.version`

### How do we normalize the risk score for Amazon GuardDuty findings?

Dynatrace normalizes severity and risk scores for all findings ingested through the current integration. This helps you to prioritize findings consistently, regardless of their source.  
For details on how normalization works, see [Severity and score normalization](/docs/secure/threat-observability/concepts#normalization "Basic concepts related to Threat Observability").

* `dt.security.risk.level` is mapped from the severity level determined by Amazon GuardDuty mapping of the severity score (`detail.severity`).
* `dt.security.risk.score` is mapped directly from the severity score (`detail.severity`) set by Amazon GuardDuty.

| `dt.security.risk.level` (mapped from `finding.severity`) | `dt.security.risk.score` (mapped from `finding.score`) |
| --- | --- |
| CRITICAL -> CRITICAL | 9.0-10.0 |
| HIGH -> HIGH | 7.00-8.9 |
| MEDIUM -> MEDIUM | 4.0-6.9 |
| LOW -> LOW | 1.0-3.9 |

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Ingest Amazon GuardDuty detection findings.](https://www.dynatrace.com/hub/detail/amazon-guardduty)

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-aws-ecr-data.md


---
title: Ingest Amazon ECR container vulnerability findings and scan events
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-aws-ecr-data
scraped: 2026-02-17T21:17:35.317985
---

# Ingest Amazon ECR container vulnerability findings and scan events

# Ingest Amazon ECR container vulnerability findings and scan events

* Latest Dynatrace
* How-to guide
* Updated on Aug 25, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest Amazon ECR container image vulnerability findings and scan events and analyze them in Dynatrace.

## Get started

### Overview

In the following, you'll learn how to ingest container vulnerability findings and scan events from [AWS Elastic Container Registry (ECR)ï»¿](https://dt-url.net/mu03pcw) into [Grail](/docs/platform/grail "Insights on what and how you can query Dynatrace data.") and analyze them on the Dynatrace platform, so you can gain insights into Amazon ECR container vulnerability findings and easily work with your data.

### Use cases

With the ingested data, you can accomplish various use cases, such as

* [Visualize and analyze security findings](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.")
* [Automate and orchestrate security findings](/docs/secure/use-cases/automate-and-orchestrate-security-findings "Regularly check for critical security findings and get automatic Jira tickets or Slack alerts.")

### Requirements

* Set up the desired Amazon ECR scan type. You have two options:

  + [Set up basic scanningï»¿](https://dt-url.net/of23pfi)
  + [Set up enhanced scanningï»¿](https://dt-url.net/ay03qkl)

  To determine which type of scan to choose, see [Scan images for software vulnerabilities in Amazon ECRï»¿](https://dt-url.net/8043q1w).
* Install and configure the [latest AWS CLIï»¿](https://dt-url.net/uf03pcx).
* Select the AWS region where you want to create the Amazon ECR event forwarder.

  Show me how

  1. In a terminal, run:

  ```
  aws configure
  ```

  2. Set your default region (for example, `us-east-1`).
* **Permissions**:

  + You need an Admin user to define a custom policy with the [`app-engine:apps:install` permission](/docs/manage/identity-access-management/permission-management/manage-user-permissions-policies/advanced/iam-policystatements#app-engine-apps-install "Complete reference of IAM policies and corresponding conditions across all Dynatrace services.") to install the app. For details, see [Dynatrace access](/docs/manage/identity-access-management/permission-management/default-policies#access "Dynatrace default policies reference").
  + To query ingested data: `storage:security.events:read`.
* **Tokens**:

  + Generate an access token with the `openpipeline.events_security` scope and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").

## Activation and setup

1. In Dynatrace, open  [**Hub**](/docs/manage/hub "See the information about Dynatrace Hub.").
2. Look for **Amazon ECR** and select **Install**.
3. Select **Set up**, then select  **Configure new connection**.
4. Follow the on-screen instructions to set up the ingestion.

## Details

### How it works

![how it works](https://dt-cdn.net/images/2025-01-15-09-03-31-1407-d2655c29b6.png)

1. Container image vulnerabilities are ingested into Dynatrace

Container image vulnerabilities reported in Amazon ECR are ingested into Dynatrace via a dedicated [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.") security events ingest endpoint, using an [Amazon EventBridgeï»¿](https://dt-url.net/qi03wtk) event forwarding set up with an [AWS CloudFormation templateï»¿](https://dt-url.net/e603poa).

2. Vulnerability findings are processed and stored in Grail

The OpenPipeline ingest endpoint processes and maps the security findings according to the [Semantic Dictionary conventionsï»¿](https://dt-url.net/3q03pb0).

These are stored in a bucket called `default_securityevents` (for details, see: [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.")).

### Monitor data

Once you ingest your Amazon ECR data into Grail, you can monitor your data in the app (in Dynatrace, go to **Settings** > **Amazon ECR**).

![amazon ecr](https://dt-cdn.net/images/2025-03-25-12-20-07-1920-c3fb043a87.png)

You can view

* A chart of ingested data from all existing connections over time

  + Available actions: [Query ingested data](#query)
* A table with information about your connections

  + Available actions: [Remove connection](#remove)

### Visualize and analyze findings

You can create your own [dashboards](/docs/analyze-explore-automate/dashboards-and-notebooks/dashboards-new "Create interactive, customizable views to visualize, analyze, and share your observability data in real time.") or use our templates to visualize and analyze container vulnerability findings.

To use a dashboard template

1. In Dynatrace, go to **Settings** > **Amazon ECR**.
2. In the **Try our templates** section, select the desired dashboard template.

### Automate and orchestrate findings

You can create your own [workflows](/docs/analyze-explore-automate/workflows "Automate IT processes with Dynatrace Workflowsâreact to events, schedule tasks, and connect services.") or use our templates to automate and orchestrate container vulnerability findings.

To use a workflow template

1. In Dynatrace, go to **Settings** > **Amazon ECR**.
2. In the **Try our templates** section, select the desired workflow template.

### Query ingested data

You can query ingested data in [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace.") or [![Investigations](https://dt-cdn.net/images/security-investigator-256-93f6c187d9.png "Investigations") **Investigations**](/docs/secure/investigations "Combine Grail functionalities for evidence-driven investigations, including incident resolution, root cause analysis, and threat hunting."), using the data format in [Semantic Dictionaryï»¿](https://dt-url.net/3q03pb0).

To query ingested data

1. In Dynatrace, go to **Settings** > **Amazon ECR**.
2. Select **Open with** .
3. Select **Investigations** or **Notebooks**.

### Delete connections

To stop sending events to Dynatrace

1. In Dynatrace, go to **Settings** > **Amazon ECR**.
2. For the connection you want to delete, select  **Delete**.
3. Follow the on-screen instructions to delete the resources. If you used values different from those specified in the setup dialog, adjust them accordingly.

This removes the Dynatrace resources created for this integration.

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Ingest Amazon Elastic Container Registry vulnerability findings and scan events.](https://www.dynatrace.com/hub/detail/aws-ecr)

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-aws-security-hub.md


---
title: Ingest AWS Security Hub security findings
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-aws-security-hub
scraped: 2026-02-17T21:17:27.408710
---

# Ingest AWS Security Hub security findings

# Ingest AWS Security Hub security findings

* Latest Dynatrace
* How-to guide
* Updated on Aug 25, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest AWS Security Hub security findings and analyze them in Dynatrace.

## Get started

### Overview

In the following, you'll learn how to ingest security findings from [AWS Security Hubï»¿](https://dt-url.net/wv03w0h) into [Grail](/docs/platform/grail "Insights on what and how you can query Dynatrace data.") and analyze them on the Dynatrace platform, so you can get insights from Dynatrace for AWS Security Hub security findings and visualize, analyze, and automate security findings uniformly on the Dynatrace platform.

### Use cases

With the ingested data, you can accomplish various use cases, such as

* [Ingest and enrich AWS Security Hub findings with Dynatraceï»¿](https://dt-url.net/t703wux)
* [Visualize and analyze security findings](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.")
* [Automate and orchestrate security findings](/docs/secure/use-cases/automate-and-orchestrate-security-findings "Regularly check for critical security findings and get automatic Jira tickets or Slack alerts.")

### Requirements

See below for the [AWS Security Hub](#aws) and [Dynatrace](#dt) requirements.

#### AWS Security Hub requirements

* Install and configure the [latest AWS CLIï»¿](https://dt-url.net/uf03pcx).
* Select the AWS region where you want to create the AWS Security Hub event forwarder.

  Show me how

  1. In a terminal, run:

     ```
     aws configure
     ```
  2. Set your default region (for example, `us-east-1`).

#### Dynatrace requirements

* Permissions:

  + You need an Admin user to define a custom policy with the [`app-engine:apps:install` permission](/docs/manage/identity-access-management/permission-management/manage-user-permissions-policies/advanced/iam-policystatements#app-engine-apps-install "Complete reference of IAM policies and corresponding conditions across all Dynatrace services.") to install the app. For details, see [Dynatrace access](/docs/manage/identity-access-management/permission-management/default-policies#access "Dynatrace default policies reference").
  + To query ingested data: `storage:security.events:read`.
* Tokens:

  + Generate an access token with the `openpipeline.events_security` scope and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").

## Activation and setup

1. In Dynatrace, open  [**Hub**](/docs/manage/hub "See the information about Dynatrace Hub.").
2. Look for **AWS Security Hub** and select **Install**.
3. Select **Set up**, then select  **Configure new connection**.
4. Follow the on-screen instructions to set up the ingestion.

## Details

### How it works

![how it works](https://dt-cdn.net/images/2025-01-15-09-02-44-1355-c1a2ad92c9.png)

1. Events are ingested into Dynatrace

Security finding events from AWS Security Hub are ingested into Dynatrace via a dedicated [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.") security ingest endpoint, using an [Amazon EventBridgeï»¿](https://dt-url.net/qi03wtk) event forwarding set up with an [AWS CloudFormationï»¿](https://dt-url.net/e603poa) template.

2. Security findings are processed and stored in Grail

The OpenPipeline ingest endpoint processes and maps the security findings according to the [Semantic Dictionary conventionsï»¿](https://dt-url.net/3q03pb0).

These are stored in a bucket called `default_securityevents` (for details, see: [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.")).

### Monitor data

Once you ingest your AWS Security Hub data into Grail, you can monitor your data in the app (in Dynatrace, go to **Settings** > **AWS Security Hub**).

![security hub](https://dt-cdn.net/images/2025-03-25-11-46-26-1920-ffd9b3b4d1.png)

You can view

* A chart of ingested data from all existing connections over time

  + Available actions: [Query ingested data](#query)
* A table with information about your connections

  + Available actions: [Delete connection](#remove)

### Visualize and analyze findings

You can create your own [dashboards](/docs/analyze-explore-automate/dashboards-and-notebooks/dashboards-new "Create interactive, customizable views to visualize, analyze, and share your observability data in real time.") or use our templates to visualize and analyze container vulnerability findings.

1. In Dynatrace, go to **Settings** > **AWS Security Hub**.
2. In the **Try our templates** section, select the desired dashboard template.

### Automate and orchestrate findings

You can create your own [workflows](/docs/analyze-explore-automate/workflows "Automate IT processes with Dynatrace Workflowsâreact to events, schedule tasks, and connect services.") or use our templates to automate and orchestrate container vulnerability findings.

1. In Dynatrace, go to **Settings** > **AWS Security Hub**.
2. In the **Try our templates** section, select the desired workflow template.

### Query ingested data

You can query ingested data in [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace.") or [![Investigations](https://dt-cdn.net/images/security-investigator-256-93f6c187d9.png "Investigations") **Investigations**](/docs/secure/investigations "Combine Grail functionalities for evidence-driven investigations, including incident resolution, root cause analysis, and threat hunting."), using the data format in [Semantic Dictionaryï»¿](https://dt-url.net/3q03pb0).

1. In Dynatrace, go to **Settings** > **AWS Security Hub**.
2. Select **Open with** .
3. Select **Investigations** or **Notebooks**.

### Evaluate, triage, and investigate detection findings

You can evaluate, triage, and investigate detection findings with [![Threats & Exploits](https://dt-cdn.net/images/attacks-512-b922840b12.png "Threats & Exploits") **Threats & Exploits**](/docs/secure/threats-and-exploits "Understand, triage, and investigate detection findings and alerts.").

1. In Dynatrace, open ![Threats & Exploits](https://dt-cdn.net/images/attacks-512-b922840b12.png "Threats & Exploits") **Threats & Exploits**.
2. Filter for **Provider** > **AWS Security Hub**.

### Support and mapping

For AWS, Dynatrace supports the following security event types:

* Vulnerability
* Detection
* Compliance experimental

#### List of AWS events mapped to Dynatrace

| AWS event type | Dynatrace mapping |
| --- | --- |
| Software and Configuration Checks/Vulnerabilities/\* | Vulnerability findings |
| TTPs/\* | Detection findings |
| Effects/\* | Detection findings |
| Unusual Behaviors/\* | Detection findings |
| Software and Configuration Checks/Industry and Regulatory Standards/\* | Compliance findings |

All other events are ingested, but not mapped.

#### How detections are handled

* When there are multiple AWS resources, detections are split per each related resource in the event to generate individual events per resource.
* The `types` field from AWS Security Hub, which is normally an array with a single value, is mapped to `detection.type`. When multiple types are reported, the first value of the array is mapped.

### Limit ingestion

By default, once you set up the Dynatrace integration, all AWS event types are ingested into Dynatrace.

To limit ingestion to a specific event type, you need to set up [filtersï»¿](https://dt-url.net/z803wpf) for your Dynatrace AWS Security Hub event forwarder Lambda function in [EventBridgeï»¿](https://dt-url.net/qi03wtk).

1. How to set up filters

1. In your AWS console, go to **Lambda** > **Functions** and select the Dynatrace AWS Security Hub event forwarder function.
2. In **Configuration**, edit the event pattern for the trigger.

Example filters:

Ingest only vulnerability findings

Ingest only detection findings

Ingest only compliance findings

```
{



"source": ["aws.securityhub"],



"detail-type": ["Security Hub Findings - Imported"],



"detail": {



"findings": {



"Types": ["Software and Configuration Checks/Vulnerabilities/CVE"]



}



}



}
```

```
{



"source": ["aws.securityhub"],



"detail-type": ["Security Hub Findings - Imported"],



"detail": {



"findings": {



"Types": [{



"wildcard": "TTPs*"



}, {



"wildcard": "Effects*"



}, {



"wildcard": "Unusual Behaviors*"



}]



}



}



}
```

experimental

```
{



"source": ["aws.securityhub"],



"detail-type": ["Security Hub Findings - Imported"],



"detail": {



"findings": {



"Types": [{



"wildcard": "Software and Configuration Checks/Industry and Regulatory Standards*"



}]



}



}



}
```

### Delete connections

To stop sending events to Dynatrace

1. In Dynatrace, go to **Settings** > **AWS Security Hub**.
2. For the connection you want to delete, select  **Delete**.
3. Follow the on-screen instructions to delete the resources. If you used values different from those specified in the setup dialog, adjust them accordingly.

This removes the Dynatrace resources created for this integration.

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Ingest AWS Security Hub vulnerabilities, detections, and compliance findings.](https://www.dynatrace.com/hub/detail/aws-security-hub)

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-custom-data.md


---
title: Ingest custom security events via API
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-custom-data
scraped: 2026-02-17T21:17:36.717502
---

# Ingest custom security events via API

# Ingest custom security events via API

* Latest Dynatrace
* How-to guide
* Updated on Nov 06, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest security events from custom third-party products via API.

## Get started

### Overview

In the following, you'll learn how to ingest external security events from custom third-party products into [Grail](/docs/platform/grail "Insights on what and how you can query Dynatrace data."), so you can get insights from Dynatrace for vulnerability findings from any source, provider, or format.

A **custom third-party product** is any product for which Dynatrace doesn't provide an out-of-the-box integration.

### Use cases

With the ingested data, you can accomplish various use cases, such as

* [Generate security events from the Dynatrace Investigations app via OpenPipelineï»¿](https://dt-url.net/r703qjx)
* [Ingest and process custom security findings](/docs/secure/use-cases/ingest-and-process-custom-security-findings "Continuously ingest your container scan findings.")
* [Automate and orchestrate security findings](/docs/secure/use-cases/automate-and-orchestrate-security-findings "Regularly check for critical security findings and get automatic Jira tickets or Slack alerts.")
* [Visualize and analyze security findings](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.")

### Requirements

To query ingested data, you need the `storage:security.events:read` permission.

## Activation and setup

To start ingesting data, use one of the options below.

Built-in API endpoint

Custom API endpoint

Endpoint URL

Method

Authentication

Scope

Payload

`https://{your-environment-id}.live.dynatrace.com/platform/ingest/v1/security.events`

POST

[Access token](/docs/manage/identity-access-management/access-tokens-and-oauth-clients/access-tokens#create-api-token "Learn the concept of an access token and its scopes.")

`openpipeline.events_security`

`application/json`

Endpoint URL

Method

Authentication

Scope

Payload

`https://{your-environment-id}.live.dynatrace.com/platform/ingest/custom/security.events/<your-custom-endpoint-name>`

POST

[Access token](/docs/manage/identity-access-management/access-tokens-and-oauth-clients/access-tokens#create-api-token "Learn the concept of an access token and its scopes.")

`openpipeline.events_security.custom`

`application/json`

For details on how to perform the API ingest, see [Learn moreï»¿](https://dt-url.net/1r03q9s).

## Details

### How it works

You ingest your data into Grail via our [built-in API endpoint](#default) or a [custom API endpoint](#custom). Then, depending on the ingest option chosen, you can either analyze data in your format or manually map data to the [Semantic Dictionary conventionsï»¿](https://dt-url.net/3q03pb0).

Ingest options

Built-in API endpoint

Custom API endpoint

Description

You can use and extend our built-in security events endpoint to ingest custom security events via API.

You can [createï»¿](https://dt-url.net/jd23q7s) and [configureï»¿](https://dt-url.net/k203p5t) from scratch a generic endpoint to ingest custom security events via API.

Details

* **Preset bucket**: Security events are stored in a bucket called `default_securityevents` (for details, see: [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.")).
* **Fixed endpoint URL**: One URL for all use cases and products.
* **Data enrichment**: A static `event.kind == "SECURITY_EVENT"` field is added to the event to mark it as a security event.
* **Mapping**: No mapping is applied; data stays in the original format. This means you can analyze data based on your format and create custom dashboards and workflows.

  + Alternatively, you can [configure a processing pipelineï»¿](https://dt-url.net/k203p5t) to map data manually to the [Semantic Dictionary conventionsï»¿](https://dt-url.net/3q03pb0). This way you can use our sample [dashboardï»¿](https://dt-url.net/j923p97), [Jira workflowï»¿](https://dt-url.net/l103p3t), and [Slack workflowï»¿](https://dt-url.net/a643qqd) to visualize data and automatize notifications.

* **Custom bucket**: You can select or create the bucket where the security events will be stored.
* **Custom endpoint URL**: You can configure dedicated URLs for specific use cases or products.
* **Data enrichment**: You can define custom data enrichments.
* **Mapping**: You can configure your endpoint to map data to the [Semantic Dictionary conventionsï»¿](https://dt-url.net/3q03pb0). This way you can use our sample [dashboardï»¿](https://dt-url.net/j923p97), [Jira workflowï»¿](https://dt-url.net/l103p3t), and [Slack workflowï»¿](https://dt-url.net/a643qqd) to visualize data and automatize notifications. For details, see [Configure a processing pipelineï»¿](https://dt-url.net/k203p5t).

### Response codes

| Code | Description |
| --- | --- |
| 202 | Accepted |
| 400 | Bad request (in case of missing body or wrong format) |
| 401 | Unauthorized (in case of missing or invalid token) |

### Examples

Example JSON

```
[



{



"imageId": {



"imageDigest": "sha256:9282579f5330ae90d22f21b1a9be944f893895f06e3bc1985f14d1cfc084c60c"



},



"imageScanFindings": {



"findingSeverityCounts": {



"HIGH": 125,



"MEDIUM": 188,



"LOW": 30,



"UNDEFINED": 13,



"INFORMATIONAL": 353,



"CRITICAL": 6



},



"findings": [



{



"attributes": [



{ "key": "CVSS3_SCORE", "value": "9.8" },



{ "key": "package_version", "value": "4.19.269-1" },



{ "key": "package_name", "value": "linux" },



{



"key": "CVSS3_VECTOR",



"value": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"



}



],



"description": "An issue was discovered in drivers/net/ethernet/intel/igb/igb_main.c in the IGB driver in the Linux kernel before 6.5.3. A buffer size may not be adequate for frames larger than the MTU.",



"name": "CVE-2023-45871",



"severity": "CRITICAL",



"uri": "https://security-tracker.debian.org/tracker/CVE-2023-45871 "



},



{



"attributes": [



{ "key": "CVSS3_SCORE", "value": "9.8" },



{ "key": "package_version", "value": "1:7.9p1-10+deb10u2" },



{ "key": "package_name", "value": "openssh" },



{



"key": "CVSS3_VECTOR",



"value": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"



}



],



"description": "The PKCS#11 feature in ssh-agent in OpenSSH before 9.3p2 has an insufficiently trustworthy search path, leading to remote code execution if an agent is forwarded to an attacker-controlled system. (Code in /usr/lib is not necessarily safe for loading into ssh-agent.) NOTE: this issue exists because of an incomplete fix for CVE-2016-10009.",



"name": "CVE-2023-38408",



"severity": "CRITICAL",



"uri": "https://security-tracker.debian.org/tracker/CVE-2023-38408 "



},



{



"attributes": [



{ "key": "CVSS3_SCORE", "value": "9.8" },



{ "key": "package_version", "value": "2.7.16-2+deb10u1" },



{ "key": "package_name", "value": "python2.7" },



{



"key": "CVSS3_VECTOR",



"value": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"



}



],



"description": "An XML External Entity (XXE) issue was discovered in Python through 3.9.1. The plistlib module no longer accepts entity declarations in XML plist files to avoid XML vulnerabilities.",



"name": "CVE-2022-48565",



"severity": "CRITICAL",



"uri": "https://security-tracker.debian.org/tracker/CVE-2022-48565 "



},



{



"attributes": [



{ "key": "CVSS3_SCORE", "value": "9.8" },



{ "key": "package_version", "value": "2.7.16-2+deb10u1" },



{ "key": "package_name", "value": "python2.7" },



{



"key": "CVSS3_VECTOR",



"value": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"



},



{ "key": "CVSS2_VECTOR", "value": "AV:N/AC:L/Au:N/C:P/I:P/A:P" },



{ "key": "CVSS2_SCORE", "value": "7.5" }



],



"description": "Python 3.x through 3.9.1 has a buffer overflow in PyCArg_repr in _ctypes/callproc.c, which may lead to remote code execution in certain Python applications that accept floating-point numbers as untrusted input, as demonstrated by a 1e300 argument to c_double.from_param. This occurs because sprintf is used unsafely.",



"name": "CVE-2021-3177",



"severity": "CRITICAL",



"uri": "https://security-tracker.debian.org/tracker/CVE-2021-3177 "



}



],



"imageScanCompletedAt": 1698376478,



"vulnerabilitySourceUpdatedAt": 1698343825



},



"imageScanStatus": {



"description": "The scan was completed successfully.",



"status": "COMPLETE"



},



"nextToken": "ukD72mdD/mC8b5xV3susmJzzaTgp3hKwR9nRUW1yZZ63B5NL+m8CiI+qgoiLO0t5s6Oi9w2CQBANPaxpQTFWXxF/Sq7shr/h//oNXvOJ2XuWPSF3ox6DgxQztXUFyKzeGw+HpbYZAAxpHjJVELVXXnhpxAScZkKhVG85CbbUGfSPyuKcSeeHoNvQPGBdxCWD6CaKl4nFxtXyUeFRs3RV+mkX5FUxosMnBJepE2JbaoM9elE1niY2Rpq3BZrp/QeOyWdmjeuySi+2KZO03915df+6OMIfXtt3zclPZ+BGcdMgWoETrte2fkh2y1RDO3PI4OCohgCbjlTk9X6fYLWrrxwkhfWAIRekqToQq+S8BHEm1o82jxDoyKO0Et9UrZVIEFOofBkvenm5U+8XvgQ4V5kvMZZLa9DZykVDteq28OF+KCgjo7WHTbXMy1yh7jyRJ6A77N12YJfxYgv16JjkVgmDqGjlM3YJEH2o55SYTAnSsiBXiMvvq1RK1hl567SIstgGPMK3c0v7TGDnCE6o3EhP4FC73As6mj2q4uGkLf8eMQLi9ogBJ1UAzKCiCl3bxeTKuMz1W8hokdPauwuAd9uKg0vLdHmM6iftfrVhsgbbioNLy3R5jOon7X61YbIGF7fUOkaj72o37fpPd/JG2g==",



"registryId": "123456789876",



"repositoryName": "unguard-frontend"



}



]
```

Example end result in Grail

Built-in API endpoint

Custom API endpoint

```
[



{



"timestamp": "2024-06-17T14:58:36.820000000+02:00",



"dt.ingest.source": "/platform/ingest/v1/security.events/",



"event.kind": "SECURITY_EVENT",



"imageId": "{\"imageDigest\":\"sha256:9282579f5330ae90d22f21b1a9be944f893895f06e3bc1985f14d1cfc084c60c\"}",



"imageScanFindings": "{\"findingSeverityCounts\":{\"HIGH\":125,\"MEDIUM\":188,\"LOW\":30,\"UNDEFINED\":13,\"INFORMATIONAL\":353,\"CRITICAL\":6},\"findings\":[{\"attributes\":[{\"key\":\"CVSS3_SCORE\",\"value\":\"9.8\"},{\"key\":\"package_version\",\"value\":\"4.19.269-1\"},{\"key\":\"package_name\",\"value\":\"linux\"},{\"key\":\"CVSS3_VECTOR\",\"value\":\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\"}],\"description\":\"An issue was discovered in drivers/net/ethernet/intel/igb/igb_main.c in the IGB driver in the Linux kernel before 6.5.3. A buffer size may not be adequate for frames larger than the MTU.\",\"name\":\"CVE-2023-45871\",\"severity\":\"CRITICAL\",\"uri\":\"https://security-tracker.debian.org/tracker/CVE-2023-45871 \"},{\"attributes\":[{\"key\":\"CVSS3_SCORE\",\"value\":\"9.8\"},{\"key\":\"package_version\",\"value\":\"1:7.9p1-10+deb10u2\"},{\"key\":\"package_name\",\"value\":\"openssh\"},{\"key\":\"CVSS3_VECTOR\",\"value\":\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\"}],\"description\":\"The PKCS#11 feature in ssh-agent in OpenSSH before 9.3p2 has an insufficiently trustworthy search path, leading to remote code execution if an agent is forwarded to an attacker-controlled system. (Code in /usr/lib is not necessarily safe for loading into ssh-agent.) NOTE: this issue exists because of an incomplete fix for CVE-2016-10009.\",\"name\":\"CVE-2023-38408\",\"severity\":\"CRITICAL\",\"uri\":\"https://security-tracker.debian.org/tracker/CVE-2023-38408 \"},{\"attributes\":[{\"key\":\"CVSS3_SCORE\",\"value\":\"9.8\"},{\"key\":\"package_version\",\"value\":\"2.7.16-2+deb10u1\"},{\"key\":\"package_name\",\"value\":\"python2.7\"},{\"key\":\"CVSS3_VECTOR\",\"value\":\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\"}],\"description\":\"An XML External Entity (XXE) issue was discovered in Python through 3.9.1. The plistlib module no longer accepts entity declarations in XML plist files to avoid XML vulnerabilities.\",\"name\":\"CVE-2022-48565\",\"severity\":\"CRITICAL\",\"uri\":\"https://security-tracker.debian.org/tracker/CVE-2022-48565 \"},{\"attributes\":[{\"key\":\"CVSS3_SCORE\",\"value\":\"9.8\"},{\"key\":\"package_version\",\"value\":\"2.7.16-2+deb10u1\"},{\"key\":\"package_name\",\"value\":\"python2.7\"},{\"key\":\"CVSS3_VECTOR\",\"value\":\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\"},{\"key\":\"CVSS2_VECTOR\",\"value\":\"AV:N/AC:L/Au:N/C:P/I:P/A:P\"},{\"key\":\"CVSS2_SCORE\",\"value\":\"7.5\"}],\"description\":\"Python 3.x through 3.9.1 has a buffer overflow in PyCArg_repr in _ctypes/callproc.c, which may lead to remote code execution in certain Python applications that accept floating-point numbers as untrusted input, as demonstrated by a 1e300 argument to c_double.from_param. This occurs because sprintf is used unsafely.\",\"name\":\"CVE-2021-3177\",\"severity\":\"CRITICAL\",\"uri\":\"https://security-tracker.debian.org/tracker/CVE-2021-3177 \"}],\"imageScanCompletedAt\":1698376478,\"vulnerabilitySourceUpdatedAt\":1698343825}",



"imageScanStatus": "{\"description\":\"The scan was completed successfully.\",\"status\":\"COMPLETE\"}",



"nextToken": "ukD72mdD/mC8b5xV3susmJzzaTgp3hKwR9nRUW1yZZ63B5NL+m8CiI+qgoiLO0t5s6Oi9w2CQBANPaxpQTFWXxF/Sq7shr/h//oNXvOJ2XuWPSF3ox6DgxQztXUFyKzeGw+HpbYZAAxpHjJVELVXXnhpxAScZkKhVG85CbbUGfSPyuKcSeeHoNvQPGBdxCWD6CaKl4nFxtXyUeFRs3RV+mkX5FUxosMnBJepE2JbaoM9elE1niY2Rpq3BZrp/QeOyWdmjeuySi+2KZO03915df+6OMIfXtt3zclPZ+BGcdMgWoETrte2fkh2y1RDO3PI4OCohgCbjlTk9X6fYLWrrxwkhfWAIRekqToQq+S8BHEm1o82jxDoyKO0Et9UrZVIEFOofBkvenm5U+8XvgQ4V5kvMZZLa9DZykVDteq28OF+KCgjo7WHTbXMy1yh7jyRJ6A77N12YJfxYgv16JjkVgmDqGjlM3YJEH2o55SYTAnSsiBXiMvvq1RK1hl567SIstgGPMK3c0v7TGDnCE6o3EhP4FC73As6mj2q4uGkLf8eMQLi9ogBJ1UAzKCiCl3bxeTKuMz1W8hokdPauwuAd9uKg0vLdHmM6iftfrVhsgbbioNLy3R5jOon7X61YbIGF7fUOkaj72o37fpPd/JG2g==",



"registryId": "123456789876",



"repositoryName": "unguard-frontend"



}



]
```

```
{



"timestamp": "2024-06-17T14:58:36.820000000+02:00",



"dt.ingest.source": "/platform/ingest/v1/security.events/",



"imageId": "{\"imageDigest\":\"sha256:9282579f5330ae90d22f21b1a9be944f893895f06e3bc1985f14d1cfc084c60c\"}",



"imageScanFindings": "{\"findingSeverityCounts\":{\"HIGH\":125,\"MEDIUM\":188,\"LOW\":30,\"UNDEFINED\":13,\"INFORMATIONAL\":353,\"CRITICAL\":6},\"findings\":[{\"attributes\":[{\"key\":\"CVSS3_SCORE\",\"value\":\"9.8\"},{\"key\":\"package_version\",\"value\":\"4.19.269-1\"},{\"key\":\"package_name\",\"value\":\"linux\"},{\"key\":\"CVSS3_VECTOR\",\"value\":\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\"}],\"description\":\"An issue was discovered in drivers/net/ethernet/intel/igb/igb_main.c in the IGB driver in the Linux kernel before 6.5.3. A buffer size may not be adequate for frames larger than the MTU.\",\"name\":\"CVE-2023-45871\",\"severity\":\"CRITICAL\",\"uri\":\"https://security-tracker.debian.org/tracker/CVE-2023-45871 \"},{\"attributes\":[{\"key\":\"CVSS3_SCORE\",\"value\":\"9.8\"},{\"key\":\"package_version\",\"value\":\"1:7.9p1-10+deb10u2\"},{\"key\":\"package_name\",\"value\":\"openssh\"},{\"key\":\"CVSS3_VECTOR\",\"value\":\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\"}],\"description\":\"The PKCS#11 feature in ssh-agent in OpenSSH before 9.3p2 has an insufficiently trustworthy search path, leading to remote code execution if an agent is forwarded to an attacker-controlled system. (Code in /usr/lib is not necessarily safe for loading into ssh-agent.) NOTE: this issue exists because of an incomplete fix for CVE-2016-10009.\",\"name\":\"CVE-2023-38408\",\"severity\":\"CRITICAL\",\"uri\":\"https://security-tracker.debian.org/tracker/CVE-2023-38408 \"},{\"attributes\":[{\"key\":\"CVSS3_SCORE\",\"value\":\"9.8\"},{\"key\":\"package_version\",\"value\":\"2.7.16-2+deb10u1\"},{\"key\":\"package_name\",\"value\":\"python2.7\"},{\"key\":\"CVSS3_VECTOR\",\"value\":\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\"}],\"description\":\"An XML External Entity (XXE) issue was discovered in Python through 3.9.1. The plistlib module no longer accepts entity declarations in XML plist files to avoid XML vulnerabilities.\",\"name\":\"CVE-2022-48565\",\"severity\":\"CRITICAL\",\"uri\":\"https://security-tracker.debian.org/tracker/CVE-2022-48565 \"},{\"attributes\":[{\"key\":\"CVSS3_SCORE\",\"value\":\"9.8\"},{\"key\":\"package_version\",\"value\":\"2.7.16-2+deb10u1\"},{\"key\":\"package_name\",\"value\":\"python2.7\"},{\"key\":\"CVSS3_VECTOR\",\"value\":\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\"},{\"key\":\"CVSS2_VECTOR\",\"value\":\"AV:N/AC:L/Au:N/C:P/I:P/A:P\"},{\"key\":\"CVSS2_SCORE\",\"value\":\"7.5\"}],\"description\":\"Python 3.x through 3.9.1 has a buffer overflow in PyCArg_repr in _ctypes/callproc.c, which may lead to remote code execution in certain Python applications that accept floating-point numbers as untrusted input, as demonstrated by a 1e300 argument to c_double.from_param. This occurs because sprintf is used unsafely.\",\"name\":\"CVE-2021-3177\",\"severity\":\"CRITICAL\",\"uri\":\"https://security-tracker.debian.org/tracker/CVE-2021-3177 \"}],\"imageScanCompletedAt\":1698376478,\"vulnerabilitySourceUpdatedAt\":1698343825}",



"imageScanStatus": "{\"description\":\"The scan was completed successfully.\",\"status\":\"COMPLETE\"}",



"nextToken": "ukD72mdD/mC8b5xV3susmJzzaTgp3hKwR9nRUW1yZZ63B5NL+m8CiI+qgoiLO0t5s6Oi9w2CQBANPaxpQTFWXxF/Sq7shr/h//oNXvOJ2XuWPSF3ox6DgxQztXUFyKzeGw+HpbYZAAxpHjJVELVXXnhpxAScZkKhVG85CbbUGfSPyuKcSeeHoNvQPGBdxCWD6CaKl4nFxtXyUeFRs3RV+mkX5FUxosMnBJepE2JbaoM9elE1niY2Rpq3BZrp/QeOyWdmjeuySi+2KZO03915df+6OMIfXtt3zclPZ+BGcdMgWoETrte2fkh2y1RDO3PI4OCohgCbjlTk9X6fYLWrrxwkhfWAIRekqToQq+S8BHEm1o82jxDoyKO0Et9UrZVIEFOofBkvenm5U+8XvgQ4V5kvMZZLa9DZykVDteq28OF+KCgjo7WHTbXMy1yh7jyRJ6A77N12YJfxYgv16JjkVgmDqGjlM3YJEH2o55SYTAnSsiBXiMvvq1RK1hl567SIstgGPMK3c0v7TGDnCE6o3EhP4FC73As6mj2q4uGkLf8eMQLi9ogBJ1UAzKCiCl3bxeTKuMz1W8hokdPauwuAd9uKg0vLdHmM6iftfrVhsgbbioNLy3R5jOon7X61YbIGF7fUOkaj72o37fpPd/JG2g==",



"registryId": "123456789876",



"repositoryName": "unguard-frontend"



}
```

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")
* [OpenPipeline Ingest API - POST Custom security event endpoint (new)](/docs/platform/openpipeline/reference/openpipeline-ingest-api/security-events/security-events-custom-endpoint "Configure a custom security event endpoint via OpenPipeline Ingest API.")
* [OpenPipeline Ingest API - POST Built-in security events (new)](/docs/platform/openpipeline/reference/openpipeline-ingest-api/security-events/security-events-builtin "Ingest security events from built-in endpoints via OpenPipeline Ingest API.")


---


## Source: ingest-github-advanced-security.md


---
title: Ingest GitHub Advanced Security security events and audit logs
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-github-advanced-security
scraped: 2026-02-17T21:17:33.989651
---

# Ingest GitHub Advanced Security security events and audit logs

# Ingest GitHub Advanced Security security events and audit logs

* Latest Dynatrace
* Extension
* Updated on Oct 07, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest GitHub Advanced Security audit logs and security events into Dynatrace as security events.

## Get started

### Overview

Dynatrace integration with [GitHub Advanced Securityï»¿](https://github.com/security/advanced-security) (GHAS) enables users to unify and contextualize vulnerability findings across DevSecOps tools and products, facilitating centralized prioritization, visualization, and automation of security findings.

[GitHub Advanced Securityï»¿](https://docs.github.com/en/get-started/learning-about-github/about-github-advanced-security) includes [Code Securityï»¿](https://github.com/security/advanced-security/code-security) and [Secret Protectionï»¿](https://github.com/security/advanced-security/secret-protection) which generate vulnerability findings for development artifacts, such as code and containers. Dynatrace observes the runtime entities associated with those artifacts. Ingesting and enriching vulnerability findings helps users focus on high-impact risks affecting production applications.

The first version of this integration ingests and contextualizes [Dependabot alertsï»¿](https://docs.github.com/en/code-security/dependabot/dependabot-alerts/about-dependabot-alerts), which are free for public repositories and part of the Code Security premium offering.

### Use cases

With the ingested data, you can accomplish various use cases, such as

* [Visualize and analyze security findings](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.")
* [Automate and orchestrate security findings](/docs/secure/use-cases/automate-and-orchestrate-security-findings "Regularly check for critical security findings and get automatic Jira tickets or Slack alerts.")
* [Discover coverage gaps in security findings](/docs/secure/use-cases/discover-coverage-gaps-in-security-scans "Unveil blind spots in your Software Development Lifecycle (SDLC).")

### Requirements

See below for the [GitHub](#github) and [Dynatrace](#dt) requirements.

#### GitHub requirements

For the extension to collect security data, authentication credentials with proper permissions are required. You have two options, described below.

GitHub app-based authentication

PAT-based authentication

Recommended

The [GitHub app-based authenticationï»¿](https://docs.github.com/en/rest/authentication/authenticating-to-the-rest-api?apiVersion=2022-11-28#authenticating-with-a-token-generated-by-an-app)

* Allows granular permission control
* Can collect organization level audit logs
* Has higher API rate limits

To register and install a GitHub app, follow the steps below.

1. Register the GitHub app

1. Follow the steps in [Registering a GitHub appï»¿](https://docs.github.com/en/apps/creating-github-apps/registering-a-github-app/registering-a-github-app) with the following values:

* For **GitHub App Name**, enter `DynatraceAppSec-<Your Company>`, making sure to replace `<Your Company>` with your own value.
* For **Homepage URL**, enter `https://dynatrace.com`.
* Clear **Webhook > Active**.
* Enable the following permissions:

  + Repository permissions:

    - **Contents**: `Read-only`
    - **Dependabot alerts**: `Read-only`
    - **Code scanning alerts**: `Read-only` (required when code scanning events are ingested)
    - **Secret scanning alerts**: `Read-only` (required when secret scanning events are ingested)
  + Organization permissions

    - **Administration**: `Read-only` (required for audit logs)
* To set the location where the app will be installed, select one of the following:

  + `Any account` (allows you to install the app in multiple organizations and even user account, which will simplify your monitoring configurations)
  + `Only this account` (the app is installed in the current account; this means you'll need multiple apps and monitoring configurations to cover multiple organizations under an enterprise)

2. Generate a private key for the app

1. Select the **General** tab and go to the newly registered app settings.
2. Copy the client ID (you'll need it when setting up the monitoring configuration).
3. Under **Private keys**, generate a private key (you'll need it when setting up the monitoring configuration)

   The private key allows authenticated requests from the extension; make sure to secure it.

3. Install the app

[Install the GitHub appï»¿](https://docs.github.com/en/apps/using-github-apps/installing-your-own-github-app) on any accounts (users or organizations) you want to monitor.

The [Personal Access Token (PAT)-based authenticationï»¿](https://docs.github.com/en/rest/authentication/authenticating-to-the-rest-api?apiVersion=2022-11-28#authenticating-with-a-personal-access-token)

* Allows a faster setup
* Is suitable for quick integration validation
* Allows audit log collection

  For the [enterprise audit logsï»¿](https://docs.github.com/en/enterprise-cloud@latest/rest/enterprise-admin/audit-log?apiVersion=2022-11-28), the authenticated user must be an enterprise admin to use this endpoint.

To generate a Personal Access Token, follow the instructions at [Managing your personal access tokensï»¿](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens), making sure to enter the following values:

* The token should be **Classic Personal Access Token**.
* **Expiration**: if you set the token to expire you are responsible for updating it.
* **Scopes**:

  + **repo**: full control
  + **audit\_log**: `read:audit_log`

#### Dynatrace requirements

* ActiveGate version 1.310+ that needs to be able to

  + Run Extensions 2.0 framework
  + Reach the GitHub API endpoint URLs
* Permissions:

  + To run ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**: Go to  **Hub**, select ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**, and display **Technical information**.
  + To query ingested data: `storage:security.events:read`.
* Generate an access token with the `openpipeline.events_security` scope and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").

## Activation and setup

1. In Dynatrace, search for **GitHub Advanced Security** and select **Install**.
2. Follow the on-screen instructions to configure the extension.
3. Verify configuration by running the following queries in [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace."):

   * For audit logs:

     ```
     fetch logs



     | filter log.source=="GitHub Advanced Security"
     ```
   * For finding events:

     ```
     fetch security.events



     | filter dt.system.bucket == "default_securityevents"



     | filter event.provider=="GitHub Advanced Security"



     AND event.type=="VULNERABILITY_FINDING"
     ```
   * For scan events:

     ```
     fetch security.events



     | filter dt.system.bucket == "default_securityevents"



     | filter event.provider=="GitHub Advanced Security"



     AND event.type=="VULNERABILITY_SCAN"
     ```
4. Once the extension is installed and working, you can access and manage it in Dynatrace via ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**. For details, see [About Extensions](/docs/ingest-from/extensions/concepts "Learn more about the concept of Dynatrace Extensions.").

## Details

### How it works

![how it works](https://dt-cdn.net/images/diagram-2560-ac2977ae34.png)

1. Events and logs are collected from GHAS products

The Dynatrace GHAS integration is an extension deployed in a [Dynatrace ActiveGate](/docs/ingest-from/dynatrace-activegate "Understand the basic concepts related to ActiveGate.") that periodically collects security findings and audit logs using the [GitHub REST APIï»¿](https://docs.github.com/en/rest?apiVersion=2022-11-28).

2. Security findings and logs are ingested into Dynatrace

Security findings are ingested into the Dynatrace platform via a dedicated [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.") security ingest endpoint.

3. Security findings and logs are processed and stored in Grail

The OpenPipeline ingest endpoint processes and maps the security findings according to the [Semantic Dictionary conventionsï»¿](https://dt-url.net/3q03pb0).

These are stored in a bucket called `default_securityevents` (for details, see: [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.")).

Optionally, the collected audit logs are ingested via a dedicated [extensions log ingest pipeline](/docs/analyze-explore-automate/logs/lma-log-ingestion#ingest-extensions "Stream log data to Dynatrace.") and stored in the appropriate [semantic format](/docs/semantic-dictionary/model/log "Get to know the Semantic Dictionary models related to Log Analytics.").

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## Feature sets

When activating your extension using [monitoring configuration](#monitoring-configuration), you can limit monitoring to one of the feature sets. To work properly, the extension has to collect at least one metric after the activation.

In highly segmented networks, feature sets can reflect the segments of your environment. Then, when you create a monitoring configuration, you can select a feature set and a corresponding ActiveGate group that can connect to this particular segment.

All metrics that aren't categorized into any feature set are considered to be the default and are always reported.

A metric inherits the feature set of a subgroup, which in turn inherits the feature set of a group. Also, the feature set defined on the metric level overrides the feature set defined on the subgroup level, which in turn overrides the feature set defined on the group level.

## FAQ

### Which data model is used for the security logs and events coming from GHAS integration?

* [**Vulnerability finding events**](/docs/semantic-dictionary/model/security-events#vulnerability-finding-events "Get to know the Semantic Dictionary models related to security events.") store the individual vulnerability findings reported by various GHAS products per affected artifacts and component.
* [**Vulnerability scan events**](/docs/semantic-dictionary/model/security-events#vulnerability-scan-events "Get to know the Semantic Dictionary models related to security events.") indicate coverage of scans for individual artifacts.
* [**Audit logs**](/docs/semantic-dictionary/model/log#audit-logs "Get to know the Semantic Dictionary models related to Log Analytics.") represent the user activity logs in the GHAS products.

### Which GHAS security findings are imported into Dynatrace?

* If the extension is configured to ingest data at an interval of `n` hours, then whenever the extension runs all security events (Dependabot, code scanning, and secret scanning alerts) updated in the last `n` hours will be ingested.
* On the first ingest, we consider alerts updated in the last `m` hours, where `m` is the first ingest interval configured in the monitoring configuration.
* If no scans occurred, no findings will be ingested, even if the project has open issues. Consult the GitHub documentation for [Dependabotï»¿](https://docs.github.com/en/code-security/dependabot/dependabot-alerts/about-dependabot-alerts#detection-of-insecure-dependencies), [code scanningï»¿](https://docs.github.com/en/code-security/code-scanning/introduction-to-code-scanning/about-code-scanning-with-codeql), and [secret scanningï»¿](https://docs.github.com/en/code-security/secret-scanning/introduction/about-secret-scanning) to see when a scan will occur.

### Which extension fields are added to the core fields of the events ingested from GHAS?

The `github` namespace is added for extracting several GHAS-specific attributes for user convenience on top of the original issue JSON, which is stored in the `event.original_content` field.

**Examples**:

* `github.dependency.relationship`
* `github.dependency.scope`
* `github.epss.percentage`
* `github.epss.percentile`
* `github.ecosystem`

### What GHAS asset types are supported by Dynatrace for runtime contextualization?

`CODE_ARTIFACT`: All the findings from GitHub Advanced Security products coming from the assessment of code artifacts are mapped set with `CODE_ARTIFACT` value in the `object.type` field, and the `artifact` and `component` namespaces are added with the corresponding fields:

* `artifact.repository.name` represents the repository name which hosts the artifact.
* `artifact.path` is the full path of the file representing the code artifact.
* `component.name` represents the name of the vulnerable library within a code artifact.
* `component.version` includes the version of the vulnerable component.

  GitHub only provides limit values and not the exact version, for example, `<1.4`. This limits the possibility of matching runtime components, as the version isn't matched in this case.

### How is the risk score for GHAS findings normalized?

Dynatrace normalizes severity and risk scores for all findings ingested through the current integration. This helps you to prioritize findings consistently, regardless of their source.  
For details on how normalization works, see [Severity and score normalization](/docs/secure/threat-observability/concepts#normalization "Basic concepts related to Threat Observability").

The Dynatrace risk levels and scores are mapped from the original [GHAS severity and scoreï»¿](https://docs.github.com/en/code-security/getting-started/dependabot-quickstart-guide).

* `dt.security.risk.level` - is taken from the GHAS severity level and mapped from the original values in `finding.severity`.
* `dt.security.risk.score` - is taken from the GHAS severity level and mapped to static scores. The CVSS score reported by GHAS is available in `finding.score`; however, this may not always match the reported severity.

| `dt.security.risk.level` (mapped from `finding.severity`) | `dt.security.risk.score` (mapped from `dt.security.risk.level`) |
| --- | --- |
| critical -> CRITICAL | 10.0 |
| high/error -> HIGH | 8.9 |
| medium/warning -> MEDIUM | 6.9 |
| low/note -> LOW | 3.9 |

Secret scanning alerts are assigned a default risk level of HIGH. You can customize this setting in **Advanced options** during the extension configuration.

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Ingest GitHub Advanced Security (GHAS) security events and audit logs.](https://www.dynatrace.com/hub/detail/github-advanced-security/)

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-harbor-data.md


---
title: Ingest Harbor vulnerability findings, scans, and audit logs
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-harbor-data
scraped: 2026-02-17T21:17:24.837794
---

# Ingest Harbor vulnerability findings, scans, and audit logs

# Ingest Harbor vulnerability findings, scans, and audit logs

* Latest Dynatrace
* Extension
* Updated on Oct 07, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest Harbor vulnerability findings, scans, and audit logs into Dynatrace as security events.

## Get started

### Overview

The Dynatrace integration with [Harborï»¿](https://dt-url.net/hn03wbw) allows you to unify and contextualize vulnerability findings across DevSecOps tools and products, enabling central prioritization, visualization, and automation of security findings.

Harbor is a container registry that allows scanning the stored container images with various tools, such as Trivy. It serves the generated vulnerability findings from container images. The Dynatrace platform observes the corresponding runtime entities (the running containers) associated with those images. Ingesting and mapping vulnerability findings to the runtime entities helps users to better focus on the top risks that affect their production applications.

### Use cases

With the ingested data, you can accomplish various use cases, such as

* [Visualize and analyze security findings](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.")
* [Discover coverage gaps in security findings](/docs/secure/use-cases/discover-coverage-gaps-in-security-scans "Unveil blind spots in your Software Development Lifecycle (SDLC).")
* [Automate and orchestrate security findings](/docs/secure/use-cases/automate-and-orchestrate-security-findings "Regularly check for critical security findings and get automatic Jira tickets or Slack alerts.")
* Analyze and detect anomalous user activity Coming soon

### Requirements

See below for the [Harbor](#harbor) and [Dynatrace](#dt) requirements.

#### Harbor requirements

We recommend using a [robot accountï»¿](https://dt-url.net/my23w6o) for fine-grained authorization. Make sure to

* Store the generated secret for the robot account, as it won't be recoverable after creation
* Refresh the expiry period in due time
* Edit the robot account to enable the permissions below.

| **Permission Type** | **Resource** | **Access Level** |
| --- | --- | --- |
| System permissions | Audit log | List |
|  | Project | List |
|  | Security Hub | List |
| Project permissions | Artifact | List |
|  | Repository | List |

These permissions must be granted for all projects you want Dynatrace to monitor. They ensure Dynatrace can retrieve scan results, audit events, and metadata necessary for accurate vulnerability mapping.

#### Dynatrace requirements

* ActiveGate version 1.300+
* Permissions:

  + To run ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**: Go to  **Hub**, select ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**, and display **Technical information**.
  + To query ingested data: `storage:security.events:read`.
* Tokens:

  + Generate an access token with the `openpipeline.events_security` scope and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").

## Activation and setup

1. In Dynatrace, search for **Harbor** and select **Install**.
2. Follow the on-screen instructions to configure the extension.
3. Verify configuration by running the following queries in [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace."):

   * For audit logs:

     ```
     fetch logs



     | filter log.source=="Harbor"
     ```
   * For finding events:

     ```
     fetch security.events



     | filter dt.system.bucket == "default_securityevents"



     | filter event.provider=="Harbor"



     AND event.type=="VULNERABILITY_FINDING"
     ```
   * For scan events:

     ```
     fetch security.events



     | filter dt.system.bucket == "default_securityevents"



     | filter event.provider=="Harbor"



     AND event.type=="VULNERABILITY_SCAN"
     ```
4. Once the extension is installed and working, you can access and manage it in Dynatrace via ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**. For details, see [About Extensions](/docs/ingest-from/extensions/concepts "Learn more about the concept of Dynatrace Extensions.").

## Details

### How it works

![ingest mechanism](https://dt-cdn.net/images/image-20250210-114352-2221-6c1861c4fb.png)

Dynatrace integration with Harbor is an [extension](/docs/ingest-from/extensions "Learn how to create and manage Dynatrace Extensions.") running on Dynatrace ActiveGate. Once you enable and configure the Dynatrace Harbor extension

1. It periodically reaches out to Harbor products and fetches the new vulnerability findings, scans, and audit logs.
2. The fetched data is ingested into Dynatrace and mapped to the [Dynatrace Semantic Dictionaryï»¿](https://dt-url.net/z1c3xsm).
3. Data is stored in a bucket called `default_securityevents` (for details, see [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.")).

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## Feature sets

When activating your extension using [monitoring configuration](#monitoring-configuration), you can limit monitoring to one of the feature sets. To work properly, the extension has to collect at least one metric after the activation.

In highly segmented networks, feature sets can reflect the segments of your environment. Then, when you create a monitoring configuration, you can select a feature set and a corresponding ActiveGate group that can connect to this particular segment.

All metrics that aren't categorized into any feature set are considered to be the default and are always reported.

A metric inherits the feature set of a subgroup, which in turn inherits the feature set of a group. Also, the feature set defined on the metric level overrides the feature set defined on the subgroup level, which in turn overrides the feature set defined on the group level.

## FAQ

### Why are some scans not being reported?

The Harbor APIs only expose the status of the last completed scan for artifacts. This means that when the extension runs, it can only report the most recent scan that occurred (if any) during the last collection interval.

If the extension is set to collect scan and vulnerability data once per hour and two scans occurred in that last hour, only the details of the most recent one will be reported.

### Which data model is used for the security logs and events coming from Harbor?

* [**Vulnerability finding events**](/docs/semantic-dictionary/model/security-events#vulnerability-finding-events "Get to know the Semantic Dictionary models related to security events.") store the individual vulnerability findings reported by Harbor per container image and component.
* [**Vulnerability scan events**](/docs/semantic-dictionary/model/security-events#vulnerability-scan-events "Get to know the Semantic Dictionary models related to security events.") indicate coverage of scans for individual container images.
* [**Audit logs**](/docs/semantic-dictionary/model/log#audit-logs "Get to know the Semantic Dictionary models related to Log Analytics.") represent user activity logs in Harbor.

### Which extension fields are added on top of the core fields of the events ingested from Harbor?

The `container_image` namespace is added for container image-related information with the following fields:

* `container_image.digest` represents the container image digest; this value can be used to match to the runtime containers
* `container_image.repository` represents the container repository name
* `container_image.registry` represents the container registry name

The `container_image.tags` field isn't reported by Harbor, so it's not available.

### What Harbor asset types are supported by Dynatrace for runtime contextualization?

`CONTAINER_IMAGE`: All findings from Harbor are generated by vulnerability assessments of container images set with the `CONTAINER_IMAGE` value in the `object.type` field, and the `container_image` namespace is added.

### How do we normalize the risk score for Harbor findings?

Dynatrace normalizes severity and risk scores for all findings ingested through the current integration. This helps you to prioritize findings consistently, regardless of their source.  
For details on how normalization works, see [Severity and score normalization](/docs/secure/threat-observability/concepts#normalization "Basic concepts related to Threat Observability").

* `dt.security.risk.level` is taken from the severity level set by the configured scanner in Harbor. The values (`CRITICAL`, `HIGH`, `MEDIUM`, `LOW`, and `NONE`) are mapped as is, with the exception of `Unknown`, which is also mapped to `NONE`.
* `dt.security.risk.score` is mapped to a set of fixed values based on the risk level determined above.

| `dt.security.risk.level` (mapped from `finding.severity`) | `dt.security.risk.score` |
| --- | --- |
| Critical -> CRITICAL | 10.0 |
| High -> HIGH | 8.9 |
| Medium -> MEDIUM | 6.9 |
| Low -> LOW | 3.9 |
| Unknown -> NONE | 0.0 |

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Ingest Harbor vulnerability findings, scans, and audit logs.](https://www.dynatrace.com/hub/detail/harbor)

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-microsoft-defender.md


---
title: Ingest Microsoft Defender for Cloud security events
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-microsoft-defender
scraped: 2026-02-17T21:17:23.556527
---

# Ingest Microsoft Defender for Cloud security events

# Ingest Microsoft Defender for Cloud security events

* Latest Dynatrace
* How-to guide
* Updated on Oct 07, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest Microsoft Defender for Cloud security events and analyze them in Dynatrace.

## Get started

### Overview

Dynatrace integration with [Microsoft Defender for Cloud CNAPP platformï»¿](https://dt-url.net/so23wzy) allows users to unify and contextualize vulnerability findings across DevSecOps tools and products, enabling central prioritization, visualization, and automation of security findings.

In the initial version of this integration, we bring container image [vulnerability assessmentsï»¿](https://dt-url.net/jt43w8r) (part of the [Microsoft Defender for Containers planï»¿](https://dt-url.net/vm63w5d)), powered by [Microsoft Defender Vulnerability Managementï»¿](https://dt-url.net/c483wfr) capabilities.

### Use cases

* Visualize and report your current security posture and trends around security findings across environments with [![Dashboards](https://dt-cdn.net/images/dashboards-512-b1f1e9690b.png "Dashboards") **Dashboards**](/docs/analyze-explore-automate/dashboards-and-notebooks/dashboards-new "Create interactive, customizable views to visualize, analyze, and share your observability data in real time.").
* Analyze and prioritize security findings across multiple tools and products uniformly with [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace.").
* Create notifications and tickets for critical security findings with [![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows**](/docs/analyze-explore-automate/workflows "Automate IT processes with Dynatrace Workflowsâreact to events, schedule tasks, and connect services.").
* Use security findings as an additional dimension for threat hunting and incident forensics using [![Investigations](https://dt-cdn.net/images/security-investigator-256-93f6c187d9.png "Investigations") **Investigations**](/docs/secure/investigations "Combine Grail functionalities for evidence-driven investigations, including incident resolution, root cause analysis, and threat hunting.").

### Requirements

See below for the Microsoft Defender for Cloud and Dynatrace requirements.

#### Microsoft Defender for Cloud requirements

* [Enable vulnerability assessment powered by Microsoft Defender Vulnerability Managementï»¿](https://dt-url.net/nx63wk0)
* Install the [Azure CLIï»¿](https://dt-url.net/yb43whw).

#### Dynatrace requirements

* Permissions:

  + To query ingested data: `storage:security.events:read`.
* Tokens:

  + Generate an access token with the `openpipeline.events_security` scope and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").

## Activation and setup

1. In Dynatrace, open  [**Hub**](/docs/manage/hub "See the information about Dynatrace Hub.").
2. Look for **Microsoft Defender for Cloud** and select **Install**.
3. Select **Set up**, then select  **Configure new connection**.
4. Follow the on-screen instructions to set up the ingestion.

## Details

### How it works

![how it works](https://dt-cdn.net/images/image-20250306-160951-3063-719dabfeb2.png)

1. Events are ingested into Dynatrace

1. Microsoft Defender for Cloud [continuously exportsï»¿](https://dt-url.net/lla3wnv) security findings to [Azure Event Hubsï»¿](https://dt-url.net/zmc3wv9).
2. An [Azure Functionï»¿](https://dt-url.net/b643w2v) app pre-processes the events and sends them to Dynatrace, taking advantage of the [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.") dedicated [security events ingest endpoint](/docs/secure/threat-observability/security-events-ingest/ingest-custom-data#default "Ingest security events from custom third-party products via API.").

2. Security findings are processed and stored in Grail

1. The fetched data is mapped to the [Dynatrace Semantic Dictionary](/docs/semantic-dictionary/model/security-events#vulnerability-finding-events "Get to know the Semantic Dictionary models related to security events.").
2. Data is stored in [Grail](/docs/platform/grail "Insights on what and how you can query Dynatrace data.") in a unified format, in a default bucket called `default_securityevents`. For details, see [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.").

### Monitor data

Once you ingest your Microsoft Defender for Cloud data into Grail, you can monitor your data in the app (in Dynatrace, go to **Settings** > **Microsoft Defender for Cloud**).

![msftdefender](https://dt-cdn.net/images/2025-06-05-11-31-30-1437-f22714114f.png)

You can view

* A chart of ingested data from all existing connections over time

  + Available actions: [Query ingested data](#query)
* A table with information about your connections

  + Available actions: [Delete connection](#remove)

### Visualize and analyze findings

You can create your own [dashboards](/docs/analyze-explore-automate/dashboards-and-notebooks/dashboards-new "Create interactive, customizable views to visualize, analyze, and share your observability data in real time.") or use our templates to visualize and analyze container vulnerability findings.

1. In Dynatrace, go to **Settings** > **Microsoft Defender for Cloud**.
2. In the **Try our templates** section, select the desired dashboard template.

### Automate and orchestrate findings

You can create your own [workflows](/docs/analyze-explore-automate/workflows "Automate IT processes with Dynatrace Workflowsâreact to events, schedule tasks, and connect services.") or use our templates to automate and orchestrate container vulnerability findings.

1. In Dynatrace, go to **Settings** > **Microsoft Defender for Cloud**.
2. In the **Try our templates** section, select the desired workflow template.

### Query ingested data

You can query ingested data in [**![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks****](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace.") or [![Investigations](https://dt-cdn.net/images/security-investigator-256-93f6c187d9.png "Investigations") **Investigations**](/docs/secure/investigations "Combine Grail functionalities for evidence-driven investigations, including incident resolution, root cause analysis, and threat hunting."), using the data format in [Semantic Dictionaryï»¿](https://dt-url.net/3q03pb0).

1. In Dynatrace, go to **Settings** > **Microsoft Defender for Cloud**.
2. Select **Open with** .
3. Select **Investigations** or **Notebooks**.

### Evaluate, triage, and investigate detection findings

You can evaluate, triage, and investigate detection findings with [![Threats & Exploits](https://dt-cdn.net/images/attacks-512-b922840b12.png "Threats & Exploits") **Threats & Exploits**](/docs/secure/threats-and-exploits "Understand, triage, and investigate detection findings and alerts.").

1. In Dynatrace, open ![Threats & Exploits](https://dt-cdn.net/images/attacks-512-b922840b12.png "Threats & Exploits") **Threats & Exploits**.
2. Filter for **Provider** > **Microsoft Defender for Cloud**.

### Delete connections

To stop sending events to Dynatrace

1. In Dynatrace, go to **Settings** > **Microsoft Defender for Cloud**.
2. For the connection you want to delete, select  **Delete**.
3. Follow the on-screen instructions to delete the resources. If you used values different from those specified in the setup dialog, adjust them accordingly.

This removes the Dynatrace resources created for this integration.

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## FAQ

### Which data model is used for the security logs and events coming from Microsoft Defender for Cloud?

* [Vulnerability finding events](/docs/semantic-dictionary/model/security-events#vulnerability-finding-events "Get to know the Semantic Dictionary models related to security events.") store the individual vulnerability findings reported by Microsoft Defender for Cloud per container image and component.
* [**Vulnerability scan events**](/docs/semantic-dictionary/model/security-events#vulnerability-scan-events "Get to know the Semantic Dictionary models related to security events.") indicate coverage of scans for individual container images.

### Which extension fields are added on the events ingested from Microsoft Defender for Cloud?

The `container_image` namespace is added to store all the container image-related information with the following fields:

* `container_image.digest` represents the container image digest; this value can be used to match to the runtime containers
* `container_image.repository` represents the container repository name
* `container_image.registry` represents the container registry name
* `container_image.tags` represents the labeled versions of the container images

### What Microsoft Defender for Cloud asset types are supported by Dynatrace for runtime contextualization?

`CONTAINER_IMAGE`: All the findings from Microsoft Defender for Cloud are generated by vulnerability assessments of container images set with `CONTAINER_IMAGE` value in the `object.type` field, and the `container_image` namespace is added.

### How do we normalize the risk score for Microsoft Defender for Cloud findings?

Dynatrace normalizes severity and risk scores for all findings ingested through the current integration. This helps you to prioritize findings consistently, regardless of their source.  
For details on how normalization works, see [Severity and score normalization](/docs/secure/threat-observability/concepts#normalization "Basic concepts related to Threat Observability").

* `dt.security.risk.level` is mapped directly from the severity level set by Microsoft Defender for Cloud.
* `dt.security.risk.score` is mapped directly from the severity score set by Microsoft Defender for Cloud.

| `dt.security.risk.level` (mapped from `finding.severity`) | `dt.security.risk.score` (mapped from `finding.score`) |
| --- | --- |
| Critical -> CRITICAL | 9.0-10.0 |
| High -> HIGH | 7.0-8.9 |
| Medium -> MEDIUM | 4.0-6.9 |
| Low -> LOW | 0.1-3.9 |
| Unknown, None -> NONE | 0.0 |

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Ingest Microsoft Defender for Cloud security findings and scan events.](https://www.dynatrace.com/hub/detail/microsoft-defender-for-cloud)

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-microsoft-entra-id.md


---
title: Ingest Microsoft Entra ID sign-in logs
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-microsoft-entra-id
scraped: 2026-02-17T21:17:18.503954
---

# Ingest Microsoft Entra ID sign-in logs

# Ingest Microsoft Entra ID sign-in logs

* Latest Dynatrace
* How-to guide
* Updated on Aug 25, 2025

Ingest Microsoft Entra ID sign-in logs and analyze them in Dynatrace.

## Get started

### Overview

In the following, you'll learn how to ingest sign-in logs from your [Microsoft Entra IDï»¿](https://www.microsoft.com/en-us/security/business/identity-access/microsoft-entra-id) instance into Grail and monitor them on the Dynatrace platform.

### Use cases

With the ingested data, you can leverage Dynatrace platform to monitor your Microsoft Entra ID sign-in activity and access to business-critical organization applications, spotting anomalies and staying ahead of potential threats. For details, see [Monitor suspicious sign-in activity with Dynatrace](/docs/secure/use-cases/monitor-sign-in-activity "Analyze suspicious and malicious sign-in behaviors with Dynatrace.").

### Requirements

* Enable Entra ID sign-in logs forwarding to Dynatrace via either of these options:

  + **Option 1**: [Azure log forwarding](/docs/ingest-from/microsoft-azure-services/azure-integrations/set-up-log-forwarder-azure "Use Azure log forwarding to ingest Azure logs.")
  + **Option 2**: [Azure Native Dynatrace Service](/docs/ingest-from/microsoft-azure-services/azure-platform/azure-native-integration "Set and configure your Dynatrace SaaS environment using Azure Marketplace.")
* Permissions:

  + To query ingested logs: `storage:logs:read`.

## Activation and setup

To set up Microsoft Entra ID sign-in log monitoring, follow the steps below.

1. Configure the OpenPipeline built-in processor

1. In Dynatrace, go to ![Settings](https://dt-cdn.net/images/settings-icon-256-38e1321b51.webp "Settings") **Settings** > **Process and contextualize** > **OpenPipeline** and select **Logs**.
2. Go to **Pipelines** and select  **Pipeline**.
3. Under **Processing**, select **Processor** > **Technology bundle** > **Azure Entra ID Audit Logs**.
4. Select **Choose**.
5. Enter a name for your Azure pipeline and select **Save**.
6. Under **Dynamic routing**, select  **Dynamic route**.
7. Enter the following matching condition:

   ```
   matchesValue(cloud.provider, "azure") AND



   matchesPhrase(content, "\"SignInLogs\"")
   ```
8. Select the newly created pipeline, enter a name for the Dynamic route, and select **Add**.

2. Verify configuration

Verify the configuration by running the following query in [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace."):

```
fetch logs



| filter cloud.provide == "azure"



AND isNotNull(audit.action)



AND isNotNull(authentication.is_multifactor)
```

3. Visualize results with our sample dashboard

1. Download our [sample dashboard from GitHubï»¿](https://dt-url.net/ur03wvb).
2. Open [![Dashboards](https://dt-cdn.net/images/dashboards-512-b1f1e9690b.png "Dashboards") **Dashboards**](/docs/analyze-explore-automate/dashboards-and-notebooks/dashboards-new "Create interactive, customizable views to visualize, analyze, and share your observability data in real time."), select ![Import](https://dt-cdn.net/images/dashboards-app-dashboards-page-import-6a06e645df.svg "Import") **Upload**, then select the downloaded file.

## Details

### How it works

There are two ways to enable Entra ID sign-in logs forwarding to Dynatrace:

* **Option 1**: Via [Azure log forwarding](/docs/ingest-from/microsoft-azure-services/azure-integrations/set-up-log-forwarder-azure "Use Azure log forwarding to ingest Azure logs.")
* **Option 2**: Via [Azure Native Dynatrace Service](/docs/ingest-from/microsoft-azure-services/azure-platform/azure-native-integration "Set and configure your Dynatrace SaaS environment using Azure Marketplace.")

See below for details.

Via Azure log forwarding

Via Azure Native Dynatrace Service

![mechanism1](https://dt-cdn.net/images/image-20250508-154953-2812-e26b3cab6c.png)

1. Logs are ingested into Dynatrace

1. Microsoft Entra ID continuously exports sign-in logs to [Azure Event Hubsï»¿](https://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-about).
2. An [Azure Functionï»¿](https://learn.microsoft.com/en-us/azure/azure-functions/functions-overview?pivots=programming-language-csharp) app pre-processes the logs and sends them to Dynatrace, taking advantage of the [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.") dedicated [log ingest endpoint](/docs/dynatrace-api/environment-api/log-monitoring-v2/post-ingest-logs "Push custom logs to Dynatrace via the Log Monitoring API v2.").

2. Logs are processed and stored in Grail

1. The fetched data is mapped to the [Dynatrace Semantic Dictionary](/docs/semantic-dictionary/model/security-events#vulnerability-finding-events "Get to know the Semantic Dictionary models related to security events.").
2. Data is stored in [Grail](/docs/platform/grail "Insights on what and how you can query Dynatrace data.") in a unified format, in a default bucket called `default_logs`. For details, see [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.").

![mechanism2](https://dt-cdn.net/images/image-20250508-154902-2731-fc140d187d.png)

1. Logs are ingested into Dynatrace

Microsoft Entra ID sign-in logs are collected, processed, and sent to Dynatrace by leveraging on the Dynatrace Native Service resource.

2. Logs are processed and stored in Grail

1. The fetched data is mapped to the [Dynatrace Semantic Dictionary](/docs/semantic-dictionary/model/security-events#vulnerability-finding-events "Get to know the Semantic Dictionary models related to security events.").
2. Data is stored in [Grail](/docs/platform/grail "Insights on what and how you can query Dynatrace data.") in a unified format, in a default bucket called `default_logs`. For details, see [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.").

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-microsoft-sentinel.md


---
title: Ingest Microsoft Sentinel security events
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-microsoft-sentinel
scraped: 2026-02-17T21:17:32.615170
---

# Ingest Microsoft Sentinel security events

# Ingest Microsoft Sentinel security events

* Latest Dynatrace
* How-to guide
* Updated on Aug 12, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest Microsoft Sentinel security events and analyze them in Dynatrace.

## Get started

### Overview

Dynatrace integration with [Microsoft Sentinelï»¿](https://www.microsoft.com/en-us/security/business/siem-and-xdr/microsoft-sentinel), a cloud-native security information and event management (SIEM), allows users to unify and contextualize security findings across DevSecOps tools and products, enabling central prioritization, visualization, and automation of security findings.

The integration ingests [security alertsï»¿](https://learn.microsoft.com/en-us/azure/sentinel/security-alert-schema) originated from various [connectorsï»¿](https://learn.microsoft.com/en-us/azure/sentinel/connect-data-sources?tabs=defender-portal), including Microsoft products, such as [Microsoft Defender for Cloudï»¿](https://learn.microsoft.com/en-us/azure/sentinel/connect-defender-for-cloud), as well as [external product connectorsï»¿](https://learn.microsoft.com/en-us/azure/sentinel/data-connectors-reference).

### Use cases

* Visualize and report your current security posture and trends around security findings across environments with [![Dashboards](https://dt-cdn.net/images/dashboards-512-b1f1e9690b.png "Dashboards") **Dashboards**](/docs/analyze-explore-automate/dashboards-and-notebooks/dashboards-new "Create interactive, customizable views to visualize, analyze, and share your observability data in real time.").
* Analyze and prioritize security findings across multiple tools and products uniformly with [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace.").
* Create notifications and tickets for critical security findings with [![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows**](/docs/analyze-explore-automate/workflows "Automate IT processes with Dynatrace Workflowsâreact to events, schedule tasks, and connect services.").
* Use security findings as an additional dimension for threat hunting and incident forensics using [![Investigations](https://dt-cdn.net/images/security-investigator-256-93f6c187d9.png "Investigations") **Investigations**](/docs/secure/investigations "Combine Grail functionalities for evidence-driven investigations, including incident resolution, root cause analysis, and threat hunting.").

### Requirements

See below for the Microsoft Sentinel and Dynatrace requirements.

#### Microsoft Sentinel

* Install the [Azure CLIï»¿](https://dt-url.net/yb43whw).

#### Dynatrace requirements

* Permissions:

  + To query ingested data: `storage:security.events:read`.
* Tokens:

  + Generate an access token with the `openpipeline.events_security` scope and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").

## Activation and setup

1. In Dynatrace, open  [**Hub**](/docs/manage/hub "See the information about Dynatrace Hub.").
2. Look for **Microsoft Sentinel** and select **Install**.
3. Select **Set up**, then select  **Configure new connection**.
4. Follow the on-screen instructions to set up the ingestion.
5. Verify configuration by running the following query in [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace."):

   ```
   fetch security.events



   | filter dt.system.bucket == "default_securityevents"



   | filter event.provider=="Microsoft Sentinel"
   ```

## Details

### How it works

![how it works - MSFT Sentinel](https://dt-cdn.net/images/architecture-diagram-2065-c0e021b96c.png)

1. Events are ingested into Dynatrace

1. Microsoft Sentinel exports security findings to [Azure Event Hubsï»¿](https://dt-url.net/zmc3wv9).
2. An [Azure Functionï»¿](https://dt-url.net/b643w2v) app pre-processes the events and sends them to Dynatrace, taking advantage of the [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.") dedicated [security events ingest endpoint](/docs/secure/threat-observability/security-events-ingest/ingest-custom-data#default "Ingest security events from custom third-party products via API.").

2. Security findings are processed and stored in Grail

1. The fetched data is mapped to the [Dynatrace Semantic Dictionary](/docs/semantic-dictionary/model/security-events#vulnerability-finding-events "Get to know the Semantic Dictionary models related to security events.").
2. Data is stored in [Grail](/docs/platform/grail "Insights on what and how you can query Dynatrace data.") in a unified format, in a default bucket called `default_securityevents`. For details, see [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.").

### Monitor data

Once you ingest your Microsoft Sentinel data into Grail, you can monitor your data in the app (in Dynatrace, go to **Settings** > **Microsoft Sentinel**).

![overview-connection](https://dt-cdn.net/images/settings-dynatrace-microsoft-sentinel-3941-9844470c4c.png)

You can view

* A chart of ingested data from all existing connections over time

  + Available actions: [Query ingested data](#query)
* A table with information about your connections

  + Available actions: [Delete connection](#remove)

### Visualize and analyze findings

You can create your own [dashboards](/docs/analyze-explore-automate/dashboards-and-notebooks/dashboards-new "Create interactive, customizable views to visualize, analyze, and share your observability data in real time.") or use our templates to visualize and analyze container vulnerability findings.

1. In Dynatrace, go to **Settings** > **Microsoft Sentinel**.
2. In the **Try our templates** section, select the desired dashboard template.

### Automate and orchestrate findings

You can create your own [workflows](/docs/analyze-explore-automate/workflows "Automate IT processes with Dynatrace Workflowsâreact to events, schedule tasks, and connect services.") or use our templates to automate and orchestrate container vulnerability findings.

1. In Dynatrace, go to **Settings** > **Microsoft Sentinel**.
2. In the **Try our templates** section, select the desired workflow template.

### Query ingested data

You can query ingested data in [**![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks****](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace.") or [![Investigations](https://dt-cdn.net/images/security-investigator-256-93f6c187d9.png "Investigations") **Investigations**](/docs/secure/investigations "Combine Grail functionalities for evidence-driven investigations, including incident resolution, root cause analysis, and threat hunting."), using the data format in [Semantic Dictionaryï»¿](https://dt-url.net/3q03pb0).

1. In Dynatrace, go to **Settings** > **Microsoft Sentinel**.
2. Select **Open with** .
3. Select **Investigations** or **Notebooks**.

### Evaluate, triage, and investigate detection findings

You can evaluate, triage, and investigate detection findings with [![Threats & Exploits](https://dt-cdn.net/images/attacks-512-b922840b12.png "Threats & Exploits") **Threats & Exploits**](/docs/secure/threats-and-exploits "Understand, triage, and investigate detection findings and alerts.").

1. In Dynatrace, open ![Threats & Exploits](https://dt-cdn.net/images/attacks-512-b922840b12.png "Threats & Exploits") **Threats & Exploits**.
2. Filter for **Provider** > **Microsoft Sentinel**.

### Delete connections

To stop sending events to Dynatrace

1. In Dynatrace, go to **Settings** > **Microsoft Sentinel**.
2. For the connection you want to delete, select  **Delete**.
3. Follow the on-screen instructions to delete the resources. If you used values different from those specified in the setup dialog, adjust them accordingly.

This removes the Dynatrace resources created for this integration.

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## FAQ

### Which data model is used for the security logs and events coming from Microsoft Sentinel?

[Detection finding events](/docs/semantic-dictionary/model/security-events#detection-finding-events "Get to know the Semantic Dictionary models related to security events.") store the individual detection findings per affected object represented by an affected Azure resource.

### Which extension fields are added on top of the core fields of the events ingested from Microsoft Sentinel?

* The `actor` namespace is added to store all the actor-related fields if present in an alert:

  + `actor.ips` represents the list of IPs of the suspicious actor
  + `actor.fqdns` represents the list of FQDNs of the suspicious actor
  + `actor.geo.country.name` represents the country name of the suspicious actor
  + `actor.geo.city.name` represents the city name of the suspicious actor
* The `azure` namespace is added to store Azure-related fields in an alert:

  + `azure.tenant.id` represents the ID of the Azure tenant
  + `azure.subscription` represents the ID of the Azure subscription
  + `azure.resource.id` represents the ID of the affect Azure resource
  + `azure.resource.group` represents the name of the Azure resource group
  + `azure.resource.type` represents the name of the Azure resource type
  + `azure.resource.name` represents the name of the Azure resource

### How do we normalize the risk score for Microsoft Sentinel findings?

Dynatrace normalizes severity and risk scores for all findings ingested through the current integration. This helps you to prioritize findings consistently, regardless of their source.  
For details on how normalization works, see [Severity and score normalization](/docs/secure/threat-observability/concepts#normalization "Basic concepts related to Threat Observability").

* `dt.security.risk.level` is mapped directly from the severity level (`AlertSeverity`) set by Microsoft Sentinel.
* `dt.security.risk.score` is mapped directly from the severity level (`AlertSeverity`) set by Microsoft Sentinel.

| `dt.security.risk.level` (mapped from `AlertSeverity`) | `dt.security.risk.score` (mapped from `AlertSeverity`) |
| --- | --- |
| High -> HIGH | High -> 8.9 |
| Medium -> MEDIUM | Medium -> 6.9 |
| Low -> LOW | Low -> 3.9 |
| Informational -> NONE | 0.0 |

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Ingest Microsoft Sentinel security findings.](https://www.dynatrace.com/hub/detail/microsoft-sentinel)

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-ocsf-data.md


---
title: Ingest vulnerability findings in OCSF format
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-ocsf-data
scraped: 2026-02-17T21:17:22.280482
---

# Ingest vulnerability findings in OCSF format

# Ingest vulnerability findings in OCSF format

* Latest Dynatrace
* How-to guide
* Updated on Nov 06, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest vulnerability findings in OCSF format from any provider and analyze them on the Dynatrace platform.

## Get started

### Overview

In the following, you'll learn how to ingest vulnerability findings from any source or provider in a standard format ([Open Cybersecurity Schema Framework (OCSF)ï»¿](https://dt-url.net/bf03qi3)) into [Grail](/docs/platform/grail "Insights on what and how you can query Dynatrace data.") and analyze them on the Dynatrace platform, so you can get Dynatrace insights for vulnerability findings from any source or provider, and easily work with your data on the Dynatrace platform in a unified format.

### Use cases

With the ingested data, you can accomplish various use cases, such as

* [Visualize and analyze security findings](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.")
* [Automate and orchestrate security findings](/docs/secure/use-cases/automate-and-orchestrate-security-findings "Regularly check for critical security findings and get automatic Jira tickets or Slack alerts.")

### Requirements

* Permissions:

  + To query ingested data: `storage:security.events:read`.

## Activation and setup

1. In Dynatrace, open  [**Hub**](/docs/manage/hub "See the information about Dynatrace Hub.").
2. Look for **OCSF** and select **Install**.
3. Select **Set up**, then select  **Configure new connection**.
4. Follow the on-screen instructions to set up the ingestion.

## Details

### How it works

![how-it-works](https://dt-cdn.net/images/image-56-2560-3d1ff640ab.png)

1. Feed OCSF-formatted data into Grail

You feed the OCSF-formatted data into Grail via our built-in security events [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.") endpoint.

For instructions, see [Get started](#start).

2. Data is mapped to the Semantic Dictionary

The OpenPipe ingest endpoint receives the vulnerability findings and maps them according to the [Semantic Dictionaryï»¿](https://dt-url.net/3q03pb0).  
They are stored in the `default_securityevents` bucket (see [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.")).

Ingested data is mapped to Dynatrace Semantic Dictionary. Original vendor data is also preserved alongside the mapped data.

3. Enjoy the data

Once data is ingested into Grail, you can visualize, analyze, and automate data using dashboards, workflows, and queries.

### Monitor data

Once you ingest your OCSF data into Grail, you can monitor your data in the app (in Dynatrace, go to **Settings** > **OCSF**).

You can view:

* A chart of ingested data from all existing connections over time

  + Available actions: [Query ingested data](#query)
* A table with information about your connections

  + Available actions: [Delete connection](#remove)

### Visualize and analyze findings

You can create your own [dashboards](/docs/analyze-explore-automate/dashboards-and-notebooks/dashboards-new "Create interactive, customizable views to visualize, analyze, and share your observability data in real time.") or use our templates to visualize and analyze container vulnerability findings.

To use a dashboard template:

1. In Dynatrace, go to **Settings** > **OCSF**.
2. In the **Try our templates** section, select the desired dashboard template.

### Automate and orchestrate findings

You can create your own [workflows](/docs/analyze-explore-automate/workflows "Automate IT processes with Dynatrace Workflowsâreact to events, schedule tasks, and connect services.") or use our templates to automate and orchestrate container vulnerability findings.

To use a workflow template:

1. In Dynatrace, go to **Settings** > **OCSF**.
2. In the **Try our templates** section, select the desired workflow template.

### Query ingested data

You can query ingested data in [**![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks****](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace.") or [![Investigations](https://dt-cdn.net/images/security-investigator-256-93f6c187d9.png "Investigations") **Investigations**](/docs/secure/investigations "Combine Grail functionalities for evidence-driven investigations, including incident resolution, root cause analysis, and threat hunting."), using the data format in [Semantic Dictionaryï»¿](https://dt-url.net/3q03pb0).

To query ingested data:

1. In Dynatrace, go to **Settings** > **OCSF**.
2. Select **Open with** .
3. Select **Investigations** or **Notebooks**.

### Support

For OCSF, Dynatrace supports vulnerability findings (regardless of the source) following the [OCSF v1.1.0 formatï»¿](https://schema.ocsf.io/1.1.0/).

### Delete connections

To stop sending events to Dynatrace:

1. In Dynatrace, go to **Settings** > **OCSF**.
2. For the connection you want to delete, select  **Delete**.
3. Follow the on-screen instructions to delete the resources. If you used values different from those specified in the setup dialog, adjust them accordingly.

This removes the Dynatrace resources created for this integration.

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Ingest security findings in Open Cybersecurity Schema Framework (OCSF) format.](https://www.dynatrace.com/hub/detail/ocsf)

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-qualys.md


---
title: Ingest Qualys vulnerability findings, scan events, and audit logs
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-qualys
scraped: 2026-02-17T21:17:39.314903
---

# Ingest Qualys vulnerability findings, scan events, and audit logs

# Ingest Qualys vulnerability findings, scan events, and audit logs

* Latest Dynatrace
* Extension
* Published Dec 15, 2025
* Preview

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest Qualys vulnerability findings, scan events, and audit logs into Dynatrace as security events.

## Get started

### Overview

Dynatrace integration with Qualys allows users to unify and contextualize vulnerability findings across DevSecOps tools and products, enabling central prioritization, visualization, and automation of security findings.

[Qualys Enterprise TruRisk platformï»¿](https://www.qualys.com/enterprise-trurisk-platform) offers a range of products, including [Vulnerability Management, Detection, & Response (VMDR)ï»¿](https://www.qualys.com/apps/vulnerability-management-detection-response), which helps detect and prioritize vulnerabilities for remediation on hosts. The Dynatrace platform observes the corresponding applications and services associated with those hosts. Ingesting and enriching vulnerability findings with runtime context helps users to better focus on the top risks that affect their production applications.

### Use cases

With the ingested data, you can accomplish various use cases, such as

* [Visualize and analyze security findings](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.")
* [Discover coverage gaps in security findings](/docs/secure/use-cases/discover-coverage-gaps-in-security-scans "Unveil blind spots in your Software Development Lifecycle (SDLC).")
* [Automate and orchestrate security findings](/docs/secure/use-cases/automate-and-orchestrate-security-findings "Regularly check for critical security findings and get automatic Jira tickets or Slack alerts.")

### Requirements

See below for the [Qualys](#qualys) and [Dynatrace](#dt) requirements.

#### Qualys requirements

To authenticate with a username and password, the user account must have the following permissions:

* **Vulnerability Management module**

  + User Role: **Reader** with API access enabled
  + Asset Groups: access to the relevant asset groups of interest, or to all asset groups
* **Administration module** (needed for the audit log ingest):

  + A **Reader**-type user role is sufficient.
  + To collect activity logs, the role must also include:

    - API access enabled
    - Access to the Administration module (**Action Log Permissions** > **Action Log Access**)

#### Dynatrace requirements

* ActiveGate version 1.310+ that needs to be able to

  + Run Extensions 2.0 framework
  + Reach the Qualys API endpoints
* Permissions: For a list of permissions required, go to  **Hub**, select ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**, and display **Technical information**.
* Generate an access token with the `openpipeline.events_security` scope and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").

## Activation and setup

1. In Dynatrace, search for **Qualys** and select **Install**.
2. Follow the on-screen instructions to configure the extension.
3. Verify configuration by running the following queries in [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace."):

   * For audit logs:

     ```
     fetch logs



     | filter log.source=="Qualys"
     ```
   * For finding events:

     ```
     fetch security.events



     | filter dt.system.bucket == "default_securityevents"



     | filter event.provider=="Qualys"



     AND event.type=="VULNERABILITY_FINDING"
     ```
   * For scan events:

     ```
     fetch security.events



     | filter dt.system.bucket == "default_securityevents"



     | filter event.provider=="Qualys"



     AND event.type=="VULNERABILITY_SCAN"
     ```
4. Once the extension is installed and working, you can access and manage it in Dynatrace via ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**. For details, see [About Extensions](/docs/ingest-from/extensions/concepts "Learn more about the concept of Dynatrace Extensions.").

## Details

### How it works

![how it works](https://dt-cdn.net/images/image-20251202-165058-2086-c9122593e9.png)

Dynatrace integration with Qualys is an [extension](/docs/ingest-from/extensions "Learn how to create and manage Dynatrace Extensions.") running on Dynatrace ActiveGate. Once you enable and configure the Dynatrace Qualys extension

1. It periodically collects security findings and audit logs using [Qualys REST APIï»¿](https://docs.qualys.com/en/vm/api/scans/index.htm#t=get_started%2Fget_started.htm).
2. The fetched data is ingested into Dynatrace and mapped to the [Dynatrace Semantic Dictionary](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.").
3. Data is stored in a bucket called `default_securityevents` (for details, see [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.")).

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## FAQ

### Which data model is used for the security events and audit logs coming from Qualys integration?

* [**Vulnerability finding events**](/docs/semantic-dictionary/model/security-events#vulnerability-finding-events "Get to know the Semantic Dictionary models related to security events.") store the individual vulnerability findings reported by Qualys per affected artifacts and component.
* [**Vulnerability scan events**](/docs/semantic-dictionary/model/security-events#vulnerability-scan-events "Get to know the Semantic Dictionary models related to security events.") indicate coverage of scans for individual artifacts.
* [**Audit logs**](/docs/semantic-dictionary/model/log#audit-logs "Get to know the Semantic Dictionary models related to Log Analytics.") represent user activity logs in Qualys.

### Which SonarQube security findings are imported into Dynatrace?

* The Qualys VMDR findings are reported by default.
* On the first ingest run, integration ingests all findings updated in the last `m` hours, where `m` is the first ingest interval configured in the monitoring configuration.
* If the extension is configured to ingest data at an interval of `n` hours, then whenever the extension runs, all vulnerability findings updated in the last `n` hours will be ingested.
* If no new or updated findings were detected, no findings will be ingested.

### Which extension fields are added on top of the core fields of the events ingested from Qualys?

* The `qualys` namespace is added for extracting several Qualys-specific attributes for user convenience on top of the original issue JSON, which is stored in `event.original_content` field.

Example fields:

* `qualys.host.asset_id`: ID assigned to all assets in the subscription that is not exposed in VMDR.
* `qualys.host.tracking_method`: How the host asset is tracked (for example, Cloud Agent, IP, DNS).
* `qualys.detection.first_found`: When the detection was first found on the asset.
* `qualys.detection.last_found` - When the detection was last found on the asset.
* `qualys.detection.times_found`: How many times this detection has been found.
* `qualys.detection.qds_factors`: A map with details on what has contributed to the Qualys Detection Score.

### What Qualys asset types are supported by Dynatrace for runtime contextualization?

`HOST`: all the findings from Qualys VMDR generated from assessment of hosts are mapped set with HOST value in object.type field, and host namespaces are added with the corresponding fields:

* `host.name`: Hostname of the host asset (if available).
* `host.ip`: IP address of the host asset.
* `host.fqdn`: Fully qualified domain name of the host asset (if available).

### How do we normalize the risk score for Qualys findings?

The Dynatrace risk levels and scores are mapped from the original Qualys severities.

* `dt.security.risk.score` is mapped from the Qualys provided severity score to static scores.
* `dt.security.risk.level` is mapped from the Qualys severity score and mapped from the original values in finding.score.

The Qualys Detection Score (QDS) has a range from 1 to 100. To map this to the 10 point Dynatrace security risk score we divide the QDS by 10.

| `dt.security.risk.score` (mapped from `finding.score`) | `dt.security.risk.level` (mapped from `dt.security.risk.score`) |
| --- | --- |
| 9.0-10.0 | CRITICAL |
| 7.0-8.9 | HIGH |
| 4.0-6.9 | MEDIUM |
| 0.1-3.9 | LOW |

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-runecast-analyzer.md


---
title: Ingest Runecast Analyzer compliance findings
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-runecast-analyzer
scraped: 2026-02-17T21:17:19.745270
---

# Ingest Runecast Analyzer compliance findings

# Ingest Runecast Analyzer compliance findings

* Latest Dynatrace
* How-to guide
* Updated on Aug 25, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest compliance findings from Runecast Analyzer and analyze them on the Dynatrace platform.

## Get started

### Overview

Dynatrace integration with [Runecast Analyzerï»¿](https://www.dynatrace.com/platform/runecast-analyzer/) allows you to access data relevant to Cloud Security Posture Management (CSPM) and VMware Security Posture Management (VSPM) on the Dynatrace platform. It provides options to uniformly visualize, analyze, and automate work related to compliance findings.

Runecast Analyzer ensures continuous compliance through its configuration analysis, generating security-related results for cloud (AWS, Azure, GCP) and VMware (vSphere, NSX-T) environments.

### Requirements

See below for the [Runecast](#runecast) and [Dynatrace](#dt) requirements.

#### Runecast requirements

* Deploy [Runecast Analyzerï»¿](https://www.dynatrace.com/platform/runecast-analyzer/) Runecast version 6.9.12.0+ with active licenses for each system type.
* Permissions: To configure the integration, you need access with the `Global Admin` role.
* Enable security profiles for the supported systems (AWS, Azure, GCP, vCenter, and NSX-T).

#### Dynatrace requirements

* Dynatrace version 1.313+
* Support:

  + Review the [Supported compliance standards and technologies](/docs/secure/application-security/security-posture-management-hub#support "Assess, manage, and take action on misconfigurations and violations against security hardening guidelines and regulatory compliance standards.").
* Permissions:

  + To query ingested data: `storage:security.events:read`.
* Tokens:

  + Generate an access token with the `openpipeline.events_security` scope and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").
* To visualize findings in our ready-made dashboard, make sure [![xSPM](https://dt-cdn.net/images/security-posture-management-highresolution-1024-83a748ecdd.png "xSPM") **Security Posture Management** is installed](/docs/secure/xspm#start "Detect, manage, and take action on security and compliance findings.").

## Activation and setup

To set up the Runecast Analyzer ingestion, follow the steps below.

1. Connect Runecast Analyzer to monitoring systems

1. Log in to your Runecast Analyzer instance.
2. Go to **Menu** in the upper-right corner and select **System settings** > **Connected systems**.
3. Connect Runecast Analyzer to the systems you want to monitor for compliance.

2. Set up the Dynatrace integration

1. Go to Menu in the upper-right corner and select **System settings** > **Integrations**.
2. For **Dynatrace**, turn on **Use Dynatrace Integration**.
3. Select **Edit** and configure the integration as follows:

   * Enter your OpenPipeline endpoint and the Dynatrace API token obtained in [Prerequisites](#dt)
   * Select the systems for which you want to send the results to Dynatrace.
4. Select **Save**.

   ![configure integration](https://dt-cdn.net/images/2025-04-25-11-37-04-761-31b9d23552.png)

3. Start ingesting data

1. Go to **Dashboard** and select **Run Analysis** in the top menu bar. After each analysis, the results for selected systems are sent to Dynatrace.

   There are several ways to trigger analysis: on demand, by periodic schedule, or via the Runecast API.
2. When analysis is complete, you can see the status in **Notifications**.

![analysis complete](https://dt-cdn.net/images/2025-04-25-12-15-58-1079-0aefaa16ad.png)

## Details

### How it works

![how it works C/VSPM](https://dt-cdn.net/images/cspm-1-1570-dca4a64b0c.png)

1. Runecast Analyzer monitors environments

After you deploy and configure Runecast Analyzer, it continuously runs configuration analysis on monitored environments relevant to Cloud Security Posture Management (CSPM) and VMware Security Posture Management (VSPM).

2. Analysis results are ingested into Dynatrace

When Dynatrace integration is configured for a monitored environment, all compliance results are ingested into Dynatrace via a dedicated [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.") security events ingest endpoint with every analysis.

3. Security compliance findings are processed and stored in Grail

The OpenPipeline endpoint processes and maps the results to the security compliance findings according to the [Semantic Dictionary conventionsï»¿](https://dt-url.net/3q03pb0). These are stored in a bucket called `default_securityevents` (for details, see: [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.")).

4. Compliance results are ready to use

Once data is ingested into Grail, you can

* Analyze your environmentsâ security posture and evaluate your compliance with industry standard
* Visualize the posture with the ready-made dashboard, which is part of [![xSPM](https://dt-cdn.net/images/security-posture-management-highresolution-1024-83a748ecdd.png "xSPM") **Security Posture Management**](/docs/secure/xspm "Detect, manage, and take action on security and compliance findings.")

### What's next

Once you set up the Runecast Analyzer integration, you can

* Visualize data with our **Security Posture Overview** dashboard

  + Example dashboard

    ![security posture overview](https://dt-cdn.net/images/2025-04-23-11-05-22-1899-8eeee3d9e4.png)
  + How to access the dashboard

    There are two ways to access the dashboard:

    - Via ![Dashboards](https://dt-cdn.net/images/dashboards-512-b1f1e9690b.png "Dashboards") **Dashboards** (in the **Dashboards** panel, select **Ready-made**)
    - Via  **Hub** (select ![xSPM](https://dt-cdn.net/images/security-posture-management-highresolution-1024-83a748ecdd.png "xSPM") **Security Posture Management**, then look for the dashboard in the **Contents** tab table)
* Query [compliance events](/docs/semantic-dictionary/model/security-events#compliance-finding-events "Get to know the Semantic Dictionary models related to security events.") with [![Investigations](https://dt-cdn.net/images/security-investigator-256-93f6c187d9.png "Investigations") **Investigations**](/docs/secure/investigations "Combine Grail functionalities for evidence-driven investigations, including incident resolution, root cause analysis, and threat hunting.") or [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace.").

  + For a list of DQL examples based on compliance events that you can use for further investigation or reporting, see [Query compliance events](/docs/secure/threat-observability/dql-examples#compliance "DQL examples for security data powered by Grail.").

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-snyk-data.md


---
title: Ingest Snyk vulnerability findings, scans, and audit logs
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-snyk-data
scraped: 2026-02-17T21:17:21.012468
---

# Ingest Snyk vulnerability findings, scans, and audit logs

# Ingest Snyk vulnerability findings, scans, and audit logs

* Latest Dynatrace
* Extension
* Updated on Oct 07, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest Snyk vulnerability findings, scans, and audit logs into Dynatrace as security events.

## Get started

### Overview

Dynatrace integration with [Snykï»¿](https://dt-url.net/4h03x92) allows you to unify and contextualize vulnerability findings across DevSecOps tools and products, enabling central prioritization, visualization, and automation of security findings.

Snyk products ([Snyk Codeï»¿](https://dt-url.net/mr23x60), [Snyk Open Sourceï»¿](https://dt-url.net/7k43x64), [Snyk Containerï»¿](https://dt-url.net/dy63xzt), [Snyk IaCï»¿](https://dt-url.net/6283xq1)) generate vulnerability findings on development artifacts, such as code and containers. The Dynatrace platform observes the corresponding runtime entities associated with those artifacts. Ingesting and enriching vulnerability findings help users to better focus on the top risks that affect their production applications.

### Use cases

With the ingested data, you can accomplish various use cases, such as

* [Visualize and analyze security findings](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.")
* [Discover coverage gaps in security findings](/docs/secure/use-cases/discover-coverage-gaps-in-security-scans "Unveil blind spots in your Software Development Lifecycle (SDLC).")
* [Automate and orchestrate security findings](/docs/secure/use-cases/automate-and-orchestrate-security-findings "Regularly check for critical security findings and get automatic Jira tickets or Slack alerts.")
* Analyze and detect anomalous user activity Coming soon

### Requirements

See below for the [Snyk](#snyk) and [Dynatrace](#dt) requirements.

#### Snyk requirements

[Generate an API tokenâbased service accountï»¿](https://dt-url.net/6ba3xua) with the required [organization-level permissions on each organizationï»¿](https://dt-url.net/6p03wzw). This can be achieved by creating a custom role (recommended) or assigning the **Organization Admin** or **Group Admin** predefined role to the service account.

**Required permissions**: `View organization`, `View audit logs`, `View container image`, `View project`, `View project history`, `View scans`.

#### Dynatrace requirements

* ActiveGate version 1.299+
* Permissions:

  + To run ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**: Go to  **Hub**, select ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**, and display **Technical information**.
  + To query ingested data: `storage:security.events:read`.
* Tokens:

  + Generate an access token with the `openpipeline.events_security` scope and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").

## Activation and setup

1. In Dynatrace, search for **Snyk** and select **Install**.
2. Follow the on-screen instructions to configure the extension.
3. Verify configuration by running the following queries in [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace."):

   * For audit logs:

     ```
     fetch logs



     | filter log.source=="Snyk"
     ```
   * For finding events:

     ```
     fetch security.events



     | filter dt.system.bucket == "default_securityevents"



     | filter event.provider=="Snyk"



     AND event.type=="VULNERABILITY_FINDING"
     ```
   * For scan events:

     ```
     fetch security.events



     | filter dt.system.bucket == "default_securityevents"



     | filter event.provider=="Snyk"



     AND event.type=="VULNERABILITY_SCAN"
     ```
4. Once the extension is installed and working, you can access and manage it in Dynatrace via ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**. For details, see [About Extensions](/docs/ingest-from/extensions/concepts "Learn more about the concept of Dynatrace Extensions.").

## Details

### How it works

![how it works](https://dt-cdn.net/images/image-20250210-114410-2266-9b907186a6.png)

Dynatrace integration with Snyk is an [extension](/docs/ingest-from/extensions "Learn how to create and manage Dynatrace Extensions.") running on Dynatrace ActiveGate. Once you enable and configure the Dynatrace Snyk extension

1. It periodically reaches out to Snyk products and fetches the new vulnerability findings, scans, and audit logs.
2. The fetched data is ingested into Dynatrace and mapped to the [Dynatrace Semantic Dictionaryï»¿](https://dt-url.net/z1c3xsm).
3. Data is stored in a bucket called `default_securityevents` (for details, see [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.")).

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## Feature sets

When activating your extension using [monitoring configuration](#monitoring-configuration), you can limit monitoring to one of the feature sets. To work properly, the extension has to collect at least one metric after the activation.

In highly segmented networks, feature sets can reflect the segments of your environment. Then, when you create a monitoring configuration, you can select a feature set and a corresponding ActiveGate group that can connect to this particular segment.

All metrics that aren't categorized into any feature set are considered to be the default and are always reported.

A metric inherits the feature set of a subgroup, which in turn inherits the feature set of a group. Also, the feature set defined on the metric level overrides the feature set defined on the subgroup level, which in turn overrides the feature set defined on the group level.

## FAQ

### Which data model is used for the security logs and events coming from Snyk?

* [**Vulnerability finding events**](/docs/semantic-dictionary/model/security-events#vulnerability-finding-events "Get to know the Semantic Dictionary models related to security events.") store the individual vulnerability findings reported by various Snyk products per affected artifacts and components.
* [**Vulnerability scan events**](/docs/semantic-dictionary/model/security-events#vulnerability-scan-events "Get to know the Semantic Dictionary models related to security events.") indicate coverage of scans for individual artifacts.
* [**Audit logs**](/docs/semantic-dictionary/model/log#audit-logs "Get to know the Semantic Dictionary models related to Log Analytics.") represent user activity logs in Snyk products.

### Which extension fields are added to the core fields of the events ingested from Snyk?

* The `container_image` namespace is added for container findings and scans to store all the container image-related information.
* The `snyk` namespace is added to extract several Snyk-specific attributes on top of the original JSON, which is stored in the `event.original_content` field.

  Examples: `snyk.org.name`, `snyk.project.name`, `snyk.project.tags`, `snyk.target.name`, `snyk.target.reference`, and others.

### Which Snyk issues are imported into Dynatrace?

* If the extension is configured to ingest data at an interval of `n` hours, then whenever the extension runs an ingest, all open issues belonging to projects that had a snapshot taken of them in the last `n` hours will be ingested (on the first ingest, Dynatrace considers all the issues in the previous `m` hours, where `m` is the first ingest interval configured in the monitoring configuration).
* If during the last `n` hours, multiple snapshots were taken for the same project, one set of findings will be ingested **for each snapshot**.
* If no snapshots were taken for a project, no findings will be ingested, even if the project has open issues.

### Why doesn't the number of vulnerability findings in Dynatrace match the number of issues in Snyk?

As explained [above](#imported-issues), issues are ingested each time a project snapshot runs, meaning that if an issue wasn't marked as resolved between snapshot runs, Dynatrace will ingest it twice.

To comply with the Dynatrace Semantic Dictionary, some Snyk issues are split into multiple vulnerability findings when ingested into Dynatrace.

To count the number of Snyk issues from the data in Dynatrace, you can use a `| dedup snyk.issue.id` command.

### What Snyk asset types are supported by Dynatrace for runtime contextualization?

`CONTAINER_IMAGE`: All the findings from Snyk Container coming from the assessment of container images are mapped with the `CONTAINER_IMAGE` value in the `object.type` field, and the `container_image` namespace is added with the corresponding fields:

* `container_image.digest` is set to the container image digest. This value can be used to match the runtime containers.

  For some containers, for example, containers import into Snyk from CLI, the digest is not available.
* `container_image.repository` represents the container repository name.
* `container_image.registry` represents the container registry name.
* `container_image.tags` represents the tags set on the container image.
* `container_image.id` represents the ID of the container image.

For some of the images, for example, those imported from CLI, Snyk doesnât report the container image digest. By default, `container_image.digest` is used for runtime contextualization, but for these cases, `container_image.id` might need to be used.

### How is the risk score for Snyk findings normalized?

Dynatrace normalizes severity and risk scores for all findings ingested through the current integration. This helps you to prioritize findings consistently, regardless of their source.
For details on how normalization works, see [Severity and score normalization](/docs/secure/threat-observability/concepts#normalization "Basic concepts related to Threat Observability").

The Dynatrace risk levels and scores are mapped from the original [Snyk severity and scoreï»¿](https://dt-url.net/ek03whg).

* `dt.security.risk.level` is taken from the Snyk severity level and mapped from the original values in `finding.severity`.
* `dt.security.risk.score` is taken from the Snyk severity level and mapped to static scores. The CVSS score (CVSS v3 or v4, for vulnerabilities reported after 2024) reported by Snyk is available in `finding.score`; however, this may not always match the reported severity.

| `dt.security.risk.level` (mapped from `finding.severity`) | `dt.security.risk.score` (mapped from `dt.security.risk.level`) |
| --- | --- |
| critical -> CRITICAL | 10.0 |
| high -> HIGH | 8.9 |
| medium -> MEDIUM | 6.9 |
| low -> LOW | 3.9 |

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Ingest Snyk vulnerability findings, scans, and audit logs.](https://www.dynatrace.com/hub/detail/snyk-1/)

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-sonarqube-data.md


---
title: Ingest SonarQube security and quality events, metrics, and audit logs
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-sonarqube-data
scraped: 2026-02-17T21:17:38.053024
---

# Ingest SonarQube security and quality events, metrics, and audit logs

# Ingest SonarQube security and quality events, metrics, and audit logs

* Latest Dynatrace
* Extension
* Updated on Oct 07, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest SonarQube security and quality events, metrics, and audit logs into Dynatrace as security events.

## Get started

### Overview

The Dynatrace integration with [SonarQubeï»¿](https://www.sonarsource.com/) allows you to unify and contextualize vulnerability findings across DevSecOps tools and products, enabling central prioritization, visualization, and automation of security findings.

SonarQube generates vulnerability findings on development artifacts like code and configuration files. The Dynatrace platform observes the corresponding runtime entities associated with those artifacts. Ingesting and enriching vulnerability findings helps users to better focus on the top risks that affect their production applications.

In this integration, in addition to the audit logs and security events, Dynatrace ingests various SonarQube quality metrics and generates Software Development Lifecycle (SDLC) events to represent assessments of artifacts done within the SDLC pipeline. This allows Dev teams to get a more exhaustive overview of the quality of their applications and services. It also allows SREs to have better visibility and control over the quality of the deployed artifacts from various quality perspectives.

### Use cases

With the ingested data, you can accomplish various use cases, such as

* [Visualize and analyze security findings](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.")
* [Discover coverage gaps in security findings](/docs/secure/use-cases/discover-coverage-gaps-in-security-scans "Unveil blind spots in your Software Development Lifecycle (SDLC).")
* [Automate and orchestrate security findings](/docs/secure/use-cases/automate-and-orchestrate-security-findings "Regularly check for critical security findings and get automatic Jira tickets or Slack alerts.")

### Requirements

[SonarQube Server Web API v1ï»¿](https://docs.sonarsource.com/sonarqube-server/latest/extension-guide/web-api/)

#### SonarQube requirements

* [Generate an API tokenï»¿](https://docs.sonarsource.com/sonarqube-server/latest/user-guide/managing-tokens/#generating-a-token) with the system administrator and `Browse` permissions on the projects to monitor.

#### Dynatrace requirements

* ActiveGate version 1.313+ that needs to be able to

  + Run Extensions 2.0 framework
  + Reach the SonarQube API endpoint URL
* Permissions: For a list of permissions required, go to  **Hub**, select ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**, and display **Technical information**.
* Generate an access token with the `openpipeline.events_security` and `openpipeline.events_sdlc` scopes and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").

## Activation and setup

1. In Dynatrace, search for **SonarQube** and select **Install**.
2. Follow the on-screen instructions to configure the extension.
3. Verify configuration by running the following queries in [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace."):

   * For audit logs:

     ```
     fetch logs



     | filter log.source=="SonarQube"
     ```
   * For security finding events:

     ```
     fetch security.events



     | filter dt.system.bucket == "default_securityevents"



     | filter event.provider=="SonarQube"



     AND event.type=="VULNERABILITY_FINDING"
     ```
   * For security scan events:

     ```
     fetch security.events



     | filter dt.system.bucket == "default_securityevents"



     | filter event.provider=="SonarQube"



     AND event.type=="VULNERABILITY_SCAN"
     ```
   * For SDLC events:

     ```
     fetch events



     | filter event.kind == "SDLC_EVENT"



     AND event.type == "control"



     | filter event.provider=="SonarQube"
     ```
   * For metrics:

     ```
     timeseries {



     Vulnerabilities = sum(sonarqube.code.vulnerabilities),



     Hotspots = sum(sonarqube.security.hotspots),



     `Hotspots reviewed` = sum(sonarqube.security.hotspots.reviewed),



     Bugs = sum(sonarqube.bugs),



     Coverage = sum(sonarqube.code.coverage),



     `Duplicated lines` = sum(sonarqube.code.duplication),



     `Code smells` = sum(sonarqube.code.smells)



     }, interval:3h
     ```
4. Once the extension is installed and working, you can access and manage it in Dynatrace via ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**. For details, see [About Extensions](/docs/ingest-from/extensions/concepts "Learn more about the concept of Dynatrace Extensions.").

## Details

### How it works

![mechanism sonarqube](https://dt-cdn.net/images/architecture-diagram-1-2560-7fb217b566.png)

Dynatrace integration with SonarQube is an [extension](/docs/ingest-from/extensions "Learn how to create and manage Dynatrace Extensions.") running on Dynatrace ActiveGate. Once you enable and configure the Dynatrace SonarQube extension

1. It periodically collects security findings and audit logs using [SonarQube Web API v1ï»¿](https://docs.sonarsource.com/sonarqube-server/latest/extension-guide/web-api/).
2. The fetched data is ingested into Dynatrace and mapped to the [Dynatrace Semantic Dictionary](/docs/semantic-dictionary/model/security-events#vulnerability-finding-events "Get to know the Semantic Dictionary models related to security events.").
3. Data is stored in a bucket called `default_securityevents` (for details, see [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.")).

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## FAQ

### Which data model is used for the security logs and events coming from SonarQube?

* [**Vulnerability finding events**](/docs/semantic-dictionary/model/security-events#vulnerability-finding-events "Get to know the Semantic Dictionary models related to security events.") store the individual vulnerability findings reported by SonarQube per affected artifacts and component.
* [**Vulnerability scan events**](/docs/semantic-dictionary/model/security-events#vulnerability-scan-events "Get to know the Semantic Dictionary models related to security events.") indicate coverage of scans for individual artifacts.
* [**Audit logs**](/docs/semantic-dictionary/model/log#audit-logs "Get to know the Semantic Dictionary models related to Log Analytics.") represent user activity logs in SonarQube.
* **SDLC control events** indicate a control validation run.

### Which SonarQube security findings are imported into Dynatrace?

* If the extension is configured to ingest data at an interval of `n` hours, whenever the extension runs, all security findings generated in the last `n` hours will be ingested.
* On the first ingest, all findings updated in the last `m` hours are considered, where `m` is the first ingest interval configured in the monitoring configuration.
* If no scans occurred, no findings are ingested, even if the project has open issues.

### Which extension fields are added on top of the core fields of the events ingested from SonarQube?

The `sonarqube` namespace is added for extracting several SonarQube-specific attributes for user convenience on top of the original issue JSON, which is stored in the `dt.raw_data` field.

Example fields:

* `sonarqube.project.name`
* `sonarqube.project.id`
* `sonarqube.revision`
* `sonarqube.revision.author`
* `sonarqube.tags`
* `sonarqube.component`

### What SonarQube asset types are supported by Dynatrace for runtime contextualization?

`CODE_ARTIFACT`: All findings from SonarQube are generated by vulnerability assessments of code artifacts set with the `CODE_ARTIFACT` value in the `object.type` field. The `artifact` and `code` namespaces are added with the corresponding fields:

* `artifact.repository.name`: the repository name which hosts the artifact.
* `artifact.path`: the full path of the file representing the code artifact.
* `code.filepath`: includes the version of the vulnerable component.
* `code.line.number`: the line number where issue has been detected.
* `code.line.offset.start`: the first character number within the line with the issue.
* `code.line.offset.end`: the last character number within the line with the issue.
* `code.line.start`: the line number where the issue starts. Same as `code.line.number`.
* `code.line.end`: the line number where the issue ends.

### How do we normalize the risk score for SonarQube findings?

Dynatrace normalizes severity and risk scores for all findings ingested through the current integration. This helps you to prioritize findings consistently, regardless of their source.  
For details on how normalization works, see [Severity and score normalization](/docs/secure/threat-observability/concepts#normalization "Basic concepts related to Threat Observability").

The Dynatrace risk levels and scores are mapped from the original [SonarQube severitiesï»¿](https://docs.sonarsource.com/sonarqube-server/10.4/user-guide/issues/#issue-severity).

* `dt.security.risk.level` is taken from the SonarQube severity level and mapped from the original values in `finding.severity`.
* `dt.security.risk.score` is mapped from the SonarQube provided severity level to static scores.

| `dt.security.risk.level` (mapped from `finding.severity`) | `dt.security.risk.score` (mapped from `dt.security.risk.level`) |
| --- | --- |
| BLOCKER/CRITICAL/HIGH  HIGH | 8.9 |
| MEDIUM/MAJOR  MEDIUM | 6.9 |
| MINOR/INFO/LOW  LOW | 3.9 |

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Ingest SonarQube vulnerability findings, metrics, and audit logs.](https://www.dynatrace.com/hub/detail/sonarqube)

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-sonatype.md


---
title: Ingest Sonatype Lifecycle security events and audit logs
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-sonatype
scraped: 2026-02-17T21:17:28.671188
---

# Ingest Sonatype Lifecycle security events and audit logs

# Ingest Sonatype Lifecycle security events and audit logs

* Latest Dynatrace
* Extension
* Updated on Oct 07, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest Sonatype Lifecycle security events and audit logs into Dynatrace as security events.

## Get started

### Overview

Dynatrace integration with [Sonatype Lifecycleï»¿](https://www.sonatype.com/products/open-source-security-dependency-management) allows users to unify and contextualize vulnerability findings across DevSecOps tools and products, enabling central prioritization, visualization, and automation of security findings.

Sonatype offers a range of products to help developers improve their productivity. The [Sonatype Lifecycle productï»¿](https://help.sonatype.com/en/sonatype-lifecycle.html) identifies vulnerabilities in development artifacts, such as code and containers. The Dynatrace platform observes the corresponding runtime entities associated with those artifacts. Ingesting and enriching vulnerability findings helps users to better focus on the top risks that affect their production applications.

### Use cases

With the ingested data, you can accomplish various use cases, such as

* [Visualize and analyze security findings](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.")
* [Discover coverage gaps in security findings](/docs/secure/use-cases/discover-coverage-gaps-in-security-scans "Unveil blind spots in your Software Development Lifecycle (SDLC).")
* [Automate and orchestrate security findings](/docs/secure/use-cases/automate-and-orchestrate-security-findings "Regularly check for critical security findings and get automatic Jira tickets or Slack alerts.")

### Requirements

See below for the [Sonatype Lifecycle](#sonatype) and [Dynatrace](#dt) requirements.

#### Sonatype Lifecycle requirements

To enable the extension to collect security data from Sonatype Lifecycle, authentication credentials with appropriate permissions are required. There are two options to provide credentials:

* **Option 1**: [User tokenï»¿](https://help.sonatype.com/en/iq-server-user-tokens.html) Recommended

  + Recommended for service users.
  + Consists of a user code and a passcode.
  + These are disposable credentials that can be revoked at any time without impacting the associated user account.
* **Option 2**: Username and password

  + Uses your accountâs standard login credentials.

**Required permissions**:

To ensure successful data collection, the authenticated user must have the following permissions in Sonatype Lifecycle:

* `View IQ Elements`
* `Access Audit Log` (required only if audit log ingestion is configured)

#### Dynatrace requirements

* ActiveGate version 1.313+ that needs to be able to

  + Run Extensions 2.0 framework
  + Reach the Sonatype API endpoints
* Permissions: For a list of permissions required, go to  **Hub**, select ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**, and display **Technical information**.
* Generate an access token with the `openpipeline.events_security` scope and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").

## Activation and setup

1. In Dynatrace, search for **Sonatype Lifecycle** and select **Install**.
2. Follow the on-screen instructions to configure the extension.
3. Verify configuration by running the following queries in [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace."):

   * For audit logs:

     ```
     fetch logs



     | filter log.source=="Sonatype Lifecycle"
     ```
   * For finding events:

     ```
     fetch security.events



     | filter dt.system.bucket == "default_securityevents"



     | filter event.provider=="Sonatype Lifecycle"



     AND event.type=="VULNERABILITY_FINDING"
     ```
   * For scan events:

     ```
     fetch security.events



     | filter dt.system.bucket == "default_securityevents"



     | filter event.provider=="Sonatype Lifecycle"



     AND event.type=="VULNERABILITY_SCAN"
     ```
4. Once the extension is installed and working, you can access and manage it in Dynatrace via ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**. For details, see [About Extensions](/docs/ingest-from/extensions/concepts "Learn more about the concept of Dynatrace Extensions.").

## Details

### How it works

![how it works - sonatype](https://dt-cdn.net/images/architechture-diagram-2560-277696e6e1.png)

Dynatrace integration with Sonatype Lifecycle is an [extension](/docs/ingest-from/extensions "Learn how to create and manage Dynatrace Extensions.") running on Dynatrace ActiveGate. Once you enable and configure the Dynatrace Sonatype Lifecycle extension

1. It periodically collects security findings and audit logs using [Sonatype REST APIï»¿](https://help.sonatype.com/en/rest-apis.html).
2. The fetched data is ingested into Dynatrace and mapped to the [Dynatrace Semantic Dictionary](/docs/semantic-dictionary/model/security-events#vulnerability-finding-events "Get to know the Semantic Dictionary models related to security events.").
3. Data is stored in a bucket called `default_securityevents` (for details, see [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.")).

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## FAQ

### Which data model is used for the security logs and events coming from Sonatype Lifecycle?

* [Vulnerability finding events](/docs/semantic-dictionary/model/security-events#vulnerability-finding-events "Get to know the Semantic Dictionary models related to security events.") store the individual vulnerability findings reported by Sonatype Lifecycle per affected artifacts and component.
* [**Vulnerability scan events**](/docs/semantic-dictionary/model/security-events#vulnerability-scan-events "Get to know the Semantic Dictionary models related to security events.") indicate coverage of scans for individual artifacts.
* [**Audit logs**](/docs/semantic-dictionary/model/log#audit-logs "Get to know the Semantic Dictionary models related to Log Analytics.") represent user activity logs in Sonatype Lifecycle.

### Which Sonatype Lifecycle security findings are imported into Dynatrace?

* On the first ingest, we consider findings updated in the last `m` hours, where `m` is the first ingest interval configured in the monitoring configuration.
* If the extension is configured to ingest data at an interval of `n` hours, then whenever the extension runs all vulnerability findings updated in the last `n` hours will be ingested.
* If no new or updated findings were detected, no findings will be ingested.

### Which extension fields are added to the core fields of the events ingested from Sonatype Lifecycle?

The `sonatype` namespace is added for extracting several Sonatype-specific attributes for user convenience on top of the original issue JSON, which is stored in the `event.original_content` field.

**Examples**:

* `sonatype.application_public_id` represents the friendly name of the assessed application.
* `sonatype.application_internal_id` represents the ID of the assessed application.
* `sonatype.commit_hash` represents the hash of a code commit that the assessment belongs to.
* `sonatype.stage` represents the application stage at which the assessment was performed.

### What Sonatype Lifecycle asset types are supported by Dynatrace for runtime contextualization?

`CODE_ARTIFACT`: All the findings from Sonatype Lifecycle coming from the assessment of code artifacts are mapped set with `CODE_ARTIFACT` value in the `object.type` field, and the `software_component` namespace is added with the corresponding fields:

* `software_component.purl` represents the package URL of the vulnerable software component.
* `software_component.ecosystem` represents the ecosystem of the component, such as maven, npm, and others.
* `software_component.type` represents the type of the vulnerable software component.
* `software_component.name` represents the name of the vulnerable library within a code artifact.
* `software_component.version` represents the version of the vulnerable component.

### How is the risk score for Sonatype Lifecycle findings normalized?

Dynatrace normalizes severity and risk scores for all findings ingested through the current integration. This helps you to prioritize findings consistently, regardless of their source.  
For details on how normalization works, see [Severity and score normalization](/docs/secure/threat-observability/concepts#normalization "Basic concepts related to Threat Observability").

The Dynatrace risk levels and scores are mapped from the original Sonatype Lifecycle scores.

* `dt.security.risk.score` - is mapped from the Sonatype Lifecycle provided severity score to static scores.
* `dt.security.risk.level` - is mapped from the Sonatype Lifecycle severity score and mapped from the original values in `finding.score`.

| `dt.security.risk.score` (mapped from `finding.score`) | `dt.security.risk.level` (mapped from `dt.security.risk.score`) |
| --- | --- |
| 9.0-10.0 | CRITICAL |
| 7.0-8.9 | HIGH |
| 4.0-6.9 | MEDIUM |
| 0.1-3.9 | LOW |

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Ingest Sonatype vulnerability findings, scans, and audit logs.](https://www.dynatrace.com/hub/detail/sonatype-lifecycle)

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: ingest-tenable-data.md


---
title: Ingest Tenable vulnerability findings, scan events, and audit logs
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/ingest-tenable-data
scraped: 2026-02-17T21:17:30.003926
---

# Ingest Tenable vulnerability findings, scan events, and audit logs

# Ingest Tenable vulnerability findings, scan events, and audit logs

* Latest Dynatrace
* Extension
* Updated on Sep 30, 2025

This page has been updated to align with the new Grail security events table. For the complete list of updates and actions needed to accomplish the migration, follow the steps in the [Grail security table migration guide](/docs/secure/threat-observability/migration "Understand the changes in the new Grail security table and learn how to migrate to it.").

Ingest Tenable vulnerability findings, scan events, and audit logs into Dynatrace as security events.

## Get started

### Overview

[Tenableï»¿](https://dt-url.net/2o23xof) provides robust solutions for identifying, prioritizing, and addressing vulnerabilities, which are crucial for reducing cyber risks and securing digital infrastructure. Integrating Tenable findings into Dynatrace can enhance your overall security posture by ensuring comprehensive visibility and streamlined vulnerability management.

### Use cases

With the ingested data, you can accomplish various use cases, such as

* [Visualize and analyze security findings](/docs/secure/use-cases/visualize-and-analyze-security-findings "Visualize, prioritize, and analyze ingested security findings.")
* [Discover coverage gaps in security findings](/docs/secure/use-cases/discover-coverage-gaps-in-security-scans "Unveil blind spots in your Software Development Lifecycle (SDLC).")
* [Automate and orchestrate security findings](/docs/secure/use-cases/automate-and-orchestrate-security-findings "Regularly check for critical security findings and get automatic Jira tickets or Slack alerts.")

### Requirements

#### Supported Tenable products

* [Tenable Vulnerability Managementï»¿](https://dt-url.net/fy43w0l) (for vulnerabilities and scan events)
* [Tenable Web App Scanningï»¿](https://dt-url.net/og63xed) (for vulnerabilities and scan events)
* [Tenable Oneï»¿](https://dt-url.net/c703wbm) (for audit logs)

  (more coming soon)

#### Tenable requirements

* [Generate an API access and secret keyï»¿](https://dt-url.net/77i3w5n) with the following roles:

  + **Basic** for vulnerability management and web app scanning

    To get full scan details, ensure that the API key configured has access to read scans and scan history as well. See [APIs used to fetch data](#apis) for details of the APIs required.
  + **Administrator** or **Custom** for audit logs

  For details, see [Tenable-Provided Roles and Privilegesï»¿](https://dt-url.net/rv63woq).

#### Dynatrace requirements

* ActiveGate version 1.299+
* Permissions:

  + To run ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**: Go to  **Hub**, select ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**, and display **Technical information**.
  + To query ingested data: `storage:security.events:read`.
* Tokens:

  + Generate an access token with the `openpipeline.events_security` scope and save it for later. For details, see [Dynatrace API - Tokens and authentication](/docs/dynatrace-api/basics/dynatrace-api-authentication "Find out how to get authenticated to use the Dynatrace API.").

## Activation and setup

1. In Dynatrace, search for **Tenable** and select **Install**.
2. Follow the on-screen instructions to configure the extension.
3. Verify configuration by running the following queries in [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace."):

   * For vulnerabilities and asset scans:

     ```
     fetch security.events



     | filter dt.system.bucket=="default_securityevents"



     | filter event.provider == "Tenable"
     ```
   * For audit logs:

     ```
     fetch logs



     | filter log.source == "Tenable"
     ```
4. Once the extension is installed and working, you can access and manage it in Dynatrace via ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions**. For details, see [About Extensions](/docs/ingest-from/extensions/concepts "Learn more about the concept of Dynatrace Extensions.").

Now you can [visualize findings](#visualize), [analyze audit logs](#analyze) and [automate notifications](#automate).

## Details

### How it works

![how tenable integration works](https://dt-cdn.net/images/2024-12-18-16-47-03-1173-dd965318f4.png)

Dynatrace integration with Tenable is an [extension](/docs/ingest-from/extensions "Learn how to create and manage Dynatrace Extensions.") running on Dynatrace ActiveGate. Once you enable and configure the Dynatrace Tenable extension

1. It periodically reaches out to Tenable products and fetches the new findings, scans, and audit logs from the [Tenable APIs](#apis).

   APIs used to fetch data

   * APIs for vulnerability management:

     + [Export assetsï»¿](https://dt-url.net/6c23wk1)
     + [List scansï»¿](https://dt-url.net/qr43wwo)
     + [List scan historyï»¿](https://dt-url.net/ph63wgp)
     + [Get scan detailsï»¿](https://dt-url.net/bs83wh5)
     + [Get asset detailsï»¿](https://dt-url.net/j0a3w41)
     + [Export vulnerabilitiesï»¿](https://dt-url.net/hac3w16)
   * API for audit logs:

     + [View activity logï»¿](https://dt-url.net/dse3wjb)
   * API for web app scanning:

     + [Search scan configurationsï»¿](https://dt-url.net/ig03xj1)
     + [Search scansï»¿](https://dt-url.net/fi23xnz)
     + [Export findingsï»¿](https://dt-url.net/c443xfn)
2. The fetched data is ingested into Dynatrace and mapped to the [Dynatrace Semantic Dictionaryï»¿](https://dt-url.net/z1c3xsm).
3. Data is stored in a bucket called `default_securityevents` (for details, see: [Built-in Grail buckets](/docs/platform/grail/organize-data#built-in-grail-buckets "Insights on the Grail data model consisting of buckets, tables, and views.")).

### Visualize

1. Open ![Extensions](https://dt-cdn.net/images/dynatrace-extensions-256-9cb05e0f55.png "Extensions") **Extensions** and go to **Tenable**.
2. In **Extension content**, select the desired [ready-made dashboard](/docs/analyze-explore-automate/dashboards-and-notebooks/ready-made-documents/ready-made-dashboards "Use ready-made dashboards to visualize your data right out of the box.").
3. In the **Product** filter, select **Tenable** to view data reported by Tenable, such as critical vulnerabilities and affected objects.

   ![filter for tenable product](https://dt-cdn.net/images/2024-12-11-20-34-24-686-e8338d8bd3.png)

Example result:

![tenable filtered dashboard](https://dt-cdn.net/images/umsaywsjuo-4308-76ecd2e8b2.png)

### Analyze

Open [![Notebooks](https://dt-cdn.net/images/notebooks-768-046137830a.webp "Notebooks") **Notebooks**](/docs/analyze-explore-automate/dashboards-and-notebooks/notebooks "Analyze, visualize, and share insights from your observability dataâall in one collaborative, customizable workspace.") or [![Investigations](https://dt-cdn.net/images/security-investigator-256-93f6c187d9.png "Investigations") **Investigations**](/docs/secure/investigations "Combine Grail functionalities for evidence-driven investigations, including incident resolution, root cause analysis, and threat hunting.") to [query](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.") ingested data, using the data format in [Semantic Dictionaryï»¿](https://dt-url.net/3q03pb0).

For examples of how you can build your queries, see below.

#### Query for logs over time by action

```
fetch logs



| filter log.source == "Tenable"



| makeTimeseries logs=countDistinctExact(id), by:{audit.action}, time:{toTimestamp(received)}, interval:{3h}
```

Example result:

![Logs over time by action](https://dt-cdn.net/images/image-20241209-153005-1988-af39449c8c.png)

#### Query for vulnerability distribution by risk level

```
fetch security.events



| filter dt.system.bucket=="default_securityevents"



| filter event.type == "VULNERABILITY_FINDING"



| filter event.provider == "Tenable"



| dedup {object.id, vulnerability.id}, sort:{timestamp}



| summarize Vulnerabilities=countDistinctExact(vulnerability.id), by:{dt.security.risk.level}



| fieldsAdd order=if(dt.security.risk.level=="CRITICAL", 1, else:



if(dt.security.risk.level=="HIGH", 2, else:



if(dt.security.risk.level=="MEDIUM", 3, else:



if(dt.security.risk.level=="LOW", 4, else:5))))



| sort order asc
```

Example result:

![Vulnerability distribution by risk level](https://dt-cdn.net/images/2024-12-11-19-40-07-1277-3f2f43c90a.png)

#### Query for top 10 scans with the most host coverage

```
fetch security.events



| filter dt.system.bucket=="default_securityevents"



| filter event.type == "VULNERABILITY_SCAN"



| filter event.provider == "Tenable"



| dedup {object.id, scan.id}



| summarize Hosts=countDistinctExact(object.id), by:{scan.name}



| sort Hosts desc



| limit 10
```

Example result:

![Query for top 10 scans with the most host coverage](https://dt-cdn.net/images/2024-12-11-19-42-02-1753-871fb9630c.png)

### Automate notifications

1. Download our [sample workflow for Jiraï»¿](https://dt-url.net/od23qa1) or [sample workflow for Slackï»¿](https://dt-url.net/ko43qsm).
2. Open [![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows**](/docs/analyze-explore-automate/workflows "Automate IT processes with Dynatrace Workflowsâreact to events, schedule tasks, and connect services."), select ![Import](https://dt-cdn.net/images/dashboards-app-dashboards-page-import-6a06e645df.svg "Import") **Upload**, then select the downloaded file.
3. Adjust the workflow to your needs to create notifications for critical Tenable findings.

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## Feature sets

When activating your extension using [monitoring configuration](#monitoring-configuration), you can limit monitoring to one of the feature sets. To work properly, the extension has to collect at least one metric after the activation.

In highly segmented networks, feature sets can reflect the segments of your environment. Then, when you create a monitoring configuration, you can select a feature set and a corresponding ActiveGate group that can connect to this particular segment.

All metrics that aren't categorized into any feature set are considered to be the default and are always reported.

A metric inherits the feature set of a subgroup, which in turn inherits the feature set of a group. Also, the feature set defined on the metric level overrides the feature set defined on the subgroup level, which in turn overrides the feature set defined on the group level.

## FAQ

### Why does my configuration show an error?

Error message: `Failed to assign monitoring configuration to ActiveGate. Reason: Extension com.dynatrace.extension.tenable(<version-number>) not available in cache yet (queued for download)`

If your configuration shows the error message above, it simply means that ActiveGate is still downloading the extension for the cluster. The status should change after a few minutes.

### Why do I see duplicate events?

Duplicate events in the Tenable extension are likely due to the first ingest running multiple times. When a monitoring configuration is assigned to an ActiveGate, the first execution will run an export for a longer timeframe (configurable in the monitoring configuration settings). Anytime the extension is restarted (due to an update, ActiveGate reset, failover, and so on), the first ingest will run again.

You can run a DQL query and [**dedup**](/docs/platform/grail/dynatrace-query-language/commands/filtering-commands#dedup "DQL filter and search commands") the events using the `object.id`, `scan.id`, and `finding.id` fields.

* For `VULNERABILITY_FINDING`, the unique ID is `{object.id, finding.id}`.
* For `VULNERABILITY_SCAN`, the unique ID is `{object.id, scan.id}`.

Example:

```
fetch security.events



| filter dt.system.bucket=="default_securityevents"



| filter event.type == "VULNERABILITY_FINDING"



| filter event.provider == "Tenable"



| dedup {object.id, finding.id}, sort:{timestamp}
```

### Why do some scan events have the same start and end times?

When fetching vulnerabilities, the Tenable extension attempts to match the data with recent scan executions. If the scan mentioned in the Tenable vulnerability can't be found (for example, due to missing permissions), the extension creates a scan event based on this finding. These scan events have the same start and end times as when the vulnerability was found.

### Why isn't my data ingested?

If you installed and configured the extension, but data isnât being ingested, follow the steps below.

1. Open the extension and go to **Health** to check the status of the monitoring configuration.
2. If the status isnât `OK`, scroll down to **Logs** and select **Run query** to see the error information.
3. If the error information isnât enough, or the status shows `OK` but you're still not getting data, extract a support archive from ActiveGate to troubleshoot further.

   How to extract a support archive

   1. Find the ActiveGate ID for the ActiveGate running the configuration and extract a support archive. For details, see [ActiveGate diagnostics: Collect and review locally](/docs/ingest-from/dynatrace-activegate/activegate-diagnostics#collect-and-review-locally "Learn how to run ActiveGate diagnostics").
   2. Unzip the support archive and find the extension log file at `COLLECTOR/<id>/remotepluginmodule/log/extensions/datasources/com.dynatrace.extension.tenable/python3.log`.
4. If the information there is still not sufficient for troubleshooting, enable the `Debug logs` flag in the monitoring configuration and contact Dynatrace Support.

Common causes for missed data ingest include:

* No connectivity between the ActiveGate and Tenable cloud

  **Suggestion**: Attempt to curl the Tenable cloud URL from the ActiveGate to ensure connectivity is working.
* Wrong access and/or secret key

  **Suggestion**: Double-check the credentials configured on the monitoring configuration.
* Missing permissions on the API user

  **Suggestion**: Ensure that the API user can call the [APIs used to fetch data](#apis).

## Which extension fields are added on top of the core fields of the events ingested from Tenable?

The `tenable` namespace is added for extracting several Tenable-specific attributes for user convenience on top of the original issue JSON, which is stored in the `event.original_content` field.

**Examples**:

* `tenable.vpr`
* `tenable.last_found`
* `tenable.first_found`
* `tenable.last_fixed`

## What Tenable asset types are supported by Dynatrace for runtime contextualization?

`HOST` - all the findings from Tenable Vulnerability Management coming from hosts scans are mapped with the `HOST` value in the `object.type` field, and the `host` namespace is added with the corresponding fields:

* `host.name` represents the host name as detected by Tenable.
* `host.ip` represents the host IP address scanned by Tenable.
* `host.fqdn` represents the host FQDN as resolved by Tenable.

Runtime contextualization can be done from the `host.ip` field.

### How is the risk score for Tenable findings normalized?

Dynatrace normalizes severity and risk scores for all findings ingested through the current integration. This helps you to prioritize findings consistently, regardless of their source.  
For details on how normalization works, see [Severity and score normalization](/docs/secure/threat-observability/concepts#normalization "Basic concepts related to Threat Observability").

The Dynatrace risk levels and scores are mapped from the original [Tenable severityï»¿](https://dt-url.net/j103w2v).

Tenable uses the VPR score. However, the severity levels are set from CVSS scores (v2 or v3, depending on the [configurationï»¿](https://dt-url.net/tg23we5)). Therefore, Dynatrace maps the severity to the risk level and then assigns the appropriate risk score based on it.

* `dt.security.risk.level` is taken from the Tenable severity level and mapped from the original values in `finding.severity`.
* `dt.security.risk.score` is mapped from the mapped risk level to a set of static scores.

| `dt.security.risk.level` (mapped from `finding.severity`) | `dt.security.risk.score` (mapped from `dt.security.risk.level`) |
| --- | --- |
| critical -> CRITICAL | 10.0 |
| high -> HIGH | 8.9 |
| medium -> MEDIUM | 6.9 |
| low -> LOW | 3.9 |

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Ingest Tenable vulnerability findings, scan events, and audit logs.](https://www.dynatrace.com/hub/detail/tenable/)

## Related topics

* [OpenPipeline](/docs/platform/openpipeline "Scale Dynatrace platform data handling with Dynatrace OpenPipeline.")
* [Dynatrace Query Language](/docs/platform/grail/dynatrace-query-language "How to use Dynatrace Query Language.")
* [Security events](/docs/semantic-dictionary/model/security-events "Get to know the Semantic Dictionary models related to security events.")


---


## Source: virustotal-enrich.md


---
title: Enrich threat observables with VirusTotal
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest/virustotal-enrich
scraped: 2026-02-17T21:17:17.200079
---

# Enrich threat observables with VirusTotal

# Enrich threat observables with VirusTotal

* Latest Dynatrace
* How-to guide
* Updated on Jan 07, 2026

Enrich threat observables with VirusTotal and analyze them in Dynatrace.

## Get started

### Overview

The Dynatrace integration with [VirusTotalï»¿](https://www.virustotal.com) brings threat intelligence context into alerts and detection investigations to help organizations combat online abuse, such as cyber-attacks, spamming, and other malicious activities.

With observable enrichment with reputation generated from the threat information provided by VirusTotal, you can perform more efficient security investigations and automate alert triaging, reducing the noise with threat-aware prioritization.

### Use cases

Once you set up the VirusTotal integration, you can enrich observables, such as IP addresses, with threat intelligence context.

Key use cases include:

* [Accelerate threat validation and streamline case triage in ![Investigations](https://dt-cdn.net/images/security-investigator-256-93f6c187d9.png "Investigations") **Investigations** with external reputation data](/docs/secure/investigations/enhance-results#enrich "Organize and interpret query outputs across investigations --- from performance analysis to threat detection.").
* [Enhance detection findings in ![Threats & Exploits](https://dt-cdn.net/images/attacks-512-b922840b12.png "Threats & Exploits") **Threats & Exploits** with external reputation data](/docs/secure/threats-and-exploits/manage-results#enrich "Filter, format, and sort detection findings.").
* IP enrichment with the Workflows app

  1. In [![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows**](/docs/analyze-explore-automate/workflows "Automate IT processes with Dynatrace Workflowsâreact to events, schedule tasks, and connect services.") ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows"), create a new workflow or edit an existing one.
  2. In the **Choose action** pane, search for **AbuseIPDB** and select the **AbuseIPDB check IP** action.
  3. Enter the parameters required for the action to run.
  4. Run the workflow to validate the action and review the results.
  5. Continue with your automation definition.

  ![workflow sample](https://dt-cdn.net/images/image-51-2526-e747d4a5ee.png)
* [Automated threat-alert triaging](/docs/secure/use-cases/automated-threat-alert-triaging "Use case scenario for automating threat-alert triaging with Dynatrace.")
* Threat-informed security investigations Coming soon

### Requirements

See below for the [VirusTotal](#virustotal) and [Dynatrace](#dt) requirements.

#### VirusTotal requirements

Register with VirusTotal and create an API v3 key.

#### Dynatrace requirements

The following IAM permissions are required:

* `app-engine:apps:run`
* `app-settings:objects:read`
* `document:documents:read`
* `settings:objects:read`
* `storage:system:read`
* `security-intelligence:enrichments:run`

To run the enrichment workflow action, all the permissions above need to be enabled in ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows** as well.

1. Go to the settings menu  in the upper-right corner of ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows** and select **Authorization settings**.
2. In **Secondary permissions**, search for and select the above-listed permissions.
3. Select **Save**.

## Activation and setup

1. In Dynatrace, open  [**Hub**](/docs/manage/hub "See the information about Dynatrace Hub.").
2. Look for **VirusTotal** and select **Install**.
3. Select **Set up** , then select  **Configure new connection**.
4. Follow the on-screen instructions to set up the connection using the API key obtained in [Prerequisites](#prereq).

   Allowed outbound connections are extended automatically with `www.virustotal.com`.

   1. How to set up outbound connections

   1. In **Settings**, go to **Preferences** > **Limit Outbound Connections**.
   2. Select **Add item** and add the domain.
   3. Select **Save changes**.
5. Test the connection to ensure the correct configuration and save it.

## Details

## How it works

![how it works](https://dt-cdn.net/images/image-20250418-083906-2216-9527a8fea8.png)

1. Install and configure the app

Dynatrace integration with VirusTotal is an app that you can install from  [**Hub**](/docs/manage/hub "See the information about Dynatrace Hub.").

The app delivers a workflow action for observable enrichment in ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows**.

To prevent accidental edits or deletions across environments, connection setup now includes owner-based access control. This ensures reliable automation, avoids unexpected configuration loss, and aligns with minimal access requirements.

For details on sharing and permissions, see [Access control for Connectors](/docs/analyze-explore-automate/workflows/actions/access-control "Display, view, create, and share connections for Dynatrace Connectors.").

2. Enrich observables

Various consumer apps can perform an on-demand enrichment of observables, for example, via a [workflow action](#workflow).

Dynatrace reaches out to VirusTotal to perform the observable enrichment.

Geolocation fields in enrichment results are sourced from the provider and can differ from the geolocation used in Dynatrace.  
For more information, see [FAQ: Geolocation differences](#ti-geo).

3. Use the threat intelligence data

The threat intelligence context is displayed within the consumer apps or in ![Workflows](https://dt-cdn.net/images/workflows-1024-b5708f3cf9.webp "Workflows") **Workflows**, helping you drive smarter decisions.

### Licensing and cost

For billing information, see [Events powered by Grail](/docs/license/capabilities/events "Learn how Dynatrace Events powered by Grail consumption is calculated using the Dynatrace Platform Subscription model.").

## FAQ

### Which observable types are currently supported?

Supported observable types: IP addresses (more coming soon).

### How will my VirusTotal API quotas will be affected from this integration?

For every new observable enrichment, we perform a single API call.

### Why does geolocation differ between enrichment results and Dynatrace?

Geolocation fields in enrichment results (such as `geo.country.iso_code`, `geo.country.name`, and city/coordinates if available) are provided directly by the external provider (in this case, VirusTotal).

These values reflect the VirusTotal geolocation data and may differ from the geolocation used in Dynatrace features (such as Real User Monitoring or platformâlevel geolocation).

Differences can occur because of different databases, update cycles, or mapping rules.

[![Hub](https://dt-cdn.net/images/hub-512-82db3c583e.png "Hub")

### Explore in Dynatrace Hub

Enrich observables with threat intelligence from VirusTotal.](https://www.dynatrace.com/hub/detail/virustotal)


---


## Source: security-events-ingest.md


---
title: Security integrations
source: https://www.dynatrace.com/docs/secure/threat-observability/security-events-ingest
scraped: 2026-02-17T21:13:50.367901
---

# Security integrations

# Security integrations

* Latest Dynatrace
* Overview
* Updated on Jan 07, 2026

Dynatrace provides different ways to integrate external security data from multiple third-party products into [Grail](/docs/platform/grail "Insights on what and how you can query Dynatrace data.") and operationalize your data on the Dynatrace platform.

## Ingest data

For a better understanding of the integration types, see [OpenPipeline integration types for security events](/docs/secure/threat-observability/concepts#security-ingest "Basic concepts related to Threat Observability").

See below for the supported integrations (with instructions).

* [Ingest custom security events via API](/docs/secure/threat-observability/security-events-ingest/ingest-custom-data "Ingest security events from custom third-party products via API.")
* [Ingest Akamai security logs and events](/docs/secure/threat-observability/security-events-ingest/ingest-akamai "Ingest Akamai security logs and events into Dynatrace as security events.")
* [Ingest Amazon ECR container vulnerability findings and scan events](/docs/secure/threat-observability/security-events-ingest/ingest-aws-ecr-data "Ingest Amazon ECR container image vulnerability findings and scan events and analyze them in Dynatrace.")
* [Ingest Amazon GuardDuty security findings](/docs/secure/threat-observability/security-events-ingest/ingest-amazon-guardduty "Ingest Amazon GuardDuty security findings and analyze them in Dynatrace.")
* [Ingest AWS Security Hub security findings](/docs/secure/threat-observability/security-events-ingest/ingest-aws-security-hub "Ingest AWS Security Hub security findings and analyze them in Dynatrace.")
* [Ingest GitHub Advanced Security security events and audit logs](/docs/secure/threat-observability/security-events-ingest/ingest-github-advanced-security "Ingest GitHub Advanced Security audit logs and security events into Dynatrace as security events.")
* [Ingest Harbor vulnerability findings, scans, and audit logs](/docs/secure/threat-observability/security-events-ingest/ingest-harbor-data "Ingest Harbor vulnerability findings, scans, and audit logs into Dynatrace as security events.")
* [Ingest Microsoft Defender for Cloud security events](/docs/secure/threat-observability/security-events-ingest/ingest-microsoft-defender "Ingest Microsoft Defender for Cloud security events and analyze them in Dynatrace.")
* [Ingest Microsoft Entra ID sign-in logs](/docs/secure/threat-observability/security-events-ingest/ingest-microsoft-entra-id "Ingest Microsoft Entra ID sign-in logs and analyze them in Dynatrace.")
* [Ingest Microsoft Sentinel security events](/docs/secure/threat-observability/security-events-ingest/ingest-microsoft-sentinel "Ingest Microsoft Sentinel security events and analyze them in Dynatrace.")
* [Ingest vulnerability findings in OCSF format](/docs/secure/threat-observability/security-events-ingest/ingest-ocsf-data "Ingest vulnerability findings in OCSF format from any provider and analyze them on the Dynatrace platform.")
* [Ingest Qualys vulnerability findings, scan events, and audit logs](/docs/secure/threat-observability/security-events-ingest/ingest-qualys "Ingest Qualys vulnerability findings, scan events, and audit logs into Dynatrace as security events.")
* [Ingest Runecast Analyzer compliance findings](/docs/secure/threat-observability/security-events-ingest/ingest-runecast-analyzer "Ingest compliance findings from Runecast Analyzer and analyze them on the Dynatrace platform.")
* [Ingest Snyk vulnerability findings, scans, and audit logs](/docs/secure/threat-observability/security-events-ingest/ingest-snyk-data "Ingest Snyk vulnerability findings, scans, and audit logs into Dynatrace as security events.")
* [Ingest SonarQube security and quality events, metrics, and audit logs](/docs/secure/threat-observability/security-events-ingest/ingest-sonarqube-data "Ingest SonarQube security and quality events, metrics, and audit logs into Dynatrace as security events.")
* [Ingest Sonatype Lifecycle security events and audit logs](/docs/secure/threat-observability/security-events-ingest/ingest-sonatype "Ingest Sonatype Lifecycle security events and audit logs into Dynatrace as security events.")
* [Ingest Tenable vulnerability findings, scan events, and audit logs](/docs/secure/threat-observability/security-events-ingest/ingest-tenable-data "Ingest Tenable vulnerability findings, scan events, and audit logs into Dynatrace as security events.")

## Enrich data

Add external reputation data to observables using trusted threat intelligence sources:

* [Enrich threat observables with AbuseIPDB](/docs/secure/threat-observability/security-events-ingest/abuseipdb-enrich "Enrich threat observables with AbuseIPDB and analyze them in Dynatrace.")
* [Enrich threat observables with VirusTotal](/docs/secure/threat-observability/security-events-ingest/virustotal-enrich "Enrich threat observables with VirusTotal and analyze them in Dynatrace.")

After configuring enrichment sources, you can apply them to:

* Validate observables in [![Investigations](https://dt-cdn.net/images/security-investigator-256-93f6c187d9.png "Investigations") **Investigations**](/docs/secure/investigations/enhance-results#enrich "Organize and interpret query outputs across investigations --- from performance analysis to threat detection.")
* Enhance detection findings in [![Threats & Exploits](https://dt-cdn.net/images/attacks-512-b922840b12.png "Threats & Exploits") **Threats & Exploits**](/docs/secure/threats-and-exploits/manage-results#enrich "Filter, format, and sort detection findings.")


---
